<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Anthony Faustine</title>
<link>https://sambaiga.github.io/pages/blog/</link>
<atom:link href="https://sambaiga.github.io/pages/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Anthony Faustine&#39;s blog on AI and Energy</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Wed, 17 Dec 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Bayesian Regression: A Real-World Battery Degradation Case Study</title>
  <dc:creator>Anthony Faustine</dc:creator>
  <link>https://sambaiga.github.io/pages/blog/posts/2025/12/2025-12-1-bayesian-regression..html</link>
  <description><![CDATA[ 





<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>Welcome back to our series on <em>Bayesian Modelling for Industrial Applications</em>. In <a href="https://sambaiga.github.io/blog/2025/10/bayesian-modelling-01.html">Part 1</a>, we explored how Bayesian thinking provides a principled framework for decision-making under uncertainty when evidence is limited.</p>
<p>In this post, we extend that foundation to continuous prediction problems, offering a practical introduction to Bayesian regression through a real-world case study: predicting lithium-ion battery degradation. If you are new to Bayesian methods, you may want to start with the first post <a href="https://sambaiga.github.io/blog/2025/10/bayesian-modelling-01.html">Part 1</a>, which introduces the foundational concepts of Bayesian inference.</p>
<blockquote class="blockquote">
<p>üõ†Ô∏è <strong>Action</strong>: If you prefer to learn by doing, you can reproduce this article using the accompanying resources:</p>
</blockquote>
<ol type="1">
<li><a href="https://github.com/sambaiga/bayesian-modelling">Repository</a>: Fork the <a href="https://github.com/sambaiga/bayesian-modelling">bayesian-modelling repository</a> and follow the setup instructions in the README.md</li>
<li><a href="https://github.com/sambaiga/bayesian-modelling/blob/main/notebook/2025-12-1-bayesian-regression..ipynb">Notebook</a>: Launch <a href="https://github.com/sambaiga/bayesian-modelling/blob/main/notebook/2025-12-1-bayesian-regression..ipynb">2025-12-1-bayesian-regression.ipynb</a> in the notebook folder to follow along step-by-step.</li>
</ol>
<p>Imagine managing a fleet of electric vehicles. One of your biggest challenges is predicting battery State of Health over time. This is important problem as early predictions inform warranty decisions, maintenance planning, and safety margins. However, industrial systems, like vehicle battery packs, are inherently complex: they are characterized by noisy, non-repeatable measurements due to sensor noise, unit variability, and stochastic physical processes. Traditional deterministic regression methods yield a single best-fit curve and therefore fail to capture the inherent variability and risk present in real-world industrial data which is characterised by:</p>
<ul>
<li>Measurement uncertainty inherent in sensors and data acquisition systems<br>
</li>
<li>Unit-to-unit variability in components (e.g., subtle differences between nominally identical batteries)<br>
</li>
<li>Random and nonlinear degradation behaviour<br>
</li>
<li>Limited early-life observations, a common constraint in industrial testing</li>
</ul>
<p>Bayesian regression addresses this reality by treating model parameters as probability distributions rather than fixed values. Each coefficient represents a range of plausible effects, informed by both prior knowledge and observed data so that uncertainty and risk are explicitly accounted for. This framework is built on three core components:</p>
<ol type="1">
<li><strong>Priors</strong>, which encode existing engineering knowledge or physical constraints<br>
</li>
<li><strong>Likelihood</strong>, which links the model to noisy real-world measurements<br>
</li>
<li><strong>Posterior</strong>, which combines prior information and data into an updated belief</li>
</ol>
<p>The posterior distribution enables <strong>credible intervals</strong>, allowing us to quantify how confident we are in both parameter estimates and future predictions‚Äîan essential capability in industrial decision-making.</p>
</section>
<section id="case-study-predicting-battery-degradation" class="level3">
<h3 class="anchored" data-anchor-id="case-study-predicting-battery-degradation">Case Study: Predicting battery degradation</h3>
<p>Lithium-ion batteries are critical components in electric vehicles and stationary energy storage systems. Unexpected capacity loss can lead to service interruptions, safety risks, and costly premature replacements.</p>
<p>The challenge is predicting future battery health when:</p>
<ul>
<li>Direct capacity measurements are infrequent and expensive</li>
<li>Early-life data is sparse</li>
<li>Degradation accelerates nonlinearly near end of life</li>
</ul>
<p>The goal is not only to predict degradation, but to quantify uncertainty well enough to support maintenance and replacement decisions. We use battery degradation data from the <a href="https://calce.umd.edu/battery-data">CALCE Battery</a> Research Group at the University of Maryland. The <a href="https://calce.umd.edu/battery-data">CALCE dataset</a> provides over 1,200 capacity measurements taken at discrete cycle intervals, alongside features like charging and discharge current and voltage. This comprehensive dataset has become a benchmark in battery research, allowing rigorous comparison of degradation models</p>
<div id="6" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> arviz <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> az</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> great_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GT, loc, md, style</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> clear_output</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lets_plot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> (</span>
<span id="cb1-5">    LetsPlot,</span>
<span id="cb1-6">    aes,</span>
<span id="cb1-7">    coord_cartesian,</span>
<span id="cb1-8">    facet_wrap,</span>
<span id="cb1-9">    flavor_high_contrast_dark,</span>
<span id="cb1-10">    geom_area,</span>
<span id="cb1-11">    geom_band,</span>
<span id="cb1-12">    geom_density,</span>
<span id="cb1-13">    geom_histogram,</span>
<span id="cb1-14">    geom_line,</span>
<span id="cb1-15">    geom_point,</span>
<span id="cb1-16">    geom_ribbon,</span>
<span id="cb1-17">    geom_vline,</span>
<span id="cb1-18">    gggrid,</span>
<span id="cb1-19">    ggplot,</span>
<span id="cb1-20">    ggsize,</span>
<span id="cb1-21">    guide_legend,</span>
<span id="cb1-22">    guides,</span>
<span id="cb1-23">    labs,</span>
<span id="cb1-24">    layer_tooltips,</span>
<span id="cb1-25">    scale_color_brewer,</span>
<span id="cb1-26">    scale_color_manual,</span>
<span id="cb1-27">    scale_fill_manual,</span>
<span id="cb1-28">    scale_y_continuous,</span>
<span id="cb1-29">)</span>
<span id="cb1-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-32"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-33"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pymc <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pm</span>
<span id="cb1-34"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span>  StandardScaler</span>
<span id="cb1-35"></span>
<span id="cb1-36">az.style.use(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arviz-doc"</span>)</span>
<span id="cb1-37"></span>
<span id="cb1-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> bayes.plot.basic_plots <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> line_plot, modern_theme, pro_colors, scatter_plot</span>
<span id="cb1-39"></span>
<span id="cb1-40">LetsPlot.setup_html(isolated_frame<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, offline<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, no_js<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, show_status<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb1-41">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span></code></pre></div></div>
</details>
</div>
<section id="choosing-the-beta-likelihood" class="level4">
<h4 class="anchored" data-anchor-id="choosing-the-beta-likelihood">Choosing the Beta Likelihood</h4>
<p>The capacity data being modeled, <img src="https://latex.codecogs.com/png.latex?C">, represents the battery‚Äôs health and is strictly bounded between $[C_{}, C_{}]. The goal of this analysis is to model the evolution of <img src="https://latex.codecogs.com/png.latex?C_i">. In many standard regression approaches, the model‚Äôs likelihood function (which defines the distribution of the noise) is assumed to be Gaussian (Normal). This assumption is fundamentally incompatible with the physical reality of capacity degradation for two key reasons.</p>
<ol type="1">
<li>Gaussian models assume the target variable can take any real value (<img src="https://latex.codecogs.com/png.latex?-%5Cinfty"> to <img src="https://latex.codecogs.com/png.latex?+%5Cinfty">), ignoring the fact that the underlying capacity <img src="https://latex.codecogs.com/png.latex?C"> cannot fall outside their physical limits (i.e., <img src="https://latex.codecogs.com/png.latex?%5BC_%7B%5Ctext%7Bmin%7D%7D,%20C_%7B%5Ctext%7Bmax%7D%7D%5D"> )</li>
<li>With enough extrapolation, Gaussian models produce impossible values (e.g.,negative capacity). In safety-critical systems, such predictions are dangerous.</li>
</ol>
<p>The Beta distribution is chosen as the likelihood due to its flexible shape, governed by <img src="https://latex.codecogs.com/png.latex?%5Calpha"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, which can model a wide range of behaviors. Because battery capacity degradation is continuous and strictly bounded within [<img src="https://latex.codecogs.com/png.latex?C_%7B%5Ctext%7Bmin%7D%7D">, <img src="https://latex.codecogs.com/png.latex?C_%7B%5Ctext%7Bmax%7D%7D">], the Beta likelihood provides a natural alternative to Gaussian models that require ad-hoc truncation.</p>
<p>To match the Beta distribution‚Äôs <img src="https://latex.codecogs.com/png.latex?%5B0,1%5D"> support, capacity <img src="https://latex.codecogs.com/png.latex?C_i"> is linearly scaled to <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BC%7Di%20=%20%5Cfrac%7BC_i%20-%20C%7B%5Ctext%7Bmin%7D%7D%7D%7BC_%7B%5Ctext%7Bmax%7D%7D%20-%20C_%7B%5Ctext%7Bmin%7D%7D%7D"> and modeled as <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BC%7D_i%20%5Csim%20%5Ctext%7BBeta%7D(%5Calpha_i,%20%5Cbeta_i)">. This guarantees physically plausible predictions while retaining flexibility through the shape parameters.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb2-2">    pm.Beta(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y_obs"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>alpha, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>beta_shape, observed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_data)</span></code></pre></div></div>
<section id="parameterization-mean-mu-and-precision-phi" class="level5">
<h5 class="anchored" data-anchor-id="parameterization-mean-mu-and-precision-phi">Parameterization: Mean (<img src="https://latex.codecogs.com/png.latex?%5Cmu">) and Precision (<img src="https://latex.codecogs.com/png.latex?%5Cphi">)</h5>
<p>To make the parameters intuitive, the Beta distribution is typically reparameterized using the mean (<img src="https://latex.codecogs.com/png.latex?%5Cmu">) and the precision (<img src="https://latex.codecogs.com/png.latex?%5Cphi">).The shape parameters, <img src="https://latex.codecogs.com/png.latex?%5Calpha_i"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta_i">, which define the exact shape of the distribution for a given observation, are calculated directly from the mean <img src="https://latex.codecogs.com/png.latex?%5Cmu_%7Bi%7D%20%5Cin%20(0,%201)"> and the global precision <img src="https://latex.codecogs.com/png.latex?%5Cphi%20%3E%200"> such that:<img src="https://latex.codecogs.com/png.latex?%5Calpha_i%20=%20%5Cmu_%7Bi%7D%20%5Ccdot%20%5Cphi%20%5Cquad%20%5Ctext%7Band%7D%20%5Cquad%20%5Cbeta_i%20=%20(1%20-%20%5Cmu_%7Bi%7D)%20%5Ccdot%20%5Cphi"> The precision parameter, <img src="https://latex.codecogs.com/png.latex?%5Cphi">, controls the variance: a large <img src="https://latex.codecogs.com/png.latex?%5Cphi"> means the predictions are tightly clustered around the mean <img src="https://latex.codecogs.com/png.latex?%5Cmu_%7Bi%7D">, indicating low uncertainty (low variance).</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb3-2">    alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mu_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> phi</span>
<span id="cb3-3">    beta_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> mu_scaled) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> phi</span></code></pre></div></div>
<p>The mean parameter <img src="https://latex.codecogs.com/png.latex?%5Cmu_%7Bi%7D%20%5Cin%20(0,%201)"> must be linked to our predictors. Since the mean is bounded by <img src="https://latex.codecogs.com/png.latex?(0,%201)">, we use the Logit Link Function to map the linear combination of predictors (<img src="https://latex.codecogs.com/png.latex?%5Ceta_i">) to this interval: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Blogit%7D(%5Cmu_%7Bi%7D)%20=%20%5Ceta_i"> as such , <img src="https://latex.codecogs.com/png.latex?%5Cmu_%7Bi%7D%20=%20%5Ctext%7Blogit%7D%5E%7B-1%7D(%5Ceta_i)%20=%20%5Cfrac%7B1%7D%7B1%20+%20e%5E%7B-%5Ceta_i%7D%7D"></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb4-2">    mu_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Deterministic(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mu_scaled"</span>, pm.math.sigmoid(logit_mu))</span></code></pre></div></div>
<blockquote class="blockquote">
<p>üí° Key Takeaway: The Logit Link function is the mathematical bridge that ensures our mean prediction, <img src="https://latex.codecogs.com/png.latex?%5Cmu_i">, respects the physical boundary of <img src="https://latex.codecogs.com/png.latex?(0,%201)"> imposed by the Beta distribution</p>
</blockquote>
</section>
<section id="the-linear-predictor-capturing-degradation" class="level5">
<h5 class="anchored" data-anchor-id="the-linear-predictor-capturing-degradation">The Linear Predictor: Capturing Degradation</h5>
<p>The core of our predictive power lies in the linear predictor, <img src="https://latex.codecogs.com/png.latex?%5Ceta_i">. It is structured to incorporate both the fundamental, non-linear degradation due to cycling and the linear operational effects from features <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> like voltage and current: <img src="https://latex.codecogs.com/png.latex?%5Ceta_i%20=%20%5Cunderbrace%7B%5Cbeta_0%7D_%7B%5Ctext%7BIntercept%7D%7D%20+%20%5Cunderbrace%7Bf(k_i)%7D_%7B%5Ctext%7BNon-linear%20Decay%7D%7D%20+%20%5Cunderbrace%7B%5Cmathbf%7Bx%7D_i%5E%7B%5Ctop%7D%20%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Ctext%7BOperational%20Effects%7D%7D"></p>
<p>In this work, the non-linear decay component is modeled as an exponential function: <img src="https://latex.codecogs.com/png.latex?f(k_i)%20=%20-A%5Ccdot(1-e%5E%7B-%5Clambda%20%5Ccdot%20k_i%7D)"> where <img src="https://latex.codecogs.com/png.latex?k_i"> is the cycle count, <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is the degradation rate, and <img src="https://latex.codecogs.com/png.latex?A%3E0"> is a learnable amplitude parameter controlling the strength of decay. This captures the physical reality that battery capacity degrades rapidly at first and then more slowly over time. where:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb5-2">    degradation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.math.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>lambda_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> cycle_data)</span>
<span id="cb5-3">    degradation_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>degr_amp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> degradation)</span>
<span id="cb5-4">    logit_mu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> intercept <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> degradation_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> pm.math.dot(x_data, beta)</span></code></pre></div></div>
<p>The components of <img src="https://latex.codecogs.com/png.latex?%5Ceta_i"> are as follows:</p>
<ol type="1">
<li>Intercept (<img src="https://latex.codecogs.com/png.latex?%5Cbeta_0">): The baseline capacity on the logit scale when operational effects are zero and the cycle count (<img src="https://latex.codecogs.com/png.latex?k_i">) is zero.</li>
<li>Degradation Term (<img src="https://latex.codecogs.com/png.latex?e%5E%7B-%5Clambda%20%5Ccdot%20k_i%7D">): This is the non-linear exponential decay over the cycle count <img src="https://latex.codecogs.com/png.latex?k_i">, controlled by the rate <img src="https://latex.codecogs.com/png.latex?%5Clambda">. This term ensures the capacity prediction naturally trends downward toward zero capacity over time.</li>
<li>Operational Effects (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_%7Bi%7D%5E%7B%5Ctop%7D%20%5Cboldsymbol%7B%5Cbeta%7D">): This is a standard linear combination, where <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D"> is the vector of coefficients for the standardized operational features <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_%7Bi%7D">.</li>
</ol>
<p>This models how factors like maximum temperature accelerate or slow down the degradation.</p>
<blockquote class="blockquote">
<p>üß† <strong>Self-Test</strong>: You are modeling <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BSoH%7D">, which must stay in <img src="https://latex.codecogs.com/png.latex?%5B0,%201%5D">. Your linear predictor, <img src="https://latex.codecogs.com/png.latex?%5Ceta_i%20=%20%5Cbeta_0%20+%20%5Cmathbf%7Bx%7D_i%5E%7B%5Ctop%7D%20%5Cboldsymbol%7B%5Cbeta%7D">, can produce values ranging from <img src="https://latex.codecogs.com/png.latex?-%5Cinfty"> to <img src="https://latex.codecogs.com/png.latex?+%5Cinfty">.What would happen if you skipped the Logit Link Function and simply set <img src="https://latex.codecogs.com/png.latex?%5Cmu_i%20=%20%5Ceta_i">? Why is the Logit Link function mandatory for the Beta regression model?</p>
</blockquote>
</section>
</section>
<section id="encoding-knowledge-with-priors" class="level4">
<h4 class="anchored" data-anchor-id="encoding-knowledge-with-priors">Encoding Knowledge with Priors</h4>
<p>In Bayesian modeling, defining priors is a critical step. This step allows domain knowledge accumulated from battery engineering to be embedded directly into the model, ensuring that predictions remain physically plausible even when data is sparse. A prior distribution is assigned to every unknown parameter (<img src="https://latex.codecogs.com/png.latex?%5Cbeta_0,%20%5Cboldsymbol%7B%5Cbeta%7D,%20%5Clambda,%20%5Cphi">). These priors act as soft constraints, preventing the model from learning extreme or non-physical relationships.</p>
<p><strong>The Intercept (<img src="https://latex.codecogs.com/png.latex?%5Cbeta_0">)</strong></p>
<p>The Intercept <img src="https://latex.codecogs.com/png.latex?%5Cbeta_0"> represents the initial capacity of the battery fleet on the logit scale. The orange curve in the figure below represents the selected informative prior, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BNormal%7D(%5Cmu_%7B%5Ctext%7Blogit%5C_start%7D%7D,%200.5%5E2)">. A standard deviation of <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%200.5"> is chosen to balance prior knowledge (centering at <img src="https://latex.codecogs.com/png.latex?%5Cmu_%7B%5Ctext%7Blogit%5C_start%7D%7D">) with sufficient uncertainty to allow the observed data to meaningfully influence the final estimate.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb6-2">    eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-8</span></span>
<span id="cb6-3">    initial_logit_capacity_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.log(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>eps)</span>
<span id="cb6-4">    intercept <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Normal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"intercept"</span>, mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>initial_logit_capacity_mean, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span></code></pre></div></div>
<div id="9" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> bayes.plot.distribution <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_density</span></code></pre></div></div>
</details>
</div>
<div id="10" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb8-2">s1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Normal.dist(mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.28</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>), n)</span>
<span id="cb8-3">s2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Normal.dist(mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.28</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>), n)</span>
<span id="cb8-4">s3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Normal.dist(mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.28</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>), n)</span>
<span id="cb8-5"></span>
<span id="cb8-6">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb8-7">    {</span>
<span id="cb8-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value"</span>: np.concatenate([s1, s2, s3]),</span>
<span id="cb8-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"distribution"</span>: np.repeat([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=0.28, œÉ=0.1)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=0.28, œÉ=0.2)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=0.28, œÉ=0.5)"</span>], n),</span>
<span id="cb8-10">    }</span>
<span id="cb8-11">)</span>
<span id="cb8-12"></span>
<span id="cb8-13">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot_density(df, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Normal Distributions Intercept Priors"</span>, fig_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>))</span></code></pre></div></div>
</details>
</div>
<div id="11" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1">plot</span></code></pre></div></div>
</details>
</div>
<p>The narrower blue (<img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%200.1">) and green (<img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%200.2">) curves represent highly concentrated priors that would strongly restrict the posterior estimates. The wider <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%200.5"> (orange) distribution corresponds to a more conservative informative prior, granting the initial capacity estimate <img src="https://latex.codecogs.com/png.latex?%5Cbeta_0"> a reasonable degree of uncertainty.</p>
<p><strong>Operational Effects (<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D">)</strong></p>
<p>The vector of coefficients <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D"> controls the influence of operational features on capacity fade. Engineering knowledge suggests that, unless a feature is extreme, its immediate effect on capacity should be subtle, as the overall degradation process is primarily driven by cycle count.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb10-2">    beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Normal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beta"</span>, mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_features)</span></code></pre></div></div>
<div id="14" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> bayes.plot.distribution <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_density</span></code></pre></div></div>
</details>
</div>
<div id="15" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"></span>
<span id="cb12-2">s1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Normal.dist(mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>), n)</span>
<span id="cb12-3">s2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Normal.dist(mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>), n)</span>
<span id="cb12-4">s3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Normal.dist(mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>), n)</span>
<span id="cb12-5"></span>
<span id="cb12-6">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb12-7">    {</span>
<span id="cb12-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value"</span>: np.concatenate([s1, s2, s3]),</span>
<span id="cb12-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"distribution"</span>: np.repeat([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=0, œÉ=0.1)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=0, œÉ=0.2)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=0, œÉ=1.0)"</span>], n),</span>
<span id="cb12-10">    }</span>
<span id="cb12-11">)</span>
<span id="cb12-12"></span>
<span id="cb12-13">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot_density(df, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Normal Distributions Beta Priors"</span>, fig_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>))</span></code></pre></div></div>
</details>
</div>
<div id="16" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1">plot</span></code></pre></div></div>
</details>
</div>
<p>As shown in the figure above, a tight informative prior, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BNormal%7D(0,%200.2%5E2)">, is used for <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D">. Centering this prior at zero reflects the assumption that, on average, operational features have no effect, while the small standard deviation (<img src="https://latex.codecogs.com/png.latex?0.2">) requires strong evidence from the data before attributing a large effect to any single feature. This constraint prevents non-physical, abrupt changes in capacity predictions. In contrast, a broader prior such as <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BNormal%7D(0,%201.0%5E2)"> (orange curve) allows extreme effects that are considered non-physical.</p>
<p><strong>Degradation rate <img src="https://latex.codecogs.com/png.latex?%5Clambda"></strong></p>
<p>The degradation rate <img src="https://latex.codecogs.com/png.latex?%5Clambda"> governs the exponential decay term <img src="https://latex.codecogs.com/png.latex?e%5E%7B-%5Clambda%20k_i%7D">. Since degradation must always occur and capacity cannot increase indefinitely, it is necessary to enforce <img src="https://latex.codecogs.com/png.latex?%5Clambda%20%3E%200">. Accordingly, a Log-Normal prior, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BLogNormal%7D(%5Cln(0.005),%200.5%5E2)">, is used for <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb14-2">    lambda_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Lognormal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lambda_rate"</span>, mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.log(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>), sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span></code></pre></div></div>
<blockquote class="blockquote">
<p>üß† <strong>Self-Test</strong>: Recall that we set the prior for the fade rate <img src="https://latex.codecogs.com/png.latex?%5Clambda"> as <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BLogNormal%7D(%5Cln(0.01),%200.5%5E2)"> (where <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%200.5">). What practical problem would arise if an engineer, overly confident in their historical knowledge, reset the prior to <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BLogNormal%7D(%5Cln(0.01),%200.1%5E2)"> (where <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%200.1">)?</p>
</blockquote>
<div id="19" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"></span>
<span id="cb15-2">s1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.LogNormal.dist(np.log(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.005</span>), sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>), n)</span>
<span id="cb15-3">s2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.LogNormal.dist(np.log(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.005</span>), sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>), n)</span>
<span id="cb15-4">s3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.LogNormal.dist(np.log(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.005</span>), sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>), n)</span>
<span id="cb15-5"></span>
<span id="cb15-6">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb15-7">    {</span>
<span id="cb15-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value"</span>: np.concatenate([s1, s2, s3]),</span>
<span id="cb15-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"distribution"</span>: np.repeat([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=In(0.005), œÉ=0.1)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=In(0.005), œÉ=0.5)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(Œº=In(0.005), œÉ=1.0)"</span>], n),</span>
<span id="cb15-10">    }</span>
<span id="cb15-11">)</span>
<span id="cb15-12"></span>
<span id="cb15-13">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot_density(df, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LogNormal Distributions Priors"</span>, fig_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>))</span></code></pre></div></div>
</details>
</div>
<div id="20" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1">plot</span></code></pre></div></div>
</details>
</div>
<p>This weakly informative prior centers the expected degradation rate around <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0.5%5C%25%7D">, while the spread <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%200.5"> (green/teal curve) is sufficiently wide to accommodate realistic fleet-level variability. At the same time, it remains substantially tighter than <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%201.0"> (orange curve), thereby avoiding non-physical probability mass assigned to unrealistically large degradation rates. This distribution reflects a conservative estimate of uncertainty, allowing greater variation in degradation behavior than a tighter prior (e.g., <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%200.1">) would permit, while still preventing implausible rates.</p>
<p><strong>Degradation Amplitude (<img src="https://latex.codecogs.com/png.latex?A">)</strong></p>
<p>The parameter degr_amp (<img src="https://latex.codecogs.com/png.latex?A">) controls the overall amplitude of the degradation component. Since this amplitude must be non-negative, a Half-Normal distribution is used, which has support only on positive values. The scale parameter <img src="https://latex.codecogs.com/png.latex?%5Csigma"> determines the strength of regularization.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1">   <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb17-2">    degr_amp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.HalfNormal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"degr_amp"</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span></code></pre></div></div>
<div id="23" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"></span>
<span id="cb18-2">s1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.HalfNormal.dist(sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>), n)</span>
<span id="cb18-3">s2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.HalfNormal.dist(sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>), n)</span>
<span id="cb18-4">s3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.HalfNormal.dist(sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>), n)</span>
<span id="cb18-5"></span>
<span id="cb18-6"></span>
<span id="cb18-7">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb18-8">    {</span>
<span id="cb18-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value"</span>: np.concatenate([s1, s2, s3]),</span>
<span id="cb18-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"distribution"</span>: np.repeat([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"œÉ=0.1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"œÉ=0.2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"œÉ=0.5"</span>], n),</span>
<span id="cb18-11">    }</span>
<span id="cb18-12">)</span>
<span id="cb18-13">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot_density(df, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gamma Distributions Phi Priors"</span>, fig_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>))</span></code></pre></div></div>
</details>
</div>
<div id="24" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1">plot</span></code></pre></div></div>
</details>
</div>
<p>As shown in the figure above, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BHalfNormal%7D(%5Csigma%20=%200.1)"> strongly concentrates probability mass near zero, requiring substantial evidence before attributing a large degradation amplitude. In contrast, broader priors such as <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BHalfNormal%7D(%5Csigma%20=%200.5)"> place non-negligible probability on large, non-subtle amplitudes (up to approximately <img src="https://latex.codecogs.com/png.latex?1.0">), increasing the risk of overfitting by allowing the model to explain noise through the amplitude term.</p>
<p><strong>Precision Parameter (<img src="https://latex.codecogs.com/png.latex?%5Cphi">)</strong></p>
<p>The precision parameter <img src="https://latex.codecogs.com/png.latex?%5Cphi"> controls the variance of the Beta likelihood and represents the expected level of noise in the <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BSoH%7D"> measurements. Accordingly, a highly informative Gamma prior, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BGamma%7D(100,%202)">, is assigned to <img src="https://latex.codecogs.com/png.latex?%5Cphi">.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> battery_model:</span>
<span id="cb20-2">    phi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Gamma(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"phi"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>)</span></code></pre></div></div>
<p>This prior is centered at <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5B%5Cphi%5D%20=%20%5Calpha%20/%20%5Cbeta%20=%2050"> with a relatively small standard deviation (<img src="https://latex.codecogs.com/png.latex?%5Csigma_%7B%5Cphi%7D%20=%205.0">), indicating high confidence in this expectation. This choice encodes the belief that sensor noise is low (<img src="https://latex.codecogs.com/png.latex?%5Csigma_%7B%5Ctext%7Bnoise%7D%7D%20%5Capprox%200.14">), reflecting the physical reality of precise laboratory-grade measurements.</p>
<div id="27" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"></span>
<span id="cb21-2">s1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Gamma.dist(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), n)</span>
<span id="cb21-3">s2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Gamma.dist(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>), n)</span>
<span id="cb21-4">s3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.draw(pm.Gamma.dist(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), n)</span>
<span id="cb21-5"></span>
<span id="cb21-6"></span>
<span id="cb21-7">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb21-8">    {</span>
<span id="cb21-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value"</span>: np.concatenate([s1, s2, s3]),</span>
<span id="cb21-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"distribution"</span>: np.repeat([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gamma(Œ±=10, Œ≤=1)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gamma(Œ±=50, Œ≤=5)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gamma(Œ±=100, Œ≤=2)"</span>], n),</span>
<span id="cb21-11">    }</span>
<span id="cb21-12">)</span>
<span id="cb21-13">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot_density(df, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gamma Distributions Phi Priors"</span>, fig_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>))</span></code></pre></div></div>
</details>
</div>
<div id="28" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1">plot</span></code></pre></div></div>
</details>
</div>
<p>From the figure above, it is evident that <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BGamma%7D(%5Calpha%20=%20100,%20%5Cbeta%20=%202.0)"> (orange curve) provides a strong belief in high precision. In contrast, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BGamma%7D(%5Calpha%20=%2010,%20%5Cbeta%20=%201.0)"> yields a lower expected precision with greater spread, allowing excessive uncertainty and risking a flat, unphysical prior predictive distribution. Alternative Gamma priors with the same expected precision but larger variance similarly underestimate the precision of modern sensors.</p>
<p>The complete model now combines all these components:</p>
<div id="31" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> beta_regression_model(</span>
<span id="cb23-2">    data: pd.DataFrame,</span>
<span id="cb23-3">    features: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>],</span>
<span id="cb23-4">    target: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"capacity"</span>,</span>
<span id="cb23-5">    scaler: StandardScaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb23-6">    lower_bound: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb23-7">    upper_bound: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.3</span>,</span>
<span id="cb23-8">    eps: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-8</span>,</span>
<span id="cb23-9">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>[pm.Model, StandardScaler]:</span>
<span id="cb23-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Beta regression model for bounded battery capacity data using PyMC.</span></span>
<span id="cb23-11"></span>
<span id="cb23-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Capacity (SoH) is scaled to the (0, 1) interval for the Beta distribution.</span></span>
<span id="cb23-13"></span>
<span id="cb23-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb23-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        data: DataFrame containing 'capacity', 'cycle', and feature columns.</span></span>
<span id="cb23-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        features: List of column names used as predictors (X variables).</span></span>
<span id="cb23-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        target: Name of the capacity column.</span></span>
<span id="cb23-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        scaler: Pre-fitted StandardScaler object, or None to fit a new one.</span></span>
<span id="cb23-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        lower_bound: Physical lower bound for capacity (for scaling).</span></span>
<span id="cb23-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        upper_bound: Physical upper bound for capacity (for scaling).</span></span>
<span id="cb23-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        eps: Small value to avoid boundary issues in Beta distribution.</span></span>
<span id="cb23-22"></span>
<span id="cb23-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb23-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        A tuple containing the PyMC model and the fitted/provided StandardScaler.</span></span>
<span id="cb23-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb23-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Prepare Features (X)</span></span>
<span id="cb23-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> scaler <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb23-28">        scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb23-29">        x_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(data[features])</span>
<span id="cb23-30">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb23-31">        x_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.transform(data[features])</span>
<span id="cb23-32"></span>
<span id="cb23-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Prepare Targets (Y)</span></span>
<span id="cb23-34">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[target].values.astype(np.float64)</span>
<span id="cb23-35">    cycles <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cycle"</span>].values.astype(np.float64)</span>
<span id="cb23-36">    n_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(features)</span>
<span id="cb23-37"></span>
<span id="cb23-38">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Transform y to (0,1) interval and clip to avoid boundaries (0 or 1)</span></span>
<span id="cb23-39">    y_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> lower_bound) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (upper_bound <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> lower_bound)</span>
<span id="cb23-40">    y_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.clip(y_scaled, eps, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> eps)</span>
<span id="cb23-41"></span>
<span id="cb23-42">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> model:</span>
<span id="cb23-43">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Data Containers</span></span>
<span id="cb23-44">        x_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Data(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x_data"</span>, x_scaled)</span>
<span id="cb23-45">        cycle_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Data(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cycle_data"</span>, cycles)</span>
<span id="cb23-46">        y_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Data(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y_data"</span>, y_scaled)</span>
<span id="cb23-47"></span>
<span id="cb23-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Priors</span></span>
<span id="cb23-49">        initial_logit_capacity_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.log(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-6</span>)</span>
<span id="cb23-50">        intercept <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Normal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"intercept"</span>, mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>initial_logit_capacity_mean, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb23-51">        lambda_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Lognormal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lambda_rate"</span>, mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.log(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.005</span>), sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb23-52">        beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Normal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beta"</span>, mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_features)</span>
<span id="cb23-53">        phi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Gamma(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"phi"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>)</span>
<span id="cb23-54">        degr_amp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.HalfNormal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"degr_amp"</span>, sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb23-55"></span>
<span id="cb23-56">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Linear predictor (eta) on logit scale</span></span>
<span id="cb23-57">        degradation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.math.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>lambda_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> cycle_data)</span>
<span id="cb23-58">        degradation_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>degr_amp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> degradation)</span>
<span id="cb23-59">        logit_mu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> intercept <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> degradation_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> pm.math.dot(x_data, beta)</span>
<span id="cb23-60"></span>
<span id="cb23-61">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to probability scale (0,1)</span></span>
<span id="cb23-62">        mu_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Deterministic(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mu_scaled"</span>, pm.math.invlogit(logit_mu))</span>
<span id="cb23-63"></span>
<span id="cb23-64">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Beta likelihood</span></span>
<span id="cb23-65">        alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mu_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> phi</span>
<span id="cb23-66">        beta_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> mu_scaled) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> phi</span>
<span id="cb23-67">        pm.Beta(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y_obs"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>alpha, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>beta_shape, observed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_data)</span>
<span id="cb23-68"></span>
<span id="cb23-69">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Transform mu back to original scale</span></span>
<span id="cb23-70">        mu_original <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Deterministic(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mu_original"</span>, mu_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (upper_bound <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> lower_bound) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> lower_bound)</span>
<span id="cb23-71"></span>
<span id="cb23-72">        pm.Deterministic(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"capacity_pred"</span>, mu_original)</span>
<span id="cb23-73">        pm.Deterministic(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"feature_effects"</span>, beta)</span>
<span id="cb23-74"></span>
<span id="cb23-75">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> model, scaler</span></code></pre></div></div>
</details>
</div>
</section>
</section>
<section id="translating-raw-battery-data-to-diagnostics-features" class="level3">
<h3 class="anchored" data-anchor-id="translating-raw-battery-data-to-diagnostics-features">Translating raw battery data to diagnostics features</h3>
<p>In the preceding sections, the output side of the Bayesian model was rigorously defined, including the Beta likelihood, the Logit link function, and physics-informed priors for the parameters (<img src="https://latex.codecogs.com/png.latex?%5Cbeta_0,%20%5Cboldsymbol%7B%5Cbeta%7D,%20%5Clambda,%20%5Cphi">). However, the quality of the resulting predictions depends critically on the quality of the input features (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">) that drive the degradation term (<img src="https://latex.codecogs.com/png.latex?%5Ceta_i%20=%20%5Cdots%20+%20%5Cmathbf%7Bx%7D_i%5E%7B%5Ctop%7D%20%5Cboldsymbol%7B%5Cbeta%7D">).</p>
<p>Raw capacity measurement curves are noisy and variable. Therefore, before proceeding to Bayesian sampling, it is necessary to dedicate a structured process to translating real-world operational data into robust, physically meaningful diagnostic features.</p>
<p>This motivates the crucial step of feature engineering.</p>
<section id="data-alignment-and-cleaning" class="level4">
<h4 class="anchored" data-anchor-id="data-alignment-and-cleaning">Data alignment and cleaning</h4>
<p>Before extracting diagnostic features, a uniform time base must be established, as the formulas used for feature extraction require comparable voltage and current values across cycles.</p>
<ol type="1">
<li>Cycle Alignment (Standardization): Linear interpolation is used to resample all voltage and current time-series arrays to a uniform length (e.g., 500 points). This standardization enables direct cycle-to-cycle comparison, as illustrated by the transition from the raw data (Figures 1 and 2) to the interpolated curves (Figures 3 and 4).</li>
</ol>
<div style="display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; margin: 30px 0;">
<div style="flex: 1; min-width: 300px; max-width: 600px; text-align: center;">
<img src="https://sambaiga.github.io/pages/blog/posts/2025/12/charge_voltage.png" alt="Cycle 1" style="width: 75%; height: auto; border-radius: 8px;">
<p style="margin-top: 12px; font-size: 15px; color: #555;">
Figure 1: Charging Voltage curve at the beginning of life
</p>
</div>
<div style="flex: 1; min-width: 300px; max-width: 600px; text-align: center;">
<img src="https://sambaiga.github.io/pages/blog/posts/2025/12/discharge_voltage.png" alt="Cycle 1000" style="width: 75%; height: auto; border-radius: 8px;">
<p style="margin-top: 12px; font-size: 15px; color: #555;">
Figure 2: Discharge Voltage curve at the beginning of life
</p>
</div>
</div>
<p>As shown in Figures 1 and 2, voltage curves differ in length due to variations in charge and discharge durations. Linear interpolation standardizes these curves to a fixed length (e.g., 500 points), enabling direct comparison across cycles, as illustrated in Figures 3 and 4.</p>
<div style="display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; margin: 30px 0;">
<div style="flex: 1; min-width: 300px; max-width: 600px; text-align: center;">
<img src="https://sambaiga.github.io/pages/blog/posts/2025/12/charge_voltage_interpolated.png" alt="Cycle 1" style="width: 75%; height: auto; border-radius: 8px;">
<p style="margin-top: 12px; font-size: 15px; color: #555;">
Figure 3: Inteporated Charging Voltage curve at the beginning of life
</p>
</div>
<div style="flex: 1; min-width: 300px; max-width: 600px; text-align: center;">
<img src="https://sambaiga.github.io/pages/blog/posts/2025/12/discharge_voltage_interpolated.png" alt="Cycle 1000" style="width: 75%; height: auto; border-radius: 8px;">
<p style="margin-top: 12px; font-size: 15px; color: #555;">
Figure 4: Inteporated Discharge Voltage curve at the beginning of life
</p>
</div>
</div>
<ol start="2" type="1">
<li>Data Filtering: Cycles exhibiting non-meaningful behavior (e.g., flat voltage profiles, excessive noise, or unrealistic starting or peak voltages) are removed to ensure that all inputs correspond to valid charging or discharging events.</li>
</ol>
</section>
<section id="diagnostic-feature-extraction" class="level4">
<h4 class="anchored" data-anchor-id="diagnostic-feature-extraction">Diagnostic Feature Extraction</h4>
<p>With aligned and cleaned curves, it is now possible to reliably extract cycle-specific diagnostic features that quantify the battery‚Äôs underlying physical degradation processes. These features are sensitive to aging mechanisms such as active material loss and internal resistance growth</p>
<blockquote class="blockquote">
<p><strong>üß† Reflection</strong>: We chose to derive these physically meaningful features instead of feeding the entire, aligned time-series data (Figures 3 &amp; 4). Why are these manually engineered features often preferred in industrial applications? Consider the trade-offs in <strong>model complexity</strong>, <strong>training speed</strong>, and the crucial <strong>interpretability</strong> of the final Bayesian coefficients (<img src="https://latex.codecogs.com/png.latex?%5Cbeta">).</p>
</blockquote>
<div id="34" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"></span>
<span id="cb24-2"></span>
<span id="cb24-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fix the typo and create data</span></span>
<span id="cb24-4">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({</span>
<span id="cb24-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Diagnostic Feature"</span>: [</span>
<span id="cb24-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Voltage Gap"</span>,</span>
<span id="cb24-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Voltage Hysteresis"</span>, </span>
<span id="cb24-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"IC Peak Metrics"</span>,</span>
<span id="cb24-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hysteresis Proxy Resistance"</span></span>
<span id="cb24-10">    ],</span>
<span id="cb24-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Formula"</span>: [</span>
<span id="cb24-12">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ŒîVÃÑ = VÃÑ_c - VÃÑ_d"</span>,</span>
<span id="cb24-13">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ŒîV(x) = V_c(x) - V_d(x)"</span>,</span>
<span id="cb24-14">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"IC = dQ/dV"</span>,</span>
<span id="cb24-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R_proxy ‚àù ŒîV(x)/I_diff"</span></span>
<span id="cb24-16">    ],</span>
<span id="cb24-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Physical Meaning"</span>: [</span>
<span id="cb24-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Average polarization; quantifies internal losses"</span>,</span>
<span id="cb24-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Loss mechanisms at specific state-of-charge"</span>,</span>
<span id="cb24-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Phase transitions; indicates active material loss"</span>,</span>
<span id="cb24-21">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Proxy for internal resistance growth"</span></span>
<span id="cb24-22">    ]</span>
<span id="cb24-23">})</span>
<span id="cb24-24"></span>
<span id="cb24-25"></span>
<span id="cb24-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create publication-quality table</span></span>
<span id="cb24-27">table <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb24-28">    GT(data)</span>
<span id="cb24-29">    .tab_header(</span>
<span id="cb24-30">        title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**Table 1: Battery Degradation Diagnostic Features**"</span>),</span>
<span id="cb24-31">        subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Mathematical definitions and physical interpretations of key battery health indicators"</span></span>
<span id="cb24-32">    )</span>
<span id="cb24-33">    .cols_label(</span>
<span id="cb24-34">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>{</span>
<span id="cb24-35">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Diagnostic Feature"</span>: md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**Diagnostic Feature**"</span>),</span>
<span id="cb24-36">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Formula"</span>: md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**Formula**"</span>),</span>
<span id="cb24-37">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Physical Meaning"</span>: md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**Physical Meaning**"</span>)</span>
<span id="cb24-38">        }</span>
<span id="cb24-39">    )</span>
<span id="cb24-40">    .tab_options(</span>
<span id="cb24-41">        table_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>,</span>
<span id="cb24-42">        container_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>,</span>
<span id="cb24-43">        table_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"14px"</span>,</span>
<span id="cb24-44">        heading_title_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"18px"</span>,</span>
<span id="cb24-45">        heading_subtitle_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"14px"</span>,</span>
<span id="cb24-46">        column_labels_border_bottom_style<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"solid"</span>,</span>
<span id="cb24-47">        column_labels_border_bottom_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"3px"</span>,</span>
<span id="cb24-48">        column_labels_border_bottom_color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#3498db"</span>,</span>
<span id="cb24-49">        table_body_border_bottom_style<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"solid"</span>,</span>
<span id="cb24-50">        table_body_border_bottom_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1px"</span>,</span>
<span id="cb24-51">        table_body_border_bottom_color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#dee2e6"</span></span>
<span id="cb24-52">    )</span>
<span id="cb24-53">    .tab_source_note(</span>
<span id="cb24-54">        source_note<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Formulas assume constant temperature and current rates unless otherwise specified."</span></span>
<span id="cb24-55">    )</span>
<span id="cb24-56">)</span>
<span id="cb24-57"></span>
<span id="cb24-58"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display</span></span>
<span id="cb24-59">table.show()</span></code></pre></div></div>
</details>
</div>
</section>
<section id="statistical-feature-aggregation" class="level4">
<h4 class="anchored" data-anchor-id="statistical-feature-aggregation">Statistical feature aggregation</h4>
<p>The diagnostic signals derived above (e.g., incremental capacity curves) remain high-resolution time- or cycle-series data. To produce robust, concise, and comparable inputs for the Bayesian regression model, a final aggregation step is performed by extracting statistical moments from each diagnostic signal <img src="https://latex.codecogs.com/png.latex?s(x)">. This aggregation reduces hundreds of data points per cycle into a small number of highly informative scalar features.</p>
<div id="36" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({</span>
<span id="cb25-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Statistical Feature"</span>: [</span>
<span id="cb25-3">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Mean"</span>,</span>
<span id="cb25-4">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Standard Deviation"</span>, </span>
<span id="cb25-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Skewness"</span>,</span>
<span id="cb25-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Kurtosis"</span>,</span>
<span id="cb25-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RMS (Root-Mean-Square)"</span>,</span>
<span id="cb25-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Entropy"</span>,</span>
<span id="cb25-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Crest Factor"</span>,</span>
<span id="cb25-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AUC (Area Under the Curve)"</span></span>
<span id="cb25-11">    ],</span>
<span id="cb25-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Role in Degradation Modeling"</span>: [</span>
<span id="cb25-13">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Captures the overall trend or shift of the diagnostic signal."</span>,</span>
<span id="cb25-14">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Measures variability and cycle-to-cycle noise."</span>,</span>
<span id="cb25-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Indicates asymmetry or bias in the signal distribution."</span>,</span>
<span id="cb25-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Quantifies the presence of extreme values or anomalies."</span>,</span>
<span id="cb25-17">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Represents the overall magnitude and stress level of the signal."</span>,</span>
<span id="cb25-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Measures irregularity or disorder, often increasing with non-uniform degradation."</span>,</span>
<span id="cb25-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Compares peak magnitude to average signal level, highlighting abnormal peaks."</span>,</span>
<span id="cb25-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Captures cumulative effects such as total energy loss or degradation trends."</span></span>
<span id="cb25-21">    ]</span>
<span id="cb25-22">})</span></code></pre></div></div>
</details>
</div>
<div id="37" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1">table <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb26-2">    GT(data)</span>
<span id="cb26-3">    .tab_header(</span>
<span id="cb26-4">        title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Statistical Features for Battery Degradation Modeling"</span>),</span>
<span id="cb26-5">        subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Key signal processing metrics used to quantify degradation patterns"</span></span>
<span id="cb26-6">    )</span>
<span id="cb26-7">    .cols_label(</span>
<span id="cb26-8">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>{</span>
<span id="cb26-9">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Statistical Feature"</span>: md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**Statistical Feature**"</span>),</span>
<span id="cb26-10">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Role in Degradation Modeling"</span>: md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**Role in Degradation Modeling**"</span>)</span>
<span id="cb26-11">        }</span>
<span id="cb26-12">    )</span>
<span id="cb26-13">    .tab_options(</span>
<span id="cb26-14">        table_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>,</span>
<span id="cb26-15">        container_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>,</span>
<span id="cb26-16">        table_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"14px"</span>,</span>
<span id="cb26-17">        heading_title_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"18px"</span>,</span>
<span id="cb26-18">        heading_subtitle_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"14px"</span>,</span>
<span id="cb26-19">        column_labels_border_bottom_style<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"solid"</span>,</span>
<span id="cb26-20">        column_labels_border_bottom_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"3px"</span>,</span>
<span id="cb26-21">        column_labels_border_bottom_color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#3498db"</span>,</span>
<span id="cb26-22">        table_body_border_bottom_style<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"solid"</span>,</span>
<span id="cb26-23">        table_body_border_bottom_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1px"</span>,</span>
<span id="cb26-24">        table_body_border_bottom_color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#dee2e6"</span></span>
<span id="cb26-25">    )</span>
<span id="cb26-26">    .tab_source_note(</span>
<span id="cb26-27">        source_note<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Bayesian Modelling|Anthony Faustine@ 2025"</span></span>
<span id="cb26-28">    )</span>
<span id="cb26-29">)</span>
<span id="cb26-30"></span>
<span id="cb26-31">table.show()</span></code></pre></div></div>
</details>
</div>
<p>These statistical summaries form the input vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> in the linear predictor <img src="https://latex.codecogs.com/png.latex?%5Ceta_i%20=%20%5Cdots%20+%20%5Cmathbf%7Bx%7D_i%5E%7B%5Ctop%7D%20%5Cboldsymbol%7B%5Cbeta%7D">. Such summaries of early-cycle behavior often preserve key degradation signatures while significantly reducing model complexity.</p>
</section>
<section id="feature-selection" class="level4">
<h4 class="anchored" data-anchor-id="feature-selection">Feature selection</h4>
<p>After extracting a broad set of diagnostic and statistical features, feature selection is required. Using all available features can lead to overfitting, increased model complexity, and multicollinearity, which compromises interpretability of the Bayesian coefficients (<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D">). The final four features selected for regression (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">) are:</p>
<ul>
<li>charge_current_auc</li>
<li>charge_current_mean</li>
<li>discharge_voltage_auc</li>
<li>discharge_voltage_crest</li>
</ul>
</section>
<section id="load-pre-processed-calce-dataset" class="level4">
<h4 class="anchored" data-anchor-id="load-pre-processed-calce-dataset">Load pre-processed CALCE dataset</h4>
<p>The raw CALCE dataset is a widely used public resource in battery prognostics and can be downloaded via the <a href="https://ieee-dataport.org/documents/calce-battery-group">CALCE dataset link</a>.</p>
<p>For this notebook, however, we use pre-processed data that has been cleaned and formatted. This pre-processing reuses the techniques and codes originally published in this paper <a href="https://www.nature.com/articles/s42256-024-00972-x#citeas">Ref</a>. Using the cleaned data allows us to focus immediately on the Bayesian modeling aspects without the overhead of complex data preparation</p>
<div id="41" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1">FIGSHARE_DOWNLOAD_URL <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://ndownloader.figshare.com/files/59415941"</span></span>
<span id="cb27-2">features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"charge_current_auc"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"charge_current_mean"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"discharge_voltage_crest"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"discharge_voltage_auc"</span>]</span>
<span id="cb27-3">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"capacity"</span></span>
<span id="cb27-4">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_parquet(FIGSHARE_DOWNLOAD_URL, engine<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pyarrow"</span>)</span>
<span id="cb27-5">upper_bound, lower_bound <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[target].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(), data[target].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>()</span>
<span id="cb27-6">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[data.CellType <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CS2"</span>].copy()</span>
<span id="cb27-7">test_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df.BatteryID <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CALCE_CS2_38"</span>]</span>
<span id="cb27-8">train_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df.BatteryID <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CALCE_CS2_38"</span>]</span></code></pre></div></div>
</details>
</div>
<div id="42" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1">plots <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb28-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> feature_name <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> features:</span>
<span id="cb28-3">    plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scatter_plot(train_df, y_col<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>feature_name)</span>
<span id="cb28-4">    plots.append(plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> labs(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>feature_name) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> modern_theme(font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>))</span>
<span id="cb28-5"></span>
<span id="cb28-6">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>gggrid(plots, ncol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ggsize(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">650</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">450</span>)</span></code></pre></div></div>
</details>
</div>
<div id="43" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1">plot</span></code></pre></div></div>
</details>
</div>
<p>The figure below plots the four selected features against cycle number for a representative battery. These plots empirically validate the selection process, as all four features exhibit clear, monotonic changes with cycling and, critically, show a distinct shift or acceleration in slope as the battery enters the failure state (<img src="https://latex.codecogs.com/png.latex?%5Ctext%7BSoH%7D%20%5Cle%2080%5C%25">, shown in green). This strong visual correlation provides high confidence that these inputs will effectively drive the degradation component of our Bayesian model.</p>
</section>
</section>
<section id="bayesian-model-building" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-model-building">Bayesian model building</h3>
<p>Before constructing the Bayesian Beta regression model, it is necessary to define a rigorous evaluation strategy. The central question addressed here is whether a model trained on data from a single battery can successfully generalize to other batteries whose degradation trajectories were not observed during training.</p>
<p>This setting reflects a common real-world scenario in which detailed historical data may be available for only a limited number of prototype units, while the deployed model must operate reliably across an entire manufacturing batch.</p>
<p>To ensure a fair and controlled evaluation, all batteries considered in this study are restricted to a single cell chemistry type (‚ÄúCS2‚Äù). By holding the underlying electrochemical properties constant, the analysis isolates unit-to-unit variability rather than confounding the results with chemistry-dependent effects.</p>
<p>A one-shot generalization split is employed. A single representative battery (CALCE_CS2_38) is designated as the training set (train_df). The model learns the degradation rate (<img src="https://latex.codecogs.com/png.latex?%5Clambda">) and operational sensitivities (<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D">) exclusively from this unit‚Äôs historical data. All remaining batteries of the same chemistry are assigned to the test set (test_df). Model performance is therefore evaluated based on its ability to predict capacity fade for previously unseen batteries using only the generalizable parameters inferred from the training unit.</p>
<p>With the input data rigorously cleaned, aligned, scaled, and reduced to the four most informative operational features (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">), the Bayesian regression model can now be implemented and fitted. As defined in the Beta Likelihood and Priors subsection, the model is specified as a Bayesian Beta regression with a logit link function, enabling the modeling of bounded battery capacity (<img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BC%7D">).</p>
<div id="47" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># from bayes.regression.beta_degradation import beta_regression_model</span></span>
<span id="cb30-2">model, scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> beta_regression_model(</span>
<span id="cb30-3">    train_df, features, target<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>target, upper_bound<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>upper_bound, lower_bound<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lower_bound</span>
<span id="cb30-4">)</span>
<span id="cb30-5">model</span></code></pre></div></div>
</details>
</div>
<section id="prior-predictive-check" class="level4">
<h4 class="anchored" data-anchor-id="prior-predictive-check">Prior Predictive Check</h4>
<p>Following standard Bayesian practice, model validation begins with a Prior Predictive Check (PPC). The PPC involves simulating data from the model using only the prior distributions, without conditioning on any observed measurements. This procedure serves as a critical sanity check, verifying that the encoded engineering knowledge produces physically plausible behavior.</p>
<div id="49" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> model:</span>
<span id="cb31-2">    prior_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample_prior_predictive(samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb31-3"></span>
<span id="cb31-4">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.8</span>))</span>
<span id="cb31-5">az.plot_ppc(prior_pred, group<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prior"</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax)</span>
<span id="cb31-6">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Capacity"</span>)</span>
<span id="cb31-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Density"</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div></div>
</details>
</div>
<p>The figure below, compare the predicted prior distribution (green line) against the observed data (blue line). This plot is essential for validating that our model‚Äôs structural assumptions align with physical reality</p>
<div id="51" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1">y_prior <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prior_pred.prior[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"capacity_pred"</span>].stack(sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"draw"</span>]).values</span>
<span id="cb32-2">y_obs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_df[target].values</span>
<span id="cb32-3">post_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_prior.mean()</span>
<span id="cb32-4">n_draws <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span></span>
<span id="cb32-5">rng <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.default_rng(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb32-6">draw_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rng.choice(y_prior.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_draws, replace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb32-7">y_prior_subset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_prior[:, draw_idx].flatten()</span>
<span id="cb32-8">df_prior <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb32-9">    {</span>
<span id="cb32-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SoH"</span>: np.concatenate([y_obs, y_prior_subset]),</span>
<span id="cb32-11">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"observed"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y_obs) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prior"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y_prior_subset),</span>
<span id="cb32-12">    }</span>
<span id="cb32-13">)</span>
<span id="cb32-14">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot_density(</span>
<span id="cb32-15">    df_prior,</span>
<span id="cb32-16">    x_col<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SoH"</span>,</span>
<span id="cb32-17">    color_col<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>,</span>
<span id="cb32-18">    x_label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Capacity"</span>,</span>
<span id="cb32-19">    fig_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>),</span>
<span id="cb32-20">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prior comparison"</span>,</span>
<span id="cb32-21">    subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prior Predictive Check"</span>,</span>
<span id="cb32-22">)</span></code></pre></div></div>
</details>
</div>
<div id="52" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1">plot</span></code></pre></div></div>
</details>
</div>
<p>From the two figures above, the PPC confirms the structural validity of the model:</p>
<ul>
<li><p>High-Confidence Initial Capacity: The predicted capacity distribution exhibits a dominant peak near <img src="https://latex.codecogs.com/png.latex?%5Cmu%20%5Capprox%201.0">, reflecting the highly informative precision prior <img src="https://latex.codecogs.com/png.latex?%5Cphi%20%5Csim%20%5Ctext%7BGamma%7D(100,%202.0)"> (mean <img src="https://latex.codecogs.com/png.latex?%5Cphi%20=%2050">). This enforces a strong prior belief in low sensor noise and high initial measurement confidence.</p></li>
<li><p>Realistic Degradation Envelope: The prior predictive distribution remains tightly constrained across the capacity range. This behavior is driven by the informative degradation-rate prior on <img src="https://latex.codecogs.com/png.latex?%5Clambda">, which minimizes the probability of immediate or catastrophic capacity loss and enforces physically plausible degradation trajectories.</p></li>
<li><p>Acknowledgment of Failure Modes: While constrained, the prior allocates non-negligible probability mass to lower capacity regions (e.g., <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BC%7D%20%5Capprox%200.4">‚Äì<img src="https://latex.codecogs.com/png.latex?0.7">). This reflects uncertainty in the degradation amplitude and rate parameters, allowing for degradation and failure scenarios without overstating their likelihood.</p></li>
</ul>
<p>The PPC demonstrates that the model respects physical bounds, reflects realistic degradation behavior, and balances strong prior knowledge with controlled uncertainty. The model is therefore suitable for posterior inference.</p>
</section>
</section>
<section id="running-inference" class="level3">
<h3 class="anchored" data-anchor-id="running-inference">Running inference</h3>
<p>With the model fully specified, priors validated through the PPC, and input features prepared, posterior inference is performed using Markov Chain Monte Carlo (MCMC) sampling. This step approximates the posterior distribution by updating prior beliefs using the observed data, forming the core of Bayesian inference.</p>
<div id="55" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> model:</span>
<span id="cb34-2">    idata <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span>, tune<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span>, target_accept<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>, random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb34-3">clear_output()</span></code></pre></div></div>
</details>
</div>
<p>As discussed in <a href="https://sambaiga.github.io/blog/2025/10/bayesian-modelling-01.html">Part 1</a>, the MCMC process uses the No-U-Turn Sampler (NUTS) to explore the parameter space. The primary arguments guide this process:</p>
<ul>
<li>tune=2000: Specifies 2000 initial samples that are used solely to adapt the sampler‚Äôs step size and are then discarded. A high tuning value is crucial for complex, highly curved posteriors (like those involving Beta distributions) to ensure stable exploration.</li>
<li>draws=2000: Specifies 2000 final samples kept from the chain. These collected samples form the final Posterior Distribution for every model parameter (<img src="https://latex.codecogs.com/png.latex?%5Clambda">, <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, <img src="https://latex.codecogs.com/png.latex?%5Cphi">).</li>
<li>target_accept=0.95: Forces the sampler to take smaller, more cautious steps. This high acceptance rate is necessary to avoid divergences in challenging models, ensuring a high-quality, accurate representation of the posterior distribution, though it increases computation time.</li>
</ul>
<p>The resulting idata object now contains thousands of samples for every single model parameter, representing our comprehensive, uncertainty-quantified solution. The next step is to ensure these samples are reliable</p>
<section id="model-diagnostics" class="level4">
<h4 class="anchored" data-anchor-id="model-diagnostics">Model diagnostics</h4>
<p>After sampling, convergence diagnostics are evaluated to ensure the reliability of posterior estimates. The validity of all subsequent inferences depends on whether the Markov chains have adequately explored the parameter space.</p>
<div id="58" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">vars</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beta"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"intercept"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lambda_rate"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"phi"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"degr_amp"</span>]</span>
<span id="cb35-2">data_summary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> az.summary(idata, var_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">vars</span>, kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"diagnostics"</span>)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ess_bulk"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ess_tail"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"r_hat"</span>]]</span>
<span id="cb35-3">GT(data_summary.reset_index()).tab_header(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>, subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Diagnostics Summary"</span>).cols_label(</span>
<span id="cb35-4">    {</span>
<span id="cb35-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ess_bulk"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ESS Bulk"</span>,</span>
<span id="cb35-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ess_tail"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ESS Tail."</span>,</span>
<span id="cb35-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"r_hat"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R-hat"</span>,</span>
<span id="cb35-8">    }</span>
<span id="cb35-9">)</span></code></pre></div></div>
</details>
</div>
<p>Two primary diagnostics are considered:</p>
<ol type="1">
<li><p><img src="https://latex.codecogs.com/png.latex?%5Chat%7BR%7D"> (Gelman‚ÄìRubin statistic): All parameters exhibit <img src="https://latex.codecogs.com/png.latex?%5Chat%7BR%7D%20=%201.0">, indicating excellent chain mixing and agreement across chains.</p></li>
<li><p>Effective Sample Size (ESS): ESS values exceed 400 for all parameters (ranging from approximately 4,200 to 7,300), confirming that a sufficient number of independent samples were obtained for stable estimation of posterior means and credible intervals.</p></li>
</ol>
<p>These diagnostics collectively indicate successful convergence and robust posterior sampling.</p>
</section>
<section id="analysing-the-posterior-distribution" class="level4">
<h4 class="anchored" data-anchor-id="analysing-the-posterior-distribution">Analysing the posterior distribution</h4>
<p>With convergence confirmed, the sampled chains provide a reliable approximation of the posterior distribution. The marginal posterior densities and corresponding trace plots for the core model parameters are examined to quantify degradation dynamics and assess the influence of operational features.</p>
<p>This analysis enables principled uncertainty quantification of degradation rates and feature effects, supporting interpretable and decision-relevant predictions for battery health forecasting.</p>
<div id="61" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1">az.plot_trace(idata, var_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">vars</span>, compact<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div></div>
</details>
</div>
<p>The <code>analyze_parameter</code> function below acts as a post-processing utility dedicated to generating publication-ready summary tables from the output of the MCMC sampling.</p>
<div id="63" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> analyze_parameter(</span>
<span id="cb37-2">    idata,</span>
<span id="cb37-3">    parameter: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>,</span>
<span id="cb37-4">    features: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb37-5">    hdi_prob: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>,</span>
<span id="cb37-6">    title: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Parameter Summary"</span>,</span>
<span id="cb37-7">    subtitle: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb37-8">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> GT:</span>
<span id="cb37-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Generates a formatted summary table for a single parameter using Great Tables.</span></span>
<span id="cb37-10"></span>
<span id="cb37-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function extracts posterior summary statistics from ArviZ InferenceData and</span></span>
<span id="cb37-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    returns a beautifully styled table suitable for reports, notebooks, or publications.</span></span>
<span id="cb37-13"></span>
<span id="cb37-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb37-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        idata: ArviZ InferenceData object containing posterior samples.</span></span>
<span id="cb37-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        parameter: Name of the parameter to summarize (e.g., "beta", "alpha", "sigma").</span></span>
<span id="cb37-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        features: List of feature names to label rows. Required and used only when</span></span>
<span id="cb37-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            ``parameter == "beta"``. Length must match the number of coefficients.</span></span>
<span id="cb37-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        hdi_prob: Highest density interval probability (default: 0.95).</span></span>
<span id="cb37-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        title: Main title for the table.</span></span>
<span id="cb37-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        subtitle: Optional subtitle. If None and parameter is "beta", defaults to</span></span>
<span id="cb37-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            "Beta coefficient analysis".</span></span>
<span id="cb37-23"></span>
<span id="cb37-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb37-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        A Great Tables (GT) object ready for display or further customization.</span></span>
<span id="cb37-26"></span>
<span id="cb37-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Raises:</span></span>
<span id="cb37-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        ValueError: If ``features`` is provided for non-beta parameters or has wrong length.</span></span>
<span id="cb37-29"></span>
<span id="cb37-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Example:</span></span>
<span id="cb37-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        &gt;&gt;&gt; gt = analyze_parameter(idata, "beta", features=X.columns.tolist())</span></span>
<span id="cb37-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        &gt;&gt;&gt; gt  # displays nicely in Jupyter</span></span>
<span id="cb37-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb37-34">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> features <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> parameter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beta"</span>:</span>
<span id="cb37-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"`features` should only be provided when parameter == 'beta'"</span>)</span>
<span id="cb37-36"></span>
<span id="cb37-37">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get summary statistics from ArviZ</span></span>
<span id="cb37-38">    summary_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> az.summary(</span>
<span id="cb37-39">        idata,</span>
<span id="cb37-40">        var_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[parameter],</span>
<span id="cb37-41">        hdi_prob<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hdi_prob,</span>
<span id="cb37-42">        kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stats"</span>,</span>
<span id="cb37-43">        fmt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"wide"</span>,</span>
<span id="cb37-44">    ).reset_index(names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"feature"</span>)</span>
<span id="cb37-45"></span>
<span id="cb37-46">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign meaningful feature names for beta coefficients</span></span>
<span id="cb37-47">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> parameter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beta"</span>:</span>
<span id="cb37-48">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> features <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb37-49">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"`features` must be provided when analyzing 'beta' parameter"</span>)</span>
<span id="cb37-50">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(features) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(summary_df):</span>
<span id="cb37-51">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(</span>
<span id="cb37-52">                <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Length of features (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(features)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">) must equal number of beta coefficients (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(summary_df)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span></span>
<span id="cb37-53">            )</span>
<span id="cb37-54">        summary_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"feature"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> features</span>
<span id="cb37-55"></span>
<span id="cb37-56">    conditions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb37-57">        summary_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_2.5%"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Entire interval is positive</span></span>
<span id="cb37-58">        summary_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_97.5%"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Entire interval is negative</span></span>
<span id="cb37-59">    ]</span>
<span id="cb37-60">    choices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Positive"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Negative"</span>]</span>
<span id="cb37-61">    summary_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"certainty"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.select(conditions, choices, default<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Uncertain"</span>)</span>
<span id="cb37-62"></span>
<span id="cb37-63">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set default subtitle for beta coefficients</span></span>
<span id="cb37-64">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> subtitle <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> parameter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beta"</span>:</span>
<span id="cb37-65">        subtitle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Beta coefficient analysis"</span></span>
<span id="cb37-66"></span>
<span id="cb37-67">    gt_table <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb37-68">        GT(summary_df)</span>
<span id="cb37-69">        .tab_header(</span>
<span id="cb37-70">            title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>md(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"**</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>title<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">**"</span>),</span>
<span id="cb37-71">            subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>md(subtitle) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> subtitle <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb37-72">        )</span>
<span id="cb37-73">        .fmt_number(</span>
<span id="cb37-74">            columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sd"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_2.5%"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_97.5%"</span>],</span>
<span id="cb37-75">            decimals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="cb37-76">        )</span>
<span id="cb37-77">        .data_color(</span>
<span id="cb37-78">            columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"certainty"</span>],</span>
<span id="cb37-79">            palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#E1DFDD"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#F18F01"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#F18F01"</span>],</span>
<span id="cb37-80">            domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Uncertain"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Negative"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Positive"</span>],</span>
<span id="cb37-81">        )</span>
<span id="cb37-82">        .cols_label(</span>
<span id="cb37-83">            feature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**Feature**"</span>),</span>
<span id="cb37-84">            mean<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**Mean**"</span>),</span>
<span id="cb37-85">            sd<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**SD**"</span>),</span>
<span id="cb37-86">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_2.5%"</span>: md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**HDI 2.5%**"</span>)},</span>
<span id="cb37-87">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_97.5%"</span>: md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"**HDI 97.5%**"</span>)},</span>
<span id="cb37-88">        )</span>
<span id="cb37-89">        .cols_align(align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"center"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sd"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_2.5%"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_97.5%"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Certainty"</span>])</span>
<span id="cb37-90">        .tab_options(</span>
<span id="cb37-91">            table_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"14px"</span>,</span>
<span id="cb37-92">            heading_title_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20px"</span>,</span>
<span id="cb37-93">            heading_subtitle_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"16px"</span>,</span>
<span id="cb37-94">            row_group_font_weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bold"</span>,</span>
<span id="cb37-95">        )</span>
<span id="cb37-96">    )</span>
<span id="cb37-97"></span>
<span id="cb37-98">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> gt_table</span></code></pre></div></div>
</details>
</div>
</section>
<section id="identifying-reliable-degradation-drivers-boldsymbolbeta-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="identifying-reliable-degradation-drivers-boldsymbolbeta-coefficients">Identifying Reliable Degradation Drivers (<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D"> Coefficients)</h4>
<p>The regression coefficients <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D"> quantify the relationship between the engineered operational features (e.g., current and voltage metrics) and battery State of Health (<img src="https://latex.codecogs.com/png.latex?%5Ctext%7BSoH%7D">) through the logit link function, <img src="https://latex.codecogs.com/png.latex?%5Clog%5Cleft(%5Cfrac%7B%5Cmu%7D%7B1-%5Cmu%7D%5Cright)">. The credibility of each predictor is assessed by examining whether its <img src="https://latex.codecogs.com/png.latex?95%25"> Highest Density Interval (HDI) includes zero.</p>
<div id="65" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1">table<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>analyze_parameter(idata, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beta"</span>, features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>features)</span></code></pre></div></div>
</details>
</div>
<div id="66" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1">table</span></code></pre></div></div>
</details>
</div>
<p>The posterior summary indicates that only one feature emerges as a statistically reliable degradation driver at the <img src="https://latex.codecogs.com/png.latex?95%25"> credibility level: the discharge_voltage_crest factor. Its <img src="https://latex.codecogs.com/png.latex?95%25"> HDI lies entirely below zero (from <img src="https://latex.codecogs.com/png.latex?-0.528"> to <img src="https://latex.codecogs.com/png.latex?-0.369">), indicating strong evidence of a negative association with capacity retention. This result implies, with high certainty, that increases in this factor accelerate capacity fade. The posterior mean coefficient for the discharge_voltage_crest factor is <img src="https://latex.codecogs.com/png.latex?%5Cbeta%20=%20-0.446">. Interpreted on the odds scale as <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BOdds%20Ratio%7D%20=%20%5Cexp(-0.446)%20%5Capprox%200.64">.</p>
<p>Thus, a one-unit increase in the crest factor is associated with an approximately <img src="https://latex.codecogs.com/png.latex?36%25"> reduction in the odds of maintaining high battery capacity (<img src="https://latex.codecogs.com/png.latex?1%20-%200.64">).</p>
<p>In contrast, the <img src="https://latex.codecogs.com/png.latex?95%25"> HDIs for the remaining three features include zero (e.g., for charge_current_auc, HDI <img src="https://latex.codecogs.com/png.latex?%5B-0.437,,0.132%5D">). As a result, the model cannot rule out the possibility that their true effects are negligible or even slightly positive. These features therefore do not constitute statistically reliable degradation drivers under the current model specification. Consequently, maintenance and monitoring efforts can be focused on the discharge_voltage_crest factor as the dominant operational indicator of degradation.</p>
<blockquote class="blockquote">
<p><strong>üõ†Ô∏è Action</strong>: Refit the Beta regression model using only the discharge_voltage_crest factor as an operational covariate. Evaluate whether predictive performance on the test set remains comparable and whether the posterior mean and HDI for this coefficient remain stable. Such consistency would further support the conclusion that the remaining features primarily contributed noise rather than explanatory signal.</p>
</blockquote>
</section>
<section id="quantifying-the-degradation-rate-lambda_textrate" class="level4">
<h4 class="anchored" data-anchor-id="quantifying-the-degradation-rate-lambda_textrate">Quantifying the degradation rate (<img src="https://latex.codecogs.com/png.latex?%5Clambda_%7B%5Ctext%7Brate%7D%7D">)</h4>
<p>The parameter <img src="https://latex.codecogs.com/png.latex?%5Clambda_%7B%5Ctext%7Brate%7D%7D"> governs the speed of capacity fade induced by cycling. By adopting a weakly informative Lognormal prior with increased dispersion (<img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%201.0">), the data is allowed to dominate the posterior estimation of this parameter.</p>
<div id="69" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1">table<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>analyze_parameter(idata, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lambda_rate"</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Lambda Rate Summary"</span>, subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Degradation rate parameter"</span>)</span></code></pre></div></div>
</details>
</div>
<div id="70" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1">table</span></code></pre></div></div>
</details>
</div>
<p>The posterior summary yields a highly precise estimate of the degradation rate, with a posterior mean of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0.003%7D"> per unit of cycle data. This value is lower than the prior expectation (centered around <img src="https://latex.codecogs.com/png.latex?0.005">), indicating that although degradation is inevitable, it progresses more gradually than initially assumed.</p>
<p>The remaining uncertainty is minimal, as evidenced by a small posterior standard deviation (<img src="https://latex.codecogs.com/png.latex?%5Ctext%7BSD%7D%20=%200.001">) and a narrow <img src="https://latex.codecogs.com/png.latex?95%25"> HDI of <img src="https://latex.codecogs.com/png.latex?%5B0.002,,0.004%5D">. These results confirm that the MCMC sampler has effectively leveraged the data to tightly constrain the degradation speed.</p>
</section>
<section id="model-precision-phi" class="level4">
<h4 class="anchored" data-anchor-id="model-precision-phi">Model precision (<img src="https://latex.codecogs.com/png.latex?%5Cphi">)</h4>
<p>The precision parameter <img src="https://latex.codecogs.com/png.latex?%5Cphi"> controls the dispersion of the Beta likelihood, quantifying how tightly the observed <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BSoH%7D"> measurements cluster around the model-predicted mean after accounting for all modeled effects.</p>
<div id="73" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1">table<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>analyze_parameter(idata, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"phi"</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Phi Summary"</span>, subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Phi  parameter"</span>)</span></code></pre></div></div>
</details>
</div>
<div id="74" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1">table</span></code></pre></div></div>
</details>
</div>
<p>The posterior distribution of <img src="https://latex.codecogs.com/png.latex?%5Cphi"> exhibits a high degree of concentration, with a posterior mean of <img src="https://latex.codecogs.com/png.latex?233.461"> and a narrow <img src="https://latex.codecogs.com/png.latex?95%25"> HDI. This large mean precision implies very low residual variance in <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BSoH%7D">, indicating that the combined model structure‚Äîincorporating the exponential degradation term, the cycling rate <img src="https://latex.codecogs.com/png.latex?%5Clambda">, and the operational features <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D"> explains the majority of observed variability across the battery fleet. The narrow HDI further indicates that this high precision is estimated with substantial certainty.</p>
<section id="degr-amp-parameter-a" class="level5">
<h5 class="anchored" data-anchor-id="degr-amp-parameter-a">Degr amp parameter (<img src="https://latex.codecogs.com/png.latex?A">)</h5>
<p>The degradation amplitude parameter, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdegr%5C_amp%7D">, quantifies the maximum potential capacity fade attributable solely to the cycling process and operates on the log-odds scale. The posterior mean of <img src="https://latex.codecogs.com/png.latex?0.367"> represents the maximum reduction in <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Blogit%7D(%5Cmu)"> induced by cycling over the battery‚Äôs lifetime, thereby determining the vertical extent of the degradation curve.</p>
<div id="77" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"></span>
<span id="cb44-2">table<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>analyze_parameter(idata, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"degr_amp"</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Degr amp"</span>, subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A  parameter"</span>)</span></code></pre></div></div>
</details>
</div>
<div id="78" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1">table</span></code></pre></div></div>
</details>
</div>
<p>The <img src="https://latex.codecogs.com/png.latex?95%25"> HDI for <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdegr%5C_amp%7D"> is narrow and entirely positive, spanning <img src="https://latex.codecogs.com/png.latex?%5B0.265,,0.468%5D">. This provides strong statistical evidence that degradation due to cycling is both certain and quantitatively well-defined, rather than an artifact of noise. The strictly positive support of this parameter confirms that capacity loss is an unavoidable consequence of repeated cycling.</p>
</section>
</section>
<section id="posterior-predictive-check" class="level4">
<h4 class="anchored" data-anchor-id="posterior-predictive-check">Posterior predictive check</h4>
<p>Following parameter interpretation, a Posterior Predictive Check (PPC) is performed to assess model adequacy. This step evaluates whether the model, using posterior parameter samples, can generate synthetic data that closely resembles the observed measurements.</p>
<p>Using PyMC‚Äôs <code>sample_posterior_predictive</code> function, samples are drawn from the likelihood conditioned on the converged posterior chains. The resulting PPC compares three distributions: the observed data, the prior predictive distribution, and the posterior predictive distribution.</p>
<div id="81" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> model:</span>
<span id="cb46-2">    post_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample_posterior_predictive(idata, var_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y_obs"</span>], random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb46-3"></span>
<span id="cb46-4">y_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> post_pred.posterior_predictive[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y_obs"</span>].stack(sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"draw"</span>]).values</span>
<span id="cb46-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Mean of the posterior predictive</span></span>
<span id="cb46-6">post_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_post.mean()</span>
<span id="cb46-7">n_draws <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span></span>
<span id="cb46-8">rng <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.default_rng(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb46-9">draw_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rng.choice(y_post.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_draws, replace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb46-10">y_post_subset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_post[:, draw_idx].flatten()</span>
<span id="cb46-11">y_post_subset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_post_subset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (upper_bound <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> lower_bound) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> lower_bound</span>
<span id="cb46-12"></span>
<span id="cb46-13"></span>
<span id="cb46-14">df_posterior <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb46-15">    {</span>
<span id="cb46-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SoH"</span>: np.concatenate([y_obs, y_post_subset]),</span>
<span id="cb46-17">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"observed"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y_obs) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"posterior"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y_post_subset),</span>
<span id="cb46-18">    }</span>
<span id="cb46-19">)</span></code></pre></div></div>
</details>
</div>
<p>The figure below shows a Posterior Predictive Check (PPC), which is the gold standard for evaluating model fit in Bayesian statistics. It compares three key distributions for the capacity: the data we observed, our initial beliefs (Prior), and the model‚Äôs final predictions (Posterior).</p>
<div id="83" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat([df_prior, df_posterior])</span>
<span id="cb47-2">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot_density(</span>
<span id="cb47-3">    df,</span>
<span id="cb47-4">    x_col<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SoH"</span>,</span>
<span id="cb47-5">    color_col<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>,</span>
<span id="cb47-6">    x_label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Capacity"</span>,</span>
<span id="cb47-7">    fig_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">700</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">350</span>),</span>
<span id="cb47-8">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prior and Posterior Comparison"</span>,</span>
<span id="cb47-9">    subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Beta-regression"</span>,</span>
<span id="cb47-10">)</span></code></pre></div></div>
</details>
</div>
<div id="84" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1">plot</span></code></pre></div></div>
</details>
</div>
<p>The posterior predictive distribution aligns closely with the observed capacity distribution, indicating that the model successfully captures the underlying data-generating process. In contrast, the prior predictive distribution is smoother and exhibits broader structure, reflecting weaker and less targeted assumptions before observing data.</p>
<p>The shift and sharpening from prior to posterior predictive distributions demonstrate that the observed data provided substantial information and that the model effectively updated its initial beliefs.</p>
<p>The posterior predictive distribution is strongly skewed toward high capacity values near <img src="https://latex.codecogs.com/png.latex?1.0">, consistent with the predominance of early- and mid-life measurements. A smaller secondary mode around <img src="https://latex.codecogs.com/png.latex?0.3">‚Äì<img src="https://latex.codecogs.com/png.latex?0.4"> corresponds to a limited number of end-of-life observations. This agreement between synthetic and observed data provides strong evidence of model adequacy and predictive reliability.</p>
</section>
</section>
<section id="predict-capacity-for-a-new-battery" class="level3">
<h3 class="anchored" data-anchor-id="predict-capacity-for-a-new-battery">Predict capacity for a new battery</h3>
<p>The final objective of this modeling effort is to transition from parameter estimation to practical prognosis by generating a full Posterior Predictive Distribution (PPD) for the capacity of a new or future battery state. This process converts uncertainty-aware parameter estimates into actionable prognostic predictions.</p>
<p>The PPD explicitly incorporates two fundamental sources of uncertainty:</p>
<ol type="1">
<li><p>Epistemic uncertainty, arising from uncertainty in the estimated model parameters (e.g., the width of the HDI for <img src="https://latex.codecogs.com/png.latex?%5Clambda_%7B%5Ctext%7Brate%7D%7D">).</p></li>
<li><p>Aleatoric uncertainty, representing irreducible noise in the measurement process, as captured by the precision parameter <img src="https://latex.codecogs.com/png.latex?%5Cphi">.</p></li>
</ol>
<p>As a result, the model produces not a single point estimate but a credible interval (HDI) that probabilistically bounds the true capacity value at each cycle.</p>
<p>To assess generalization performance and demonstrate practical utility for risk management, four cells from the CALCE dataset that were excluded during training are selected for evaluation. For each battery, the same four operational features used in model training are extracted and supplied to the fitted model.</p>
<div id="87" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> bayes.regression.beta_degradation <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_posterior_predictions</span></code></pre></div></div>
</details>
</div>
<div id="88" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1">new_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_df[test_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BatteryID"</span>].isin([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CALCE_CS2_34"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CALCE_CS2_36"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CALCE_CS2_37"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CALCE_CS2_33"</span>])].copy()</span></code></pre></div></div>
</details>
</div>
<p>Posterior predictions for unseen batteries are generated using the `<code>get_posterior_predictions</code> procedure, which applies the fitted Bayesian model to new input data. The process consists of the following steps:</p>
<ul>
<li><strong>Feature Transformation</strong>: The operational features of the new battery are transformed using the same scaling object fitted during training, ensuring consistency between training and inference domains. The corresponding cycle counts are extracted separately, as they directly enter the exponential degradation component of the model.</li>
<li></li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1">    x_new <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.transform(data[features])</span></code></pre></div></div>
<ul>
<li><strong>Dummy Target Initialization</strong>: A placeholder target array is supplied to satisfy the dimensional requirements of the PyMC model‚Äôs observed variable. These values are ignored during posterior prediction..</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1">    y_dummy_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.full(shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(X_new_scaled.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],), fill_value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span></code></pre></div></div>
<ul>
<li><strong>Model update</strong>: The new feature matrix, cycle data, and dummy target are injected into the model using pm.set_data, reconfiguring the model for prediction without retraining.</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> battery_model:</span>
<span id="cb53-2">        pm.set_data({</span>
<span id="cb53-3">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x_data"</span>: x_new,</span>
<span id="cb53-4">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cycle_data"</span>: cycle_new,</span>
<span id="cb53-5">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y_obs"</span>: y_dummy_scaled</span>
<span id="cb53-6">        })</span></code></pre></div></div>
<ul>
<li><strong>Posterior Predictive Sampling</strong>: Samples are drawn from the Posterior Predictive Distribution using <code>pm.sample_posterior_predictive</code>, incorporating both posterior parameter uncertainty and observation noise..</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> battery_model:</span>
<span id="cb54-2">        post_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample_posterior_predictive(</span>
<span id="cb54-3">            idata,</span>
<span id="cb54-4">            var_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y_obs"</span>],</span>
<span id="cb54-5">            random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>,</span>
<span id="cb54-6">            predictions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb54-7">        )</span></code></pre></div></div>
<div id="90" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1">pred_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_posterior_predictions(</span>
<span id="cb55-2">    idata, model, scaler, new_df, features, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, upper_bound<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>upper_bound, lower_bound<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lower_bound</span>
<span id="cb55-3">)</span>
<span id="cb55-4">clear_output()</span></code></pre></div></div>
</details>
</div>
<p>Predictions for each test battery are visualized using the plot_hdi_regression function. The plots display the observed capacity measurements (points) overlaid with the model‚Äôs posterior predictive mean and the corresponding <img src="https://latex.codecogs.com/png.latex?90%25"> HDI. The blue line represents the posterior predictive mean where the shaded region represents the <img src="https://latex.codecogs.com/png.latex?90%25"> HDI, quantifying predictive uncertainty.</p>
<div id="92" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> bayes.plot.regres_plot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_hdi_regression</span></code></pre></div></div>
</details>
</div>
<div id="93" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1">plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot_hdi_regression(</span>
<span id="cb57-2">    pred_df,</span>
<span id="cb57-3">    x_column<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cycle"</span>,</span>
<span id="cb57-4">    y_column<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"capacity"</span>,</span>
<span id="cb57-5">    group_column<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BatteryID"</span>,</span>
<span id="cb57-6">    pred_column<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pred_median"</span>,</span>
<span id="cb57-7">    x_label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cycle Number"</span>,</span>
<span id="cb57-8">    y_label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Capacity (Ah)"</span>,</span>
<span id="cb57-9">    title_prefix<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Battery Capacity vs. Cycle with Posterior Predictions"</span>,</span>
<span id="cb57-10">    subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"90% HDI accounts for  uncertainty."</span>,</span>
<span id="cb57-11">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb57-12">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ggsize(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">800</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>)</span></code></pre></div></div>
</details>
</div>
<div id="94" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1">plot</span></code></pre></div></div>
</details>
</div>
<p>Key Observations</p>
<ul>
<li><p>The posterior predictive mean closely tracks the observed capacity trajectory across the full battery lifetime, including the non-linear degradation phase near end-of-life.</p></li>
<li><p>Approximately <img src="https://latex.codecogs.com/png.latex?90%5C%25"> (or more) of observed data points fall within the predictive HDI, indicating well-calibrated uncertainty estimates.</p></li>
<li><p>For batteries CS2_33, CS2_36, and CS2_37, the HDI remains narrow even during late-life degradation, reflecting high model confidence and low residual noise.</p></li>
<li><p>For battery CS2_34, the HDI widens toward the final cycles, appropriately reflecting increased predictive uncertainty in the late-life regime.</p></li>
</ul>
<section id="evaluating-predictive-performance" class="level4">
<h4 class="anchored" data-anchor-id="evaluating-predictive-performance">Evaluating Predictive Performance</h4>
<p>Predictive performance on the held-out batteries is quantified using both accuracy and uncertainty-based metrics.</p>
<div id="97" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> bayes.metrics.interval <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_interval_metrics</span>
<span id="cb59-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> bayes.metrics.regression <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> regression_report</span>
<span id="cb59-3"></span>
<span id="cb59-4">metrics_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb59-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> battery_id, df <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> pred_df.groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BatteryID"</span>):</span>
<span id="cb59-6">    reg_report <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> regression_report(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"capacity"</span>], df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pred_median"</span>])</span>
<span id="cb59-7">    interval_report <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_interval_metrics(</span>
<span id="cb59-8">        df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pred_median"</span>].values,</span>
<span id="cb59-9">        df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"capacity"</span>].values,</span>
<span id="cb59-10">        df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_low"</span>].values,</span>
<span id="cb59-11">        df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hdi_high"</span>].values,</span>
<span id="cb59-12">        alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb59-13">    )</span>
<span id="cb59-14">    full_report <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat([reg_report, interval_report], ignore_index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb59-15">    full_report[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BatteryID"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> battery_id</span>
<span id="cb59-16">    metrics_list.append(full_report)</span>
<span id="cb59-17">metrics_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat(metrics_list, ignore_index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb59-18"></span>
<span id="cb59-19">metrics_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metrics_df.pivot_table(</span>
<span id="cb59-20">    index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BatteryID"</span>],</span>
<span id="cb59-21">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Metric"</span>,</span>
<span id="cb59-22">    values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Value"</span>,</span>
<span id="cb59-23">).reset_index()</span>
<span id="cb59-24"></span>
<span id="cb59-25"></span>
<span id="cb59-26"></span>
<span id="cb59-27"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> make_metrics_table(metrics_df, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model Evaluation Results"</span>):</span>
<span id="cb59-28">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Generate a formatted GT table from cross-validation metrics."""</span></span>
<span id="cb59-29">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sort to present best models first</span></span>
<span id="cb59-30">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metrics_df.sort_values([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BatteryID"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MAE"</span>]).reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb59-31"></span>
<span id="cb59-32">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Build base table</span></span>
<span id="cb59-33">    gt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb59-34">        GT(df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BatteryID"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MAE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RMSE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NMPI"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PICP"</span>]])</span>
<span id="cb59-35">        .tab_header(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>title, subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Per-battery performance"</span>)</span>
<span id="cb59-36">        .cols_label(BatteryID<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Test Cell"</span>, MAE<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MAE"</span>, RMSE<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RMSE"</span>, R2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>md(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R&lt;sup&gt;2&lt;/sup&gt;"</span>))</span>
<span id="cb59-37">        .fmt_number(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MAE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RMSE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NMPI"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PICP"</span>], decimals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb59-38">        .fmt_number(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R2"</span>, decimals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb59-39">        .tab_spanner(label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Error Metrics"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MAE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RMSE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NMPI"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PICP"</span>])</span>
<span id="cb59-40">        .tab_style(</span>
<span id="cb59-41">            style<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>style.text(weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bold"</span>),</span>
<span id="cb59-42">            locations<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>loc.body(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model"</span>),</span>
<span id="cb59-43">        )</span>
<span id="cb59-44">        .tab_options(</span>
<span id="cb59-45">            table_font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"small"</span>,</span>
<span id="cb59-46">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># row_strip_color="#fafafa"</span></span>
<span id="cb59-47">        )</span>
<span id="cb59-48">    )</span>
<span id="cb59-49">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> col <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MAE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RMSE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NMPI"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PICP"</span>]:</span>
<span id="cb59-50">        best_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[col].idxmax() <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> col <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PICP"</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> df[col].idxmin()</span>
<span id="cb59-51">        gt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gt.tab_style(style<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>style.fill(color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#E1DFDD"</span>), locations<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>loc.body(rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>best_idx, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>col))</span>
<span id="cb59-52"></span>
<span id="cb59-53">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> gt</span></code></pre></div></div>
</details>
</div>
<div id="98" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1">make_metrics_table(metrics_df, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model Evaluation Results"</span>)</span></code></pre></div></div>
</details>
</div>
<p><strong>Accuracy Metrics</strong></p>
<p>Point-prediction accuracy is evaluated using the coefficient of determination (<img src="https://latex.codecogs.com/png.latex?R%5E2">), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE). Together, these metrics assess how well the model‚Äôs posterior predictive mean captures the observed capacity degradation trajectory.</p>
<ul>
<li><p><img src="https://latex.codecogs.com/png.latex?R%5E2"> quantifies the proportion of variance in the observed capacity explained by the model. Values close to 1 indicate that the predicted degradation curve accurately follows the overall trend and slope of capacity fade.</p></li>
<li><p>MAE represents the average absolute deviation between predicted and observed capacity values, expressed in State-of-Health (SoH) units. MAE provides a physically interpretable measure of typical prediction error.</p></li>
<li><p>RMSE penalizes larger deviations more strongly than MAE and is therefore particularly sensitive to localized mismatches, especially during the highly nonlinear end-of-life degradation phase.</p></li>
</ul>
<p>From the results summarized above, the model achieves <img src="https://latex.codecogs.com/png.latex?R%5E2"> values between <img src="https://latex.codecogs.com/png.latex?0.910"> and <img src="https://latex.codecogs.com/png.latex?1.0">, with MAE in the range of <img src="https://latex.codecogs.com/png.latex?0.010">‚Äì<img src="https://latex.codecogs.com/png.latex?0.040"> SoH units, indicating strong point-prediction accuracy across all evaluated cells. RMSE values range from <img src="https://latex.codecogs.com/png.latex?0.01"> to <img src="https://latex.codecogs.com/png.latex?0.05"> SoH units, confirming that large deviations are generally rare.</p>
<p>However, Cell 34 exhibits the highest RMSE (<img src="https://latex.codecogs.com/png.latex?0.05">), along with comparatively lower <img src="https://latex.codecogs.com/png.latex?R%5E2"> and higher MAE than the remaining cells. This combination indicates that, while the model captures the overall degradation trend for Cell 34, it experiences larger localized errors‚Äîparticularly near late-life degradation relative to other cells. These deviations suggest the presence of sharper nonlinear behavior or cell-specific degradation mechanisms not fully represented by the global model parameters.</p>
<p><strong>Uncertainty Quality Metrics</strong></p>
<p>Beyond point accuracy, a central goal of Bayesian modeling is to provide reliable and interpretable uncertainty estimates. This is assessed using Prediction Interval Coverage Probability (PICP) and Normalized Mean Prediction Interval (NMPI).</p>
<ul>
<li><p>PICP measures the fraction of observed capacity values that fall within the model‚Äôs <img src="https://latex.codecogs.com/png.latex?90%25"> Highest Density Interval (HDI). A well-calibrated model should achieve PICP close to the nominal level (0.95), indicating that the predicted uncertainty accurately reflects real variability.</p></li>
<li><p>NMPI quantifies the average width of the predictive interval, normalized by the observed capacity range. NMPI reflects the sharpness of predictions: lower values indicate tighter uncertainty bounds, which are essential for actionable maintenance and risk-based decision-making.</p></li>
</ul>
<p>Results show consistently low NMPI values (approximately <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0.1%7D">) across all test cells. This confirms that the predictive intervals are narrow relative to the capacity range, indicating high confidence in the model‚Äôs predictions. At the same time, PICP exceeds <img src="https://latex.codecogs.com/png.latex?0.90"> for most cells, demonstrating that this confidence is not over-stated and that the uncertainty bounds are well calibrated.</p>
<p>Cell 34 again deviates from this pattern, exhibiting reduced PICP (<img src="https://latex.codecogs.com/png.latex?75%5C%25">). This indicates that a larger fraction of its observed capacity measurements fall outside the predicted <img src="https://latex.codecogs.com/png.latex?90%25"> HDI, suggesting either increased intrinsic variability or degradation dynamics that differ from those captured by the global model.</p>
<blockquote class="blockquote">
<p><strong>üõ†Ô∏è Action</strong>: To diagnose the degraded predictive performance observed for Cell 34, compare all test cells by plotting <img src="https://latex.codecogs.com/png.latex?R%5E2"> versus PICP to identify accuracy‚Äìreliability trade-offs. Examine whether Cell 34‚Äôs operational features fall outside the training-feature distribution, indicating extrapolation beyond the model‚Äôs learned domain. Finally, compare the capacity degradation distribution of Cell 34 with the training cell to assess whether it follows a distinct degradation regime.</p>
</blockquote>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>This post demonstrates that a single-level Bayesian Beta regression model, informed by physics-aware priors and carefully engineered features, can deliver highly accurate capacity predictions together with trustworthy uncertainty bounds. The model achieves near-perfect predictive accuracy while maintaining well-calibrated <img src="https://latex.codecogs.com/png.latex?95%25"> credible intervals, validating the use of Beta likelihoods and informed priors for battery degradation modeling.</p>
<p>However, the current formulation assumes that the degradation rate (<img src="https://latex.codecogs.com/png.latex?%5Clambda_%7B%5Ctext%7Brate%7D%7D">) and operational sensitivities (<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D">) are shared across the entire battery fleet. In practice, manufacturing variability and latent defects introduce unit-specific degradation behavior. As a result, even a highly accurate global model may underpredict risk for batteries from unfavorable batches or overestimate degradation for higher-quality units.</p>
<p><strong>Coming Next</strong>: In Part 3, this limitation will be addressed by introducing Hierarchical Bayesian Models. These models learn a robust global degradation trend while allowing each individual battery to exhibit informed local deviations in parameters such as <img src="https://latex.codecogs.com/png.latex?%5Clambda_%7B%5Ctext%7Brate%7D%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cbeta%7D">.</p>
<blockquote class="blockquote">
<p>The data and full code in <a href="https://www.pymc.io/welcome.html">pymc5</a> is available on my <a href="https://github.com/sambaiga/bayesian-modelling/blob/main/notebook/2025-12-1-bayesian-regression..ipynb">GITHUB</a> page.</p>
</blockquote>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ol type="1">
<li>Zhang, H., Li, Y., Zheng, S. et al.&nbsp;<a href="https://www.nature.com/articles/s42256-024-00972-x#citeas">Battery lifetime prediction across diverse ageing conditions with inter-cell deep learning</a>. Nat Mach Intell 7, 270‚Äì277 (2025). https://doi.org/10.1038/s42256-024-00972-x</li>
<li>Ferrari, S. L. P., &amp; Cribari-Neto, F. (2004). Beta regression for modelling rates and proportions. Journal of Applied Statistics, 31(7), 799‚Äì815.</li>
<li>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). CRC Press.</li>
<li>McElreath, R. (2020). Statistical Rethinking (2nd ed.). CRC Press.</li>
</ol>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{faustine2025,
  author = {Faustine, Anthony},
  title = {Bayesian {Regression:} {A} {Real-World} {Battery}
    {Degradation} {Case} {Study}},
  date = {2025-12-17},
  url = {https://sambaiga.github.io/pages/blog/posts/2025/12/2025-12-1-bayesian-regression..html},
  langid = {en}
}
</code></pre></div></section></div> ]]></description>
  <category>python</category>
  <category>bayesian</category>
  <guid>https://sambaiga.github.io/pages/blog/posts/2025/12/2025-12-1-bayesian-regression..html</guid>
  <pubDate>Wed, 17 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://sambaiga.github.io/pages/blog/posts/2025/12/posterior-comparison-1.png" medium="image" type="image/png" height="62" width="144"/>
</item>
<item>
  <title>Understanding Bayesian Thinking for Industrial Applications</title>
  <dc:creator>Anthony Faustine</dc:creator>
  <link>https://sambaiga.github.io/pages/blog/posts/2025/10/2025-10-10-bayesion-foundation.html</link>
  <description><![CDATA[ 





<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>A company has recently installed a new, expensive machine. A critical question arises: <em>How long will it last before failure</em>?. The lead engineer, drawing on experience with previous models, estimates a lifespan of approximately 10 years. However, only 3 months of real-world test data are available for this specific unit, and a major warranty and service contract decision must be made immediately.</p>
<p>This scenario exemplifies a common challenge in industrial applications: <strong>making informed decisions with limited data</strong>. Bayesian thinking offers a powerful framework to address such problems by combining prior knowledge with observed data to update our beliefs about uncertain parameters.</p>
<p>In this article, we will explore the fundamentals of Bayesian thinking and how it can be applied to industrial scenarios like the one described above. We will cover key concepts such as prior distributions, likelihood functions, and posterior distributions, and demonstrate how to implement Bayesian models using Python‚Äôs <a href="https://www.pymc.io/welcome.html">PyMC library</a>.</p>
<p>To immediately dive into the code and reproduce the models discussed in this article, you can use our accompanying resources:</p>
<ol type="1">
<li><p>Repository: Fork <a href="https://github.com/sambaiga/bayesian-modelling/tree/main">bayesian-modelling repository</a> and follow the setup instructions in the <a href="https://github.com/sambaiga/bayesian-modelling/tree/main">README.md</a> file.</p></li>
<li><p>Notebook: Launch <a href="https://github.com/sambaiga/bayesian-modelling/blob/main/notebook/bayesian-modelling-01.ipynb">the bayesian-modelling-01.ipynb</a> notebook located in the notebook folder to follow along step-by-step.</p></li>
</ol>
</section>
<section id="the-building-blocks-of-bayesian-modeling" class="level3">
<h3 class="anchored" data-anchor-id="the-building-blocks-of-bayesian-modeling">The Building Blocks of Bayesian modeling</h3>
<p>Traditional (Frequentist) statistics relies on large datasets the ‚Äúlong run‚Äù to produce confident conclusions, a limitation in industrial contexts where data are often sparse. New products, machines, or processes typically generate only small samples, while valuable expert knowledge such as an engineer‚Äôs lifespan estimate is excluded from conventional models.</p>
<p>Bayesian inference overcomes these issues by combining <strong>prior knowledge</strong> with <strong>new data</strong>, enabling faster and more informed decisions when information is limited. This integration of expertise and evidence defines Bayesian thinking.</p>
<p>The process of updating our beliefs is formalized by Bayes‚Äô Theorem. <img src="https://latex.codecogs.com/png.latex?%0AP(%5Ctheta%20%5Cmid%20D)%20=%20%5Cfrac%7BP(D%20%5Cmid%20%5Ctheta)%20P(%5Ctheta)%7D%7BP(D)%7D%0A"></p>
<p>While the formula looks mathematical, its components represent a beautifully intuitive learning cycle.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BPosterior%7D%20%5Cpropto%20%5Cmathrm%7BLikelihood%7D%20%5Ctimes%20%5Cmathrm%7BPrior%7D%0A"></p>
<p>Let us break down how this relates to our machine failure problem; where <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is the machine‚Äôs expected failure rate, and <img src="https://latex.codecogs.com/png.latex?D"> is the 3 months of test data.</p>
<section id="prior-likelihood-and-posterior" class="level4">
<h4 class="anchored" data-anchor-id="prior-likelihood-and-posterior">Prior, Likelihood, and Posterior</h4>
<ol type="1">
<li><p><strong>Prior</strong> <img src="https://latex.codecogs.com/png.latex?P(%5Ctheta)"> represents the initial belief before observing any data. It incorporates domain expertise and historical knowledge. For instance, historical records may indicate that similar machines have an average lifespan of approximately ten years, implying a low failure rate. This prior belief defines the starting point for ùúÉ <img src="https://latex.codecogs.com/png.latex?%5Ctheta">.</p></li>
<li><p><strong>Likelihood</strong> <img src="https://latex.codecogs.com/png.latex?P(D%20%5Cmid%20%5Ctheta)"> quantifies the compatibility between the observed data and a given parameter value. It expresses the probability of observing the test outcomes for different possible failure rates. In this context, the likelihood measures how probable it is to observe zero failures within three months if the true average lifespan were, for example, five or fifteen years.</p></li>
<li><p><strong>Posterior</strong> <img src="https://latex.codecogs.com/png.latex?P(%5Ctheta%20%5Cmid%20D)"> represents the updated belief after incorporating the observed data. It integrates prior knowledge with the evidence provided by the likelihood. In the machine-failure example, the posterior distribution expresses the updated estimate of expected lifespan after combining historical information (e.g., the ten-year prior) with the three months of failure-free operational data.</p></li>
</ol>
</section>
<section id="pymc-the-probabilistic-programming-engine" class="level4">
<h4 class="anchored" data-anchor-id="pymc-the-probabilistic-programming-engine">PyMC: The Probabilistic Programming Engine</h4>
<p>Understanding the relationship <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BPosterior%7D%20%5Cpropto%20%5Cmathrm%7BLikelihood%7D%20%5Ctimes%20%5Cmathrm%7BPrior%7D"> is the conceptual heart of Bayesian analysis. However, calculating the actual posterior distribution, <img src="https://latex.codecogs.com/png.latex?P(%5Ctheta%20%5Cmid%20D)">, often involves complex, multi-dimensional integration that is impossible to solve analytically for real-world industrial problems. This challenge is addressed through Probabilistic Programming Languages (PPLs) such as PyMC.</p>
<p><a href="https://www.pymc.io/welcome.html">PyMC</a> is an open-source Python library for constructing and fitting Bayesian statistical models using advanced computational algorithms, including Markov Chain Monte Carlo (MCMC) and variational inference. It is one of several modern PPLs available in Python, alongside <a href="https://pyro.ai/">Pyro</a> and <a href="https://www.tensorflow.org/probability">TensorFlow Probability (TFP)</a>. This tutorial focuses on PyMC due to its clarity, community support, and extensive documentation.</p>
</section>
</section>
<section id="case-study-ab-testing-with-small-samples" class="level3">
<h3 class="anchored" data-anchor-id="case-study-ab-testing-with-small-samples">Case study: A/B Testing with Small Samples</h3>
<p>To shift from theory to practical implementation, we will apply the Bayesian building blocks Prior, Likelihood, and Posterior to a concrete industrial problem common in tech and e-commerce: A/B Testing</p>
<blockquote class="blockquote">
<p>Suppose you are a data scientist at an e-commerce company. The marketing team just launched a new website feature and wants to know:</p>
</blockquote>
<ol type="1">
<li><p>What‚Äôs the true conversion rate?</p></li>
<li><p>Is it better than the old version (which historically has an 8% conversion rate)?</p></li>
<li><p>How much should we trust this estimate with limited data?</p></li>
</ol>
<blockquote class="blockquote">
<p>During the first few days of the feature launch, the company has observed 200 visitors with only 15 conversion.</p>
</blockquote>
<section id="library-imports" class="level4">
<h4 class="anchored" data-anchor-id="library-imports">Library Imports</h4>
<p>Import the required Python libraries for Bayesian modeling:</p>
<ul>
<li>NumPy for numerical computations</li>
<li>Pandas for data manipulation</li>
<li>PyMC for Bayesian statistical modeling</li>
<li>Matplotlib, arviz and altair for visualization</li>
</ul>
<div id="10" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#import libraries</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb1-3">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ignore"</span>, category<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">UserWarning</span>)</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pymc <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pm</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> arviz <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> az</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> clear_output</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> great_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GT</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-11">az.style.use(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arviz-white"</span>)</span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cycler <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cycler</span>
<span id="cb1-13">colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#107591'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f69a48'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#00c0bf'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#fdcd49'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#cf166e"</span>, </span>
<span id="cb1-14">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#7035b7"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#212121"</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#757575"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#E0E0E0"</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#FAFAFA"</span>]</span>
<span id="cb1-15">plt.rcParams.update({</span>
<span id="cb1-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"figure.dpi"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb1-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"axes.labelsize"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb1-18">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"axes.titlesize"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb1-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"figure.titlesize"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb1-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font.size"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb1-21">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"legend.fontsize"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb1-22">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"xtick.labelsize"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb1-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ytick.labelsize"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb1-24">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"axes.linewidth"</span> : <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,</span>
<span id="cb1-25">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lines.linewidth"</span> : <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>,</span>
<span id="cb1-26">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"legend.frameon"</span> :<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb1-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'axes.prop_cycle'</span>: cycler(color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors)</span>
<span id="cb1-28">        </span>
<span id="cb1-29">})</span>
<span id="cb1-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> altair </span>
<span id="cb1-31">altair.themes.enable(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'carbonwhite'</span>)</span>
<span id="cb1-32"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> altair <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> alt</span>
<span id="cb1-33">alt.data_transformers.enable(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'default'</span>, max_rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb1-34">clear_output()</span></code></pre></div></div>
</details>
</div>
<section id="define-key-variables-and-parameters" class="level5">
<h5 class="anchored" data-anchor-id="define-key-variables-and-parameters">Define key variables and parameters</h5>
<div id="12" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For reproducibility</span></span>
<span id="cb2-2">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># A/B Test Parameters</span></span>
<span id="cb2-5">visitors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span></span>
<span id="cb2-6">conversions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span></span>
<span id="cb2-7">observed_conversion_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conversions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> visitors</span>
<span id="cb2-8">historical_baseline <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.08</span></span></code></pre></div></div>
</details>
</div>
</section>
</section>
<section id="define-prior-likelihood-and-posterior-in-pymc" class="level4">
<h4 class="anchored" data-anchor-id="define-prior-likelihood-and-posterior-in-pymc">Define Prior, likelihood, and Posterior in PyMC</h4>
<p>To model this problem in PyMC, one must first define the Prior and Likelihood distributions</p>
<p><strong>Prior</strong>: Since the conversion rate <img src="https://latex.codecogs.com/png.latex?%5Ctheta">, can only range between 0 and 1. The Beta distribution is ideal for modeling parameters that are bounded between 0 and 1, such as probabilities or rates.</p>
<p>The Beta distribution is controlled by two parameters, <img src="https://latex.codecogs.com/png.latex?%5Calpha"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta">. hese parameters are set to formally encode the prior knowledge: the historical 8% conversion rate. The mean of a <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BBeta%7D(%5Calpha,%5Cbeta)"> distribution is <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Calpha%7D%7B%20%5Calpha%20+%20%5Cbeta%7D">. Since the historical rate is 8% (or 0.08), we need to choose <img src="https://latex.codecogs.com/png.latex?%5Calpha"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> such that: <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Calpha%7D%7B%20%5Calpha%20+%20%5Cbeta%7D%20=%200.08%0A"></p>
<p>To determine the strength of this belief, a number that represents the effective sample size (ESS) of the historical knowledge is chosen. Choosing a hypothetical ESS of 100 trials, we can solve for <img src="https://latex.codecogs.com/png.latex?%5Calpha"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta">: - ESS <img src="https://latex.codecogs.com/png.latex?=%20%5Calpha%20+%20%5Cbeta%20=%20100"> - <img src="https://latex.codecogs.com/png.latex?%5Calpha"> (hypothetical successes) <img src="https://latex.codecogs.com/png.latex?=100%C3%970.08=8"> - <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> (hypothetical failures) <img src="https://latex.codecogs.com/png.latex?=100%E2%88%928=92"></p>
<p><strong>Likelihood</strong> the Likelihood is determined by the process that generated the data. Since there is a fixed number of trials (N=200 visitors) and the number of successes (k=15 conversions) is counted, this is a Binomial distribution.</p>
<div id="14" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> conversion_model:</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prior distribution based on historical performance</span></span>
<span id="cb3-3">    conversion_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Beta(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"conversion_rate"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">92</span>)</span>
<span id="cb3-4">    </span>
<span id="cb3-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Likelihood function</span></span>
<span id="cb3-6">    likelihood <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Binomial(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"observations"</span>, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>visitors, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>conversion_rate, observed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>conversions)</span>
<span id="cb3-7">    </span>
<span id="cb3-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sample from posterior distribution</span></span>
<span id="cb3-9">    trace <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span>, tune<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, chains<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>, return_inferencedata<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-10"></span>
<span id="cb3-11">clear_output()</span></code></pre></div></div>
</details>
</div>
<p>This small block of code above defines and runs our entire Bayesian analysis. For those seeing PyMC for the first time, here is what each section is doing:</p>
<ol type="1">
<li><p><code>with pm.Model() as model:</code> This block acts as a container for all the random variables and data in our model. Everything inside this context belongs to the conversion_model</p></li>
<li><p><code>conversion_rate = pm.Beta(...)</code>: We are telling PyMC that the true conversion_rate is a random variable, and our initial belief is described by the Beta(8,92) distribution.</p></li>
<li><p><code>likelihood = pm.Binomial(...)</code>: This defines the process that generated our observed data. We link the conversion_rate parameter to the actual observed data (n=visitors, observed=conversions) using the appropriate Binomial distribution.</p></li>
<li><p><code>pm.sample(...)</code>: This is where the magic happens! The pm.sample function runs the MCMC sampler (the computational engine) to combine the Prior and the Likelihood, effectively calculating the Posterior distribution. We ask the sampler to draw 2000 samples after a 1000-sample tuning period, running 4 independent chains to ensure reliable results.</p></li>
</ol>
</section>
</section>
<section id="model-diagnostics" class="level3">
<h3 class="anchored" data-anchor-id="model-diagnostics">Model diagnostics</h3>
<p>Running <code>pm.sample()</code> generates the raw output, but the job isn‚Äôt done yet. Before we trust the results, we must perform Model Diagnostics to ensure our computational engine (the MCMC sampler) has worked correctly. The single most important diagnostic check is confirming Convergence.</p>
<section id="model-convergencevergence" class="level4">
<h4 class="anchored" data-anchor-id="model-convergencevergence">Model Convergencevergence</h4>
<p>In Bayesian inference, Markov Chain Monte Carlo (MCMC) methods are employed to sample from the complex posterior distribution. These samples are relied upon to accurately estimate quantities like the mean conversion rate or its credible interval.</p>
<p><strong>Convergence</strong> is the guarantee that the MCMC chains have explored the entire distribution and are now producing samples that truly represent the target Posterior distribution, and are not just stuck in a starting location.</p>
<blockquote class="blockquote">
<p><strong>Analogy</strong>: Imagine trying to understand the shape of a deep, misty valley (the posterior). If your chains haven‚Äôt converged, they might be stuck high up on a ridge, missing the true, deep center. Diagnostics are the tools we use to confirm the chains have found and are walking across the bottom of the true valley.</p>
</blockquote>
<p>PyMC uses the supporting library <a href="https://www.arviz.org/en/latest/">ArviZ</a> for standardizing and analyzing the results, which provides the following diagnostics and plots</p>
<ol type="1">
<li><p>Trace Plots: Visual inspection of parameter samples across iterations.</p>
<ul>
<li>Good trace plots look like <em>fuzzy caterpillars</em> with no trends or jumps.</li>
</ul></li>
<li><p>R-hat (Gelman-Rubin Statistic): Measures how well multiple chains agree.</p>
<ul>
<li>R-hat ‚âà 1 means convergence.</li>
<li>R-hat &gt; 1.01 suggests problems.</li>
</ul></li>
<li><p>Effective Sample Size (ESS): Indicates how many independent samples you effectively have.</p>
<ul>
<li>Low ESS means poor mixing or autocorrelation. Good ESS is typically &gt; 200 per parameter.</li>
</ul></li>
</ol>
<p>The most efficient way to check convergence numerically is using the ArviZ summary function, specifically asking for the diagnostics <code>az.summary(trace, kind="diagnostics")</code>. Alternatively, <code>az.plot_trace(trace)</code> can be used to get a visual sense of convergence.</p>
<section id="example-diagnostic-output" class="level5">
<h5 class="anchored" data-anchor-id="example-diagnostic-output">Example Diagnostic Output</h5>
<div id="20" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1">diag_table<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>az.summary(trace, kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"diagnostics"</span>)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ess_bulk'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ess_tail'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r_hat'</span>]]</span>
<span id="cb4-2">GT(diag_table).tab_header(</span>
<span id="cb4-3">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>,</span>
<span id="cb4-4">    subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Conversion Rate Model"</span></span>
<span id="cb4-5">).cols_label({</span>
<span id="cb4-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ess_bulk'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ESS Bulk'</span>,</span>
<span id="cb4-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ess_tail'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ESS Tail.'</span>,</span>
<span id="cb4-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r_hat'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'R-hat'</span>,</span>
<span id="cb4-9">    })</span></code></pre></div></div>
</details>
</div>
<p>This table immediately indicates that the model is reliable and ready for analysis</p>
<ul>
<li><p>(R_hat = 1.0,Goal Achieved): Since R_hat is exactly 1.0, this confirms that the four independent MCMC chains have fully converged and agree on the shape of the posterior distribution. The model is reliable.</p></li>
<li><p>ESS bulk ‚Äãand ESS tail (3966.0 and 5559.0, Goal Achieved): Both effective sample sizes are significantly greater than the ‚â•400 minimum threshold. This means there are plenty of high-quality, effectively independent samples to accurately estimate the mean, mode, and credible intervals of the true conversion rate.</p></li>
</ul>
<section id="visual-check-trace-plots" class="level6">
<h6 class="anchored" data-anchor-id="visual-check-trace-plots">Visual Check: Trace Plots</h6>
<p>While the numbers in the summary table are essential, visually inspecting the MCMC chains confirms the story.</p>
<div id="23" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1">az.plot_trace(trace)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div></div>
</details>
</div>
<p>The trace plot above shows excellent convergence for our conversion rate (<img src="https://latex.codecogs.com/png.latex?%5Ctheta">) model, supporting the conclusions from our quantitative diagnostics. The plot is split into two panels 1. Right Panel: MCMC Sampling Behavior</p>
<ul>
<li>This panel shows the raw sampled values across iterations for each of our four chains. The sampled values oscillate stably around ‚àº0.075 (7.5%) without any noticeable trends, sudden jumps, or long-term drifts.</li>
<li>The different lines (chains) are thoroughly intertwined and overlap completely. This ‚Äúfuzzy caterpillar‚Äù appearance is the visual proof that the sampler is efficiently exploring the parameter space and that all chains have converged to the same distribution.</li>
<li>The stable behavior confirms the chain has reached <strong>stationarity</strong>, meaning it is now sampling from the true, converged Posterior distribution.</li>
</ul>
<ol start="2" type="1">
<li><p>Left Panel: Posterior Distribution</p>
<ul>
<li>This panel shows the estimated Posterior probability density function (PDF) based on the samples. The shape is smooth and unimodal (single peak), indicating a well-behaved posterior without ambiguity.</li>
<li>The peak is clearly centered at a value close to our observed rate (7.5%), which is what we expect when combining a prior (8%) and data (7.5%).</li>
<li>The spread of the distribution clearly visualizes our remaining uncertainty about the true conversion rate.</li>
</ul></li>
</ol>
</section>
</section>
</section>
</section>
<section id="prior-predictive-checks-validating-model-assumptions" class="level3">
<h3 class="anchored" data-anchor-id="prior-predictive-checks-validating-model-assumptions">Prior Predictive Checks: Validating Model Assumptions</h3>
<p>While we have demonstrated that the convergence of the fitted model a complete Bayesian analysis requires us to first validate the assumptions we made before seeing any data (priors). This validation is accomplished through the Prior Predictive Check.</p>
<blockquote class="blockquote">
<p>Prior Predictive Checks helps validate the prior assumptions before fitting the model to data. It show what kind of data the model expects to generate based solely on the prior beliefs.</p>
</blockquote>
<div id="26" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> conversion_model:</span>
<span id="cb6-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prior distribution based on historical performance</span></span>
<span id="cb6-3">    conversion_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Beta(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"conversion_rate"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">92</span>)</span>
<span id="cb6-4">    </span>
<span id="cb6-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Likelihood function</span></span>
<span id="cb6-6">    likelihood <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Binomial(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"observations"</span>, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>visitors, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>conversion_rate, observed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>conversions)</span></code></pre></div></div>
</details>
</div>
<p>Given our prior belief of an 8% conversion rate, we can simulate what kind of data we would expect to see if this belief were true. This is done by generating synthetic datasets from the prior distribution and comparing them to the actual observed data. This is acomplished in PyMC by running <code>pm.sample_prior_predictive()</code> function.</p>
<div id="28" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> conversion_model:</span>
<span id="cb7-2">    prior_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample_prior_predictive()</span></code></pre></div></div>
</details>
</div>
<div id="29" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1">fig, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.8</span>))</span>
<span id="cb8-2">az.plot_ppc(prior_pred, group<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prior"</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax)</span>
<span id="cb8-3">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'conversions'</span>)</span>
<span id="cb8-4">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Density'</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div></div>
</details>
</div>
<p>The generated plot from the prior predictive sampling shows the distributions of simulated data (the number of conversions) created by sampling from the <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BBeta%7D(8,92)"> prior distribution. - The distribution of the simulated data (prior predictive line) appear broadly spread out and relatively flat across a wide range (0 to 40+ conversions). This indicates that the prior allows for many different outcomes, and thus it is not overly restrictive. - The dashed line represents the average predicted number of conversions It is also quite flat and non-committal. - It evident that the prior predictive distribution does not overly concentrate around any specific number of conversions, which is desirable when we want to remain open to various possible outcomes. - So the prior predictive check confirms that our chosen Beta(8,92) prior is reasonable though it also quite weakly informative how?</p>
<p><strong>Red flags to watch for:</strong></p>
<ul>
<li><p><strong>Impossible values</strong>: Predictions outside the feasible range (e.g., negative conversion, &gt;200 observations)</p></li>
<li><p><strong>Unrealistic concentrations</strong>: If priors are too informative, you might see all predictions clustered in a narrow range</p></li>
<li><p><strong>Poor scaling</strong>: Predictions that don‚Äôt match the scale of your problem</p></li>
</ul>
<section id="posterior-predictive-checks" class="level4">
<h4 class="anchored" data-anchor-id="posterior-predictive-checks">Posterior Predictive Checks</h4>
<p>Posterior Predictive Checks addresses the important test: Does the model actually make sense given the data observed?</p>
<p>This moves the process from confirming the samplers or priors to validating the model itself.</p>
<blockquote class="blockquote">
<p>PPCs evaluate model fit by comparing the observed data to simulated data from the posterior distribution. If a model accurately represents the data-generating process, the simulated data should resemble the actual observations.</p>
</blockquote>
<p>To achive this it is important to generate new, simulated data from the posterior distribution and compare it to the actual observed data. This is done using the <code>pm.sample_posterior_predictive</code> function in PyMC.</p>
<div id="36" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> conversion_model:</span>
<span id="cb9-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prior distribution based on historical performance</span></span>
<span id="cb9-3">    conversion_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Beta(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"conversion_rate"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">92</span>)</span>
<span id="cb9-4">    </span>
<span id="cb9-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Likelihood function</span></span>
<span id="cb9-6">    likelihood <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Binomial(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"observations"</span>, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>visitors, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>conversion_rate, observed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>conversions)</span>
<span id="cb9-7">    </span>
<span id="cb9-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sample from posterior distribution</span></span>
<span id="cb9-9">    trace <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span>, tune<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, chains<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>, return_inferencedata<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb9-10"></span>
<span id="cb9-11"></span>
<span id="cb9-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> conversion_model:</span>
<span id="cb9-13">    posterior_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample_posterior_predictive(trace, random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>,)</span>
<span id="cb9-14">    </span>
<span id="cb9-15">clear_output()</span></code></pre></div></div>
</details>
</div>
<div id="37" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1">ppc_summary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> az.summary(posterior_pred, kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'stats'</span>, hdi_prob<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>)</span>
<span id="cb10-2">ppc_table <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb10-3">    GT(ppc_summary)</span>
<span id="cb10-4">    .cols_label({</span>
<span id="cb10-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mean'</span>,</span>
<span id="cb10-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sd'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Std-Dev.'</span>,</span>
<span id="cb10-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hdi_2.5%'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'HDI 3%'</span>,</span>
<span id="cb10-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hdi_97.5%'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'HDI 97%'</span></span>
<span id="cb10-9">    }).tab_header(</span>
<span id="cb10-10">        title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Posterior Predictive Summary Statistics"</span>,</span>
<span id="cb10-11">        subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb10-12">    )</span>
<span id="cb10-13">)</span>
<span id="cb10-14">ppc_table </span></code></pre></div></div>
</details>
</div>
<p>It clear that the predicted mean (15.314) is extremely close to the actual observed count (15). This is a strong indication that the <code>conversion_rate model</code> fits the data very well. And thus the choice of the Beta Prior and Binomial Likelihood is appropriate for this data. The model predicts that 95% of the time, the number of conversions will fall between 6 and 24. Since the company observed value of 15 falls well within this 95% HDI, the actual observation is considered highly plausible according to your model.</p>
<div id="39" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1">ppc_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> posterior_pred.posterior_predictive[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'observations'</span>].values.flatten()</span>
<span id="cb11-2">percentile <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (ppc_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> conversions).mean() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb11-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Observed convervation (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>conversions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">) is at the </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>percentile<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">th percentile of predictions"</span>)</span></code></pre></div></div>
</details>
</div>
<p>The value of 53.7 is very close to the ideal 50, which provides further strong evidence (in addition to the mean of 15.314 already seen) that:</p>
<ul>
<li><p>The model is not biased (it is not systematically over- or under-estimating the data).</p></li>
<li><p>The choice of the Beta-Binomial model is highly appropriate for this data set.</p></li>
</ul>
</section>
</section>
<section id="model-utility-and-business-decision" class="level3">
<h3 class="anchored" data-anchor-id="model-utility-and-business-decision">Model Utility and Business Decision</h3>
<p>Following the confirmation of the reliability of the Bayesian model through the Posterior Predictive Check (PPC), the focus now shifts from ‚ÄúDoes the model fit the data?‚Äù to the commercially critical question: ‚ÄúIs the model useful for making business decisions?‚Äù</p>
<p>Specifically, the derived posterior distribution is utilized to quantify the evidence that the new feature‚Äôs conversion rate (Feature B) is superior to the existing, established conversion rate (Feature A, which has a known baseline rate of 0.08).</p>
<p>To achieve this, we need to extract the posterior distribution for the conversion_rate parameter that your model estimated.</p>
<div id="44" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1">posterior_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> trace.posterior.stack(sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"draw"</span>))</span>
<span id="cb12-2">conversion_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>posterior_samples[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'conversion_rate'</span>].values</span></code></pre></div></div>
</details>
</div>
<p>Next, calculate the ‚Äúprobability of superiority‚Äù‚Äîthe probability that the new feature (B) is better than the old (A).</p>
<p>Finally, the expected uplift in conversion rate can be computed and translated into business value. This involves calculating the difference between the posterior mean conversion rate and the historical rate, then multiplying by the number of visitors and average revenue per conversion.</p>
<ul>
<li><p>0.95: Strong Evidence. The new feature is very likely superior. Launching it should be considered.</p></li>
<li><p>0.80: Moderate Evidence. The new feature is likely better, but there is still a 20% chance it is worse. The decision depends on company risk tolerance.</p></li>
<li><p>0.50: No Evidence. The new feature is a toss-up; there is no statistical reason to prefer it over the old feature.</p></li>
</ul>
<div id="46" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1">prob_superiority <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (conversion_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> historical_baseline).mean()</span>
<span id="cb13-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the result</span></span>
<span id="cb13-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"The probability that the new feature is better than the old rate (0.08) is: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>prob_superiority<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
</details>
</div>
<p>The calculated Probability of Superiority is approximately 0.40, indicating that there is a 40% chance the new feature‚Äôs conversion rate is better than the old feature‚Äôs with 8% rate. This imply that there is a 60.3% chance the new feature is worse than the baseline.</p>
<p>Since the probability that the new feature is superior is well below the neutral benchmark of 50%, the data does not support replacing the existing Feature A with the new Feature B based on conversion rate alone. The new feature is highly likely to perform worse.</p>
<section id="probability-of-meaningful-improvement." class="level5">
<h5 class="anchored" data-anchor-id="probability-of-meaningful-improvement.">Probability of Meaningful Improvement.</h5>
<p>Depending on the business context, one might also want to calculate the probability that the new feature is better by a meaningful margin (e.g., &gt;1% improvement). This calculates the chance that the new feature is better than the old feature by a practically significant margin of at least 1 percentage point. This is a crucial business metric. Sometimes a tiny statistical ‚Äúwin‚Äù is not worth the cost of development and deployment. If this probability is low, it confirms the feature is not a major improvement.</p>
<div id="49" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1">prob_1pct_improvement <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (conversion_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> historical_baseline<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>).mean()</span>
<span id="cb14-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f" Probability of &gt;1% improvement: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>prob_1pct_improvement<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
</details>
</div>
</section>
<section id="probability-of-hitting-a-target-rate" class="level4">
<h4 class="anchored" data-anchor-id="probability-of-hitting-a-target-rate">Probability of Hitting a Target Rate</h4>
<p>This calculates the chance that the true conversion rate of the new feature is 10% or higher. This is useful if 10% is a specific, ambitious KPI (Key Performance Indicator) or goal set by the marketing or product team. It tells how likely the team is to meet its goal.</p>
<div id="51" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1">prob_10pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (conversion_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.10</span>).mean()</span>
<span id="cb15-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f" Probability of &gt;10% improvement: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>prob_10pct<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
</details>
</div>
<section id="expected-value-of-the-change." class="level5">
<h5 class="anchored" data-anchor-id="expected-value-of-the-change.">Expected Value of the Change.</h5>
<p>This is the single-number best estimate of the average change (positive or negative) to expect upon deploying the new feature. This is the foundation for the ‚ÄúExpected Business Impact‚Äù section. If this value is negative, it represents an Expected Loss.</p>
<p>If one calculates: expected_uplift√óTotal&nbsp;Visitors√óARPC, the estimated dollar value of the change is obtained.</p>
<p>The goal is to translate the statistically determined average change in conversion rate into a clear financial outcome for the business. This calculation provides the most actionable insight for the go/no-go decision on the new feature.</p>
<div id="53" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate key business probabilities</span></span>
<span id="cb16-2">expected_uplift <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conversion_samples.mean() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> historical_baseline</span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate expected business impact</span></span>
<span id="cb16-5">monthly_visitors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span></span>
<span id="cb16-6">expected_additional_conversions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> monthly_visitors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> expected_uplift</span>
<span id="cb16-7">conversion_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Average value per conversion</span></span>
<span id="cb16-8">expected_monthly_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> expected_additional_conversions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> conversion_value</span>
<span id="cb16-9"></span>
<span id="cb16-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Expected uplift: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>expected_uplift<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>expected_uplift<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> points)"</span>)</span>
<span id="cb16-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Expected monthly value: $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>expected_monthly_value<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:,.0f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
</details>
</div>
<p>We see that the expected uplift is -0.030 (-3.0% points), indicating that, on average, the new feature is expected to decrease the conversion rate by 3 percentage points. The expected financial consequence of deploying the new feature is a loss of $1,717 per month</p>
<p>The data suggests that deploying the new feature would likely result in an Expected Monthly Loss of $1,717. This financial quantification is the most compelling reason to reject the new feature based on conversion rate performance.</p>
<p>The decision to proceed should only be considered if the feature provides other, unquantified benefits (e.g., improved customer retention, compliance, or brand value) that are estimated to be worth more than $1,717 per month.</p>
</section>
</section>
<section id="prior-sensitivity-analysis" class="level4">
<h4 class="anchored" data-anchor-id="prior-sensitivity-analysis">Prior sensitivity analysis</h4>
<p>Assessing how the <strong>choice of prior influences the final decision</strong> is important. This transparency is a key strength of <strong>Bayesian modeling</strong>, as it allows testing every assumption. Thus, one must determine how much the choice of prior affects the outcome by comparing several <strong>Beta priors</strong>. These comparisons will include priors from very optimistic (expecting a <img src="https://latex.codecogs.com/png.latex?15%5C%25"> conversion rate) to skeptical (expecting only <img src="https://latex.codecogs.com/png.latex?4%5C%25">), plus an <strong>uninformative prior</strong> that lets the data speak entirely for itself.</p>
<div id="57" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"></span>
<span id="cb17-2">priors_to_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb17-3">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Very Optimistic"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">85</span>),    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Believes 15% conversion rate</span></span>
<span id="cb17-4">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Optimistic"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">88</span>),         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Believes 12% conversion rate  </span></span>
<span id="cb17-5">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Historical Based"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">92</span>),    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Our original prior (8%)</span></span>
<span id="cb17-6">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Strong Historical'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">920</span>),      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Mean = 0.08, ESS = 1000</span></span>
<span id="cb17-7">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Skeptical"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>),           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Believes 4% conversion rate</span></span>
<span id="cb17-8">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Uninformative"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Let data dominate completely</span></span>
<span id="cb17-9">]</span>
<span id="cb17-10"></span>
<span id="cb17-11">sensitivity_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb17-12">traces_to_comprare <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb17-13"></span>
<span id="cb17-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, (prior_name, alpha, beta) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(priors_to_test):</span>
<span id="cb17-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> pm.Model() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> model:</span>
<span id="cb17-16">        conversion_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Beta(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"conversion_rate"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>alpha, beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>beta)</span>
<span id="cb17-17">        obs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.Binomial(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"observations"</span>, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>visitors, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>conversion_rate, observed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>conversions)</span>
<span id="cb17-18">        trace <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pm.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span>, tune<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, chains<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>, return_inferencedata<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, progressbar<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb17-19">        </span>
<span id="cb17-20"> </span>
<span id="cb17-21">    posterior_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> trace.posterior.stack(sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chain"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"draw"</span>))</span>
<span id="cb17-22">    conversion_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>posterior_samples[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'conversion_rate'</span>].values</span>
<span id="cb17-23">    expected_uplift <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conversion_samples.mean() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> historical_baseline</span>
<span id="cb17-24">    expected_additional_conversions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> monthly_visitors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> expected_uplift</span>
<span id="cb17-25">    expected_monthly_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> expected_additional_conversions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> conversion_value</span>
<span id="cb17-26"></span>
<span id="cb17-27"></span>
<span id="cb17-28">    posterior_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conversion_samples.mean()</span>
<span id="cb17-29">    posterior_std <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conversion_samples.std()</span>
<span id="cb17-30">    prior_std <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt((alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> beta) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> ((alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> beta)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)))</span>
<span id="cb17-31">    prob_better <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (conversion_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> historical_baseline).mean()</span>
<span id="cb17-32">    uncertainty_reduction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, (prior_std <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> posterior_std) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> prior_std)</span>
<span id="cb17-33">    </span>
<span id="cb17-34">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prior"</span>: prior_name,</span>
<span id="cb17-35">                       <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Posterior"</span>: conversion_samples}</span>
<span id="cb17-36">                       )</span>
<span id="cb17-37">    </span>
<span id="cb17-38">    sensitivity_results.append({</span>
<span id="cb17-39">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Prior_Belief'</span>: prior_name,</span>
<span id="cb17-40">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Prior_Parameters'</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Beta(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>alpha<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>beta<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>,</span>
<span id="cb17-41">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Prior_Mean'</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>beta)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb17-42">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Posterior_Mean'</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>posterior_mean<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb17-43">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Prob_Better'</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>prob_better<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb17-44">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Expected_uplift"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"$</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>expected_uplift<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb17-45">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Expected_monthly_value"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"$</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>expected_monthly_value<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:,.0f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb17-46">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Uncertainty_Reduction'</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>uncertainty_reduction<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb17-47">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Data_Influence'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Strong'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> uncertainty_reduction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Moderate'</span></span>
<span id="cb17-48">    })</span>
<span id="cb17-49">    traces_to_comprare.append(df) </span>
<span id="cb17-50">sensitivity_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(sensitivity_results)</span>
<span id="cb17-51">traces_to_comprare<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pd.concat(traces_to_comprare)</span>
<span id="cb17-52">clear_output()</span>
<span id="cb17-53"></span></code></pre></div></div>
</details>
</div>
<p>Let first visualise the different priors</p>
<div id="59" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1">domain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Very Optimistic"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Optimistic"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Historical Based"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Strong Historical"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Skeptical"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Uninformative"</span>]</span>
<span id="cb18-2">reference_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame([</span>
<span id="cb18-3">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.08</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Old Feature CR (8%)'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'color'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label_x'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.08</span>},</span>
<span id="cb18-4">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.075</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'New Feature CR (7.5%)'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'color'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label_x'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.075</span>}</span>
<span id="cb18-5">])</span>
<span id="cb18-6"></span>
<span id="cb18-7"></span>
<span id="cb18-8">chart <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> alt.Chart(traces_to_comprare).transform_density(density<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Posterior'</span>, groupby<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Prior'</span>], as_<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Posterior'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'density'</span>])<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb18-9">    .mark_line(opacity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb18-10">    .encode(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Posterior:Q'</span>, </span>
<span id="cb18-11">            y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'density:Q'</span>, </span>
<span id="cb18-12">            color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>alt.Color(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prior:N"</span>).scale(domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>domain, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(domain)])</span>
<span id="cb18-13">            )</span>
<span id="cb18-14"></span>
<span id="cb18-15">reference_lines <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> alt.Chart(reference_data).mark_rule(</span>
<span id="cb18-16">    strokeDash<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>], <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dashed line</span></span>
<span id="cb18-17">    size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, </span>
<span id="cb18-18">).encode(</span>
<span id="cb18-19">    x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x:Q'</span>,</span>
<span id="cb18-20">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>alt.Color(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label:N'</span>, </span>
<span id="cb18-21">                    scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>alt.Scale(domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>reference_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].tolist(), </span>
<span id="cb18-22">                                    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>reference_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'color'</span>].tolist()),</span>
<span id="cb18-23">                    legend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>alt.Legend(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Conversion Rate"</span>))</span>
<span id="cb18-24">)</span>
<span id="cb18-25"></span>
<span id="cb18-26"></span>
<span id="cb18-27">final<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>chart <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> reference_lines </span>
<span id="cb18-28">final<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>final.properties(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Posterior Distributions by Prior Belief'</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">700</span>, height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>).configure_axis(</span>
<span id="cb18-29">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set grid to False to remove all grid lines</span></span>
<span id="cb18-30">    grid<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb18-31">).configure_view(</span>
<span id="cb18-32">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Optional: Remove the surrounding border of the plot area</span></span>
<span id="cb18-33">    strokeWidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> </span>
<span id="cb18-34">)</span>
<span id="cb18-35">final.save(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'posterior_sensitivity.pdf'</span>)</span>
<span id="cb18-36">final</span></code></pre></div></div>
</details>
</div>
<p>The figure above show Posterior belief distributions under different prior assumptions. Each curve in the figure represents a posterior distribution for the conversion rate under a different prior assumption. The horizontal axis shows possible conversion rates, and the vertical axis shows how plausible each value is after combining the prior belief with the observed data.</p>
<p>Despite very different starting assumptions, the posterior estimates converge around 7‚Äì10%, showing that the data provide a stable, consistent signal largely independent of the chosen prior. All reasonable priors converge to the same conclusion: <strong>the new feature likely isn‚Äôt better than the old one</strong>.</p>
<p>To support decision-making, we compile a summary table comparing key metrics across these prior choices.</p>
<div id="62" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create sensitivity analysis table</span></span>
<span id="cb19-2">sensitivity_table <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb19-3">    GT(sensitivity_df)</span>
<span id="cb19-4">    .tab_header(</span>
<span id="cb19-5">        title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Sensitivity Analysis: Impact of Prior Beliefs"</span>,</span>
<span id="cb19-6">        subtitle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"How Different Starting Assumptions Affect Final Conclusions"</span></span>
<span id="cb19-7">    )</span>
<span id="cb19-8">    .cols_label(</span>
<span id="cb19-9">        Prior_Belief<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prior Belief"</span>,</span>
<span id="cb19-10">        Prior_Parameters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prior Distribution"</span>, </span>
<span id="cb19-11">        Prior_Mean<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prior Mean"</span>,</span>
<span id="cb19-12">        Posterior_Mean<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Posterior Mean"</span>,</span>
<span id="cb19-13">        Prob_Better<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prob. Better"</span>,</span>
<span id="cb19-14">        Data_Influence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Data Influence"</span>,</span>
<span id="cb19-15">        Uncertainty_Reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Uncertainty Reduction"</span>,</span>
<span id="cb19-16">        Expected_uplift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Expected Uplift"</span>,</span>
<span id="cb19-17">        Expected_monthly_value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Expected Monthly Value"</span></span>
<span id="cb19-18">    )</span>
<span id="cb19-19">    .data_color(</span>
<span id="cb19-20">        columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Prob_Better"</span>],</span>
<span id="cb19-21">        palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#C73E1D"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#F18F01"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#2E8B57"</span>],</span>
<span id="cb19-22">        domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>]</span>
<span id="cb19-23">    )</span>
<span id="cb19-24">    .data_color(</span>
<span id="cb19-25">        columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Data_Influence"</span>],</span>
<span id="cb19-26">        palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#2E8B57"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#F18F01"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#C73E1D"</span>],</span>
<span id="cb19-27">        domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Strong"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Moderate"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Weak"</span>]</span>
<span id="cb19-28">    ).data_color(</span>
<span id="cb19-29">        columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Uncertainty Reduction"</span>],</span>
<span id="cb19-30">        palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#C73E1D"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#F18F01"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#2E8B57"</span>],</span>
<span id="cb19-31">        domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>]</span>
<span id="cb19-32">    ).tab_source_note(</span>
<span id="cb19-33">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Analysis shows robustness of conclusions to different prior assumptions ‚Ä¢ "</span></span>
<span id="cb19-34">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Even skeptical priors converge toward data-driven truth"</span></span>
<span id="cb19-35">    )</span>
<span id="cb19-36">    .tab_options(</span>
<span id="cb19-37">        table_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>,</span>
<span id="cb19-38">    )</span>
<span id="cb19-39">)</span>
<span id="cb19-40">clear_output()</span>
<span id="cb19-41">sensitivity_table</span></code></pre></div></div>
</details>
</div>
<p>Key observations:</p>
<ol type="1">
<li><p><strong>Prior Pull</strong>: The data moderate extreme beliefs. The very optimistic prior (0.150) is pulled down to 0.100, while the skeptical prior (0.040) rises to 0.064‚Äîdemonstrating how new evidence shifts expectations toward a central value.</p></li>
<li><p><strong>Prior Strength vs.&nbsp;Data Influence:</strong> The Strong Historical prior (Beta(80, 920)) and Uninformative prior (Beta(1, 1)) yield similar posteriors (~0.079, ~45% Prob_Better), but for opposite reasons. The former is dominated by prior belief; the latter, by data‚Äîshowing that strong evidence can overcome weak or missing priors.</p></li>
<li><p><strong>Impact on Decision Metrics:</strong>: The Very Optimistic prior suggests an 88% Prob_Better and +$9.9k expected value, favoring a launch. The Skeptical prior predicts only 12% Prob_Better and ‚Äì$8.2k, suggesting the opposite. Even moderate priors (e.g., 40‚Äì47%) could tip a go/no-go decision depending on the threshold.</p></li>
</ol>
</section>
</section>
<section id="common-bayesian-pitfalls-and-best-practices" class="level3">
<h3 class="anchored" data-anchor-id="common-bayesian-pitfalls-and-best-practices">Common bayesian pitfalls and best practices</h3>
<p>While Bayesian modeling provides a powerful framework for decision-making under uncertainty, several common mistakes can reduce its effectiveness.</p>
<blockquote class="blockquote">
<p>The first is overconfident priors, where excessively strong prior assumptions prevent new data from influencing the results. This issue is best mitigated by starting with weak or moderately informative priors and refining them as more evidence becomes available.</p>
</blockquote>
<blockquote class="blockquote">
<p>A second pitfall is ignoring prior sensitivity. Conclusions may shift significantly depending on the chosen prior distribution, so it is essential to conduct sensitivity analyses using multiple plausible priors to ensure that insights are robust.</p>
</blockquote>
<blockquote class="blockquote">
<p>The third major issue involves misinterpreting probability. A statement such as ‚Äú95% probability‚Äù does not imply absolute certainty; rather, it reflects the degree of belief given the available data and assumptions. Probabilities in Bayesian analysis are best interpreted in terms of relative confidence, risk, and decision trade-offs.</p>
</blockquote>
</section>
<section id="next-steps-in-the-bayesian-journey" class="level3">
<h3 class="anchored" data-anchor-id="next-steps-in-the-bayesian-journey">Next steps in the bayesian journey</h3>
<p>We have laid the groundwork by exploring the core components of the Bayesian approach. The subsequent session will focus on advanced practical implementation. We will apply this framework to critical survival analysis problems, modeling the probability and timing of events such as equipment failure.</p>
</section>
<section id="resources-to-continue-learning" class="level3">
<h3 class="anchored" data-anchor-id="resources-to-continue-learning">Resources to continue learning</h3>
<ul>
<li><a href="https://bayesiancomputationbook.com/welcome.html">Bayesian Modeling and Computation in Python</a></li>
<li><a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers">Bayesian Methods for Hackers</a></li>
<li><a href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking</a></li>
<li><a href="https://www.taylorfrancis.com/books/mono/10.1201/9781315372495/doing-bayesian-data-analysis-john-kruschke">Doing Bayesian Data Analysis</a></li>
<li><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data Analysis</a></li>
<li><a href="https://www.pymc.io/welcome.html">PyMC Documentation</a></li>
</ul>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{faustine2025,
  author = {Faustine, Anthony},
  title = {Understanding {Bayesian} {Thinking} for {Industrial}
    {Applications}},
  date = {2025-10-10},
  url = {https://sambaiga.github.io/pages/blog/posts/2025/10/2025-10-10-bayesion-foundation.html},
  langid = {en}
}
</code></pre></div></section></div> ]]></description>
  <category>python</category>
  <category>bayesian</category>
  <guid>https://sambaiga.github.io/pages/blog/posts/2025/10/2025-10-10-bayesion-foundation.html</guid>
  <pubDate>Fri, 10 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://sambaiga.github.io/pages/blog/posts/2025/10/posterior_sensitivity.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Shared Mental Models: The Invisible Architecture of High-Performance Teams</title>
  <dc:creator>Anthony Faustine</dc:creator>
  <link>https://sambaiga.github.io/pages/blog/posts/2024/07/</link>
  <description><![CDATA[ 





<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>Ever been on a team where everything just <em>clicks</em>? communication is effortless, everyone knows their role, and the team anticipates each other‚Äôs moves, achieving goals with remarkable efficiency. This seamless collaboration is not a magic. It is often the result of something called a <strong>shared mental model</strong>, the invisible architecture that supports high-performance teamwork.</p>
<p>This post explores what shared mental models are, why they are a critical predictor of team effectiveness, and how leaders can consciously cultivate them, especially in the complex environments of virtual and hybrid teams.</p>
</section>
<section id="what-is-a-shared-mental-model" class="level3">
<h3 class="anchored" data-anchor-id="what-is-a-shared-mental-model">What is a Shared Mental Model?</h3>
<p>Team effectiveness and coordination are critical aspects of a high-performance team. Team members who share a similar and organized understanding of team tasks and goals ‚Äî and who understand each other‚Äôs working environments ‚Äî are more likely to perform well.</p>
<p>This shared understanding and knowledge about the mission, goals, and other relevant environments among team members are called <strong>mental models</strong>. The shared mental model is one of the most frequently used concepts in team cognition <span class="citation" data-cites="Schelble2022">(Schelble et al. 2022)</span>. <span class="citation" data-cites="Lungeanu2022">(2022)</span> further identify the shared mental model as a critical predictor of team effectiveness.</p>
<p><span class="citation" data-cites="Lungeanu2022">Lungeanu, DeChurch, and Contractor (2022)</span> define shared mental models as team properties reflecting how team members organize knowledge and understanding about the team‚Äôs purpose, the nature of the work, and how they work together. Thus, team mental models are a collective mental representation among team members of how they interact in performing task-work <span class="citation" data-cites="Larson2020">(Larson and DeChurch 2020)</span>.</p>
<p>They represent the organized mental representations of the various component pieces relevant to a team‚Äôs overall task <span class="citation" data-cites="Schelble2022">(Schelble et al. 2022)</span>. As <span class="citation" data-cites="Schelble2022">(Schelble et al. 2022)</span> point out, shared mental models measure whether or not team members share a common understanding of their shared tasks, roles, interdependencies, and strategies.</p>
<p><span class="citation" data-cites="Schelble2022">Schelble et al. (2022)</span> break shared mental models into two types:</p>
<ul>
<li><strong>Task mental model</strong> ‚Äî covers aspects specific to understanding and completing a shared task.<br>
</li>
<li><strong>Team mental model</strong> ‚Äî focuses on factors related to cooperation and communication within a team.</li>
</ul>
</section>
<section id="the-impact-on-team-success" class="level3">
<h3 class="anchored" data-anchor-id="the-impact-on-team-success">The Impact on Team Success</h3>
<p>Shared mental models can continually develop over time, becoming more effective and influencing various team outcomes, such as objective performance, team viability, member well-being, and strategic alignment <span class="citation" data-cites="Lungeanu2022">(Lungeanu, DeChurch, and Contractor 2022)</span>.</p>
<p>Teams with shared mental models can recognize one another‚Äôs needs and information requirements <span class="citation" data-cites="Lungeanu2022 Schelble2022">(Lungeanu, DeChurch, and Contractor 2022; Schelble et al. 2022)</span>, which enhances coordination and mutual support.</p>
<p>While this may be more intuitive in physical teams, virtual teams ‚Äî now an integral part of modern work ‚Äî require special attention in developing and maintaining shared mental models among members.</p>
<p>Unlike face-to-face teams, creating and sustaining mental models is harder in virtual environments. Leaders must therefore compensate for challenges such as communication barriers and cultural differences. These issues can impact relationship building, which is essential for developing and sustaining shared mental models.</p>
<p>As underlined in <span class="citation" data-cites="Larson2020">(Larson and DeChurch 2020)</span>, face-to-face teams tend to have stronger shared mental models than virtual ones.</p>
<p>To improve team effectiveness and performance in virtual settings, leaders should aim to create a conducive environment for shared mental models. This can be achieved by:</p>
<ul>
<li>Cultivating high-quality, interpersonal communication.<br>
</li>
<li>Creating psychological safety.<br>
</li>
<li>Adopting a leadership style that aligns well with virtual collaboration <span class="citation" data-cites="Larson2020">(Larson and DeChurch 2020)</span>.</li>
</ul>
</section>
<section id="leaderships-role-in-building-a-shared-mind" class="level3">
<h3 class="anchored" data-anchor-id="leaderships-role-in-building-a-shared-mind">Leadership‚Äôs Role in Building a Shared Mind</h3>
<p><span class="citation" data-cites="Lungeanu2022">Lungeanu, DeChurch, and Contractor (2022)</span> highlight that leadership particularly <strong>shared leadership</strong> plays a crucial role in creating and shaping shared mental models in teams. This applies to both face-to-face and virtual teams.</p>
<p>For instance, <span class="citation" data-cites="Lungeanu2022">(Lungeanu, DeChurch, and Contractor 2022)</span> note that when leadership responsibilities are shared among members, the team tends to show greater commitment and information sharing. This dynamic fosters trust and enhances performance.</p>
<p>Teams that embrace shared leadership and have diverse skills, experiences, and perspectives are more likely to develop and maintain strong shared mental models.</p>
<p>Furthermore, <strong>connected leadership</strong> as opposed to fragmented leadership offers several advantages for improving similarity in team mental models. It promotes accuracy, synchronization of effort, and cohesion or trust.</p>
<p>For example, <span class="citation" data-cites="Lungeanu2022">(Lungeanu, DeChurch, and Contractor 2022)</span> argue that hierarchical and coordinated leadership are better at promoting shared mental models than factional or isolated forms of leadership. They also emphasize that boundaries among members of shared leadership groups are permeable, allowing reciprocal leadership processes that reduce conflict and tension.</p>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>Ultimately, a shared mental model is not just a nice-to-have; it‚Äôs the cognitive foundation upon which effective teams are built. It serves as the shared ‚Äúmap‚Äù that enables a group of individuals to navigate complex tasks together with clarity and confidence.</p>
<p>While the rise of virtual work presents new challenges, the core principle remains: <strong>effective leadership is the catalyst</strong>. By fostering open communication, psychological safety, and a connected leadership structure, leaders can intentionally design the conditions for these powerful shared understandings to emerge and thrive.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-Larson2020" class="csl-entry">
Larson, Lindsay, and Leslie A. DeChurch. 2020. <span>‚ÄúLeading Teams in the Digital Age: Four Perspectives on Technology and What They Mean for Leading Teams.‚Äù</span> <em>The Leadership Quarterly</em> 31 (1): 101377. <a href="https://doi.org/10.1016/j.leaqua.2019.101377">https://doi.org/10.1016/j.leaqua.2019.101377</a>.
</div>
<div id="ref-Lungeanu2022" class="csl-entry">
Lungeanu, Alina, Leslie A. DeChurch, and Noshir S. Contractor. 2022. <span>‚ÄúLeading Teams over Time Through Space: Computational Experiments on Leadership Network Archetypes.‚Äù</span> <em>The Leadership Quarterly</em>, January, 101595. <a href="https://doi.org/10.1016/j.leaqua.2021.101595">https://doi.org/10.1016/j.leaqua.2021.101595</a>.
</div>
<div id="ref-Schelble2022" class="csl-entry">
Schelble, Beau G., Christopher Flathmann, Nathan J. McNeese, Guo Freeman, and Rohit Mallick. 2022. <span>‚ÄúLet<span></span>s Think Together! Assessing Shared Mental Models, Performance, and Trust in Human-Agent Teams.‚Äù</span> <em>Proceedings of the <span>ACM</span> on Human-Computer Interaction</em> 6 (<span>GROUP</span>): 1‚Äì29. <a href="https://doi.org/10.1145/3492832">https://doi.org/10.1145/3492832</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{faustine2024,
  author = {Faustine, Anthony},
  title = {Shared {Mental} {Models:} {The} {Invisible} {Architecture} of
    {High-Performance} {Teams}},
  date = {2024-07-12},
  url = {https://sambaiga.github.io/pages/blog/posts/2024/07/},
  langid = {en}
}
</code></pre></div></section></div> ]]></description>
  <category>Team leadership</category>
  <category>Leadership</category>
  <guid>https://sambaiga.github.io/pages/blog/posts/2024/07/</guid>
  <pubDate>Fri, 12 Jul 2024 00:00:00 GMT</pubDate>
  <media:content url="https://sambaiga.github.io/pages/blog/posts/2024/07/team-mental-model.svg" medium="image" type="image/svg+xml"/>
</item>
</channel>
</rss>
