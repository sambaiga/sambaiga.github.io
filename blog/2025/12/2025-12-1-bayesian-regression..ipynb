{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Bayesian Regression: A Real-World Battery Degradation Case Study\"\n",
    "date: 2025-12-17\n",
    "description: \"Learn how Bayesian regression works in practice using PyMC, through a real-world\n",
    "  battery degradation case study.\"\n",
    "\n",
    "image: posterior-comparison-1.png\n",
    "twitter-card: \n",
    "    image: \"posterior-comparison-1.png\"\n",
    "open-graph: \n",
    "    image: \"posterior-comparison-1.png\"\n",
    "\n",
    "categories:\n",
    "  - python\n",
    "  - bayesian\n",
    "\n",
    "title-block-banner: \"blog-cover.jpg\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-summary: \"Show the code\"\n",
    "    code-overflow: wrap\n",
    "    shift-heading-level-by: 1\n",
    "    reference-location: margin\n",
    "    quarto-template-params:\n",
    "      banner-header-class: \"blog-post\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Predictive modeling in industrial settings is rarely just about accuracy. Decisions informed by models often carry financial, safety, and operational risks. In such environments, understanding uncertainty can be just as important as generating a good point prediction.\n",
    "\n",
    "This article offers a practical introduction to Bayesian regression through a real-world case study: predicting lithium-ion battery degradation. Instead of treating model parameters as fixed, unknown values, the Bayesian approach frames them as probability distributions‚Äîexplicitly modeling uncertainty to give engineers and data scientists a richer, more actionable understanding of system behavior.\n",
    "\n",
    "\n",
    ">üõ†Ô∏è **Action**: If you prefer to learn by doing, you can reproduce  this article using the accompanying resources:\n",
    "\n",
    "  1. [Repository](https://github.com/sambaiga/bayesian-modelling): Fork the [bayesian-modelling repository](https://github.com/sambaiga/bayesian-modelling) and follow the setup instructions in the README.md\n",
    "  2. [Notebook](https://github.com/sambaiga/bayesian-modelling/blob/main/notebook/2025-12-1-bayesian-regression..ipynb): Launch [2025-12-1-bayesian-regression.ipynb](https://github.com/sambaiga/bayesian-modelling/blob/main/notebook/2025-12-1-bayesian-regression..ipynb) in the notebook folder to follow along step-by-step.\n",
    "\n",
    "\n",
    "\n",
    "This post is part of the *Bayesian Modelling for Industrial Applications series* ‚Äì **Part 2**  . If you are new to Bayesian methods, you may want to start with the first post [Part 1](https://sambaiga.github.io/blog/2025/10/bayesian-modelling-01.html), which introduces the foundational concepts of Bayesian inference.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome back to our series on **Bayesian Modelling for Industrial Applications**. In\n",
    "[Part 1](https://sambaiga.github.io/blog/2025/10/bayesian-modelling-01.html), we explored how Bayesian thinking provides a principled framework for decision-making under uncertainty when evidence is limited. \n",
    "\n",
    "In this post, we extend that foundation to **continuous prediction problems**, showing how **Bayesian regression** transforms noisy industrial data into actionable insights *with uncertainty explicitly quantified rather than ignored*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Why Bayesian regression?\n",
    "\n",
    "\n",
    "\n",
    "Imagine managing a fleet of electric vehicles. One of your biggest challenges is predicting\n",
    "**battery State of Health (SoH)** over time. Early predictions inform warranty decisions,\n",
    "maintenance planning, and safety margins.\n",
    "\n",
    "Industrial systems, like vehicle battery packs, are inherently complex: they are characterized by noisy, non-repeatable measurements due to sensor noise, unit variability, and stochastic physical processes.\n",
    "\n",
    "Traditional, purely deterministic regression methods (which produce a single \"best-fit\" curve) fail to capture this complexity. A deterministic model might predict one degradation curve, but in practice, real batteries age differently even under similar conditions. This reliance on a single point estimate overlooks critical, high-risk aspects of the industrial data:\n",
    "\n",
    "- Measurement uncertainty inherent in sensors and data acquisition systems  \n",
    "- Unit-to-unit variability in components (e.g., subtle differences between nominally identical batteries)  \n",
    "- Random and nonlinear degradation behaviour  \n",
    "- Limited early-life observations, a common constraint in industrial testing  \n",
    "\n",
    "\n",
    "Bayesian regression addresses this reality by treating uncertainty as a first-class citizen.\n",
    "Instead of delivering a single prediction, it provides **ranges of plausible outcomes**,\n",
    "allowing decisions to be made with risk explicitly accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Modeling distributions with bayes' theorem\n",
    "\n",
    "Bayesian regression models uncertainty by treating parameters as probability distributions\n",
    "rather than fixed values. Each coefficient represents a range of plausible effects, informed\n",
    "by both prior knowledge and observed data.\n",
    "\n",
    "This framework is built on three core components:\n",
    "\n",
    "1. **Priors**, which encode existing engineering knowledge or physical constraints  \n",
    "2. **Likelihood**, which links the model to noisy real-world measurements  \n",
    "3. **Posterior**, which combines prior information and data into an updated belief\n",
    "\n",
    "The posterior distribution enables **credible intervals**, allowing us to quantify how\n",
    "confident we are in both parameter estimates and future predictions‚Äîan essential capability\n",
    "in industrial decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Case Study: Predicting battery degradation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Lithium-ion batteries are critical components in electric vehicles and stationary energy\n",
    "storage systems. Unexpected capacity loss can lead to service interruptions, safety risks,\n",
    "and costly premature replacements.\n",
    "\n",
    "The challenge is predicting future battery health when:\n",
    "- Direct capacity measurements are infrequent and expensive\n",
    "- Early-life data is sparse\n",
    "- Degradation accelerates nonlinearly near end of life\n",
    "\n",
    "The goal is not only to predict degradation, but to quantify uncertainty well enough to\n",
    "support maintenance and replacement decisions.\n",
    "\n",
    "\n",
    "We use battery degradation data from the  [CALCE Battery](https://calce.umd.edu/battery-data) Research Group at the University of Maryland. Battery State of Health ($\\text{SoH}$) is defined as current capacity relative to initial capacity ($\\text{SoH} = C/C_{max}$).  This continuous value degrades non-linearly over the battery's life, driven primarily by cycle count and operational conditions, with significant measurement noise. The [CALCE dataset](https://calce.umd.edu/battery-data) provides over 1,200 capacity measurements   taken at discrete cycle intervals, alongside features like charging and discharge current and voltage. This comprehensive dataset has become a benchmark in battery research, allowing rigorous comparison of degradation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "from great_tables import GT, loc, md, style\n",
    "from IPython.display import clear_output\n",
    "from lets_plot import (\n",
    "    LetsPlot,\n",
    "    aes,\n",
    "    coord_cartesian,\n",
    "    facet_wrap,\n",
    "    flavor_high_contrast_dark,\n",
    "    geom_area,\n",
    "    geom_band,\n",
    "    geom_density,\n",
    "    geom_histogram,\n",
    "    geom_line,\n",
    "    geom_point,\n",
    "    geom_ribbon,\n",
    "    geom_vline,\n",
    "    gggrid,\n",
    "    ggplot,\n",
    "    ggsize,\n",
    "    guide_legend,\n",
    "    guides,\n",
    "    labs,\n",
    "    layer_tooltips,\n",
    "    scale_color_brewer,\n",
    "    scale_color_manual,\n",
    "    scale_fill_manual,\n",
    "    scale_y_continuous,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "\n",
    "az.style.use(\"arviz-doc\")\n",
    "\n",
    "from bayes.plot.basic_plots import line_plot, modern_theme, pro_colors, scatter_plot\n",
    "\n",
    "LetsPlot.setup_html(isolated_frame=False, offline=True, no_js=True, show_status=False)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Choosing the Beta Likelihood\n",
    "\n",
    "\n",
    "The capacity data being modeled, $C$, represents the battery's health and is strictly bounded between zero and its initial (maximum) capacity, $C_{\\text{max}}$. The goal of this analysis is to model the evolution of $C$. In many standard regression approaches, the model's likelihood function (which defines the distribution of the noise) is assumed to be Gaussian (Normal). This assumption is fundamentally incompatible with the physical reality of capacity degradation for two key reasons.\n",
    "\n",
    "1.  Gaussian models assume the target variable can take any real value ($-\\infty$ to $+\\infty$), ignoring the fact that the underlying capacity $C$  cannot fall outside their physical limits (i.e., $[C_{\\text{min}}, C_{\\text{max}}]$ )\n",
    "2.  With enough extrapolation, Gaussian models produce impossible values (e.g.,negative capacity). In safety-critical systems, such predictions are dangerous.\n",
    "\n",
    "The Beta distribution is consequently chosen as the likelihood function for this regression problem. The Beta distribution is flexible, capable of modeling various shapes (uniform, U-shaped, skewed) depending on its shape parameters ($\\alpha$ and $\\beta$).Furthermore, since battery capacity degradation is continuous and strictly bounded by $[C_{\\text{min}}, C_{\\text{max}}]$, a Beta likelihood provides a natural modeling choice that avoids the ad-hoc truncation required by Gaussian assumptions. \n",
    "\n",
    "To fit the Beta's intrinsic $[0, 1]$ domain, capacity ($C_i$) is first scaled into a normalized State of Health ($\\tilde{C}_i$) using the following transformation:$$\\tilde{C}_i = \\frac{C_i - C_{\\text{min}}}{C_{\\text{max}} - C_{\\text{min}}}$$The model then utilizes the Beta distribution for the scaled capacity:$$\\tilde{C}_i \\sim \\text{Beta}(\\alpha_i, \\beta_i)$$where $\\alpha_i, \\beta_i > 0$ and $\\tilde{C}_i \\in [0, 1]$. This modeling choice ensures all predicted $\\tilde{C}_i$ values remain physically plausible while allowing for flexible modeling of degradation patterns through the shape parameters.\n",
    "\n",
    "```python\n",
    "with pm.Model() as battery_model:\n",
    "    pm.Beta(\"y_obs\", alpha=alpha, beta=beta_shape, observed=y_data)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Parameterization: Mean ($\\mu$) and Precision ($\\phi$)\n",
    "\n",
    "To make the parameters intuitive, the Beta distribution is typically reparameterized using the mean ($\\mu$) and the precision ($\\phi$).The shape parameters, $\\alpha_i$ and $\\beta_i$, which define the exact shape of the distribution for a given observation, are calculated directly from the mean $\\mu_{i} \\in (0, 1)$ and the global precision $\\phi > 0$ such that:$$\\alpha_i = \\mu_{i} \\cdot \\phi \\quad \\text{and} \\quad \\beta_i = (1 - \\mu_{i}) \\cdot \\phi$$ The precision parameter, $\\phi$, controls the variance: a large $\\phi$ means the predictions are tightly clustered around the mean $\\mu_{i}$, indicating low uncertainty (low variance).\n",
    "\n",
    "\n",
    "```python\n",
    "with pm.Model() as battery_model:\n",
    "    alpha = mu_scaled * phi\n",
    "    beta_shape = (1 - mu_scaled) * phi\n",
    "```\n",
    "\n",
    "The mean parameter $\\mu_{i} \\in (0, 1)$ must be linked to our predictors. Since the mean is bounded by $(0, 1)$, we use the Logit Link Function to map the linear combination of predictors ($\\eta_i$) to this interval: $$\\text{logit}(\\mu_{i}) = \\eta_i$$ as such , $$\\mu_{i} = \\text{logit}^{-1}(\\eta_i) = \\frac{1}{1 + e^{-\\eta_i}}$$\n",
    "\n",
    "```python\n",
    "with pm.Model() as battery_model:\n",
    "    mu_scaled = pm.Deterministic(\"mu_scaled\", pm.math.sigmoid(logit_mu))\n",
    "```\n",
    "\n",
    "> üí° Key Takeaway: The Logit Link function is the mathematical bridge that ensures our mean prediction, $\\mu_i$, respects the physical boundary of $(0, 1)$ imposed by the Beta distribution\n",
    "\n",
    "#### The Linear Predictor: Capturing Degradation\n",
    "\n",
    "The core of our predictive power lies in the linear predictor, $\\eta_i$. It is structured to incorporate both the fundamental, non-linear degradation due to cycling and the linear operational effects from features $\\mathbf{x}$ like voltage and current:\n",
    "$$\\eta_i = \\underbrace{\\beta_0}_{\\text{Intercept}} + \\underbrace{f(k_i)}_{\\text{Non-linear Decay}} + \\underbrace{\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}}_{\\text{Operational Effects}}$$\n",
    "\n",
    "In this work, the non-linear decay component is modeled as an exponential function: $$f(k_i) = -A\\cdot(1-e^{-\\lambda \\cdot k_i})$$ where $k_i$ is the cycle count, $\\lambda$ is the degradation rate, and $A>0$ is a learnable amplitude parameter controlling the strength of decay. This captures the physical reality that battery capacity degrades rapidly at first and then more slowly over time. where:\n",
    "\n",
    "\n",
    "```python\n",
    "with pm.Model() as battery_model:\n",
    "    degradation = pm.math.exp(-lambda_rate * cycle_data)\n",
    "    degradation_term = -degr_amp * (1 - degradation)\n",
    "    logit_mu = intercept + degradation_term + pm.math.dot(x_data, beta)\n",
    "```\n",
    "\n",
    "The components of $\\eta_i$ are as follows:\n",
    "\n",
    "\n",
    "1. Intercept ($\\beta_0$): The baseline capacity on the logit scale when operational effects are zero and the cycle count ($k_i$) is zero.\n",
    "2. Degradation Term ($e^{-\\lambda \\cdot k_i}$): This is the non-linear exponential decay over the cycle count $k_i$, controlled by the rate $\\lambda$. This term ensures the capacity prediction naturally trends downward toward zero capacity over time.\n",
    "3. Operational Effects ($\\mathbf{x}_{i}^{\\top} \\boldsymbol{\\beta}$): This is a standard linear combination, where $\\boldsymbol{\\beta}$ is the vector of coefficients for the standardized operational features $\\mathbf{x}_{i}$. \n",
    "   \n",
    "This models how factors like maximum temperature accelerate or slow down the degradation.\n",
    "\n",
    "> üß† **Self-Test**: You are modeling $\\text{SoH}$, which must stay in $[0, 1]$. Your linear predictor, $\\eta_i = \\beta_0 + \\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}$, can produce values ranging from $-\\infty$ to $+\\infty$.What would happen if you skipped the Logit Link Function and simply set $\\mu_i = \\eta_i$? Why is the Logit Link function mandatory for the Beta regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Encoding Knowledge with Priors\n",
    "\n",
    "In Bayesian modeling, defining priors is a critical step. This step allows domain knowledge accumulated from battery engineering to be embedded directly into the model, ensuring that predictions remain physically plausible even when data is sparse. A prior distribution is assigned to every unknown parameter ($\\beta_0, \\boldsymbol{\\beta}, \\lambda, \\phi$). These priors act as soft constraints, preventing the model from learning extreme or non-physical relationships.\n",
    "\n",
    "**The Intercept ($\\beta_0$)** \n",
    "\n",
    "The Intercept $\\beta_0$ represents the initial capacity of the battery fleet on the logit scale. The orange curve in the figure below represents the selected informative prior, $\\text{Normal}(\\mu_{\\text{logit\\_start}}, 0.5^2)$. A standard deviation of $\\sigma = 0.5$ is chosen to balance prior knowledge (centering at $\\mu_{\\text{logit\\_start}}$) with sufficient uncertainty to allow the observed data to meaningfully influence the final estimate.\n",
    "\n",
    "```python\n",
    "with pm.Model() as battery_model:\n",
    "    eps=1e-8\n",
    "    initial_logit_capacity_mean = -np.log(1-eps)\n",
    "    intercept = pm.Normal(\"intercept\", mu=initial_logit_capacity_mean, sigma=0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes.plot.distribution import plot_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "s1 = pm.draw(pm.Normal.dist(mu=0.28, sigma=0.1), n)\n",
    "s2 = pm.draw(pm.Normal.dist(mu=0.28, sigma=0.2), n)\n",
    "s3 = pm.draw(pm.Normal.dist(mu=0.28, sigma=0.5), n)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"value\": np.concatenate([s1, s2, s3]),\n",
    "        \"distribution\": np.repeat([\"(Œº=0.28, œÉ=0.1)\", \"(Œº=0.28, œÉ=0.2)\", \"(Œº=0.28, œÉ=0.5)\"], n),\n",
    "    }\n",
    ")\n",
    "\n",
    "plot=plot_density(df, title=\"Normal Distributions Intercept Priors\", fig_size=(500, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "The narrower blue ($\\sigma = 0.1$) and green ($\\sigma = 0.2$) curves represent highly concentrated priors that would strongly restrict the posterior estimates. The wider $\\sigma = 0.5$ (orange) distribution corresponds to a more conservative informative prior, granting the initial capacity estimate $\\beta_0$ a reasonable degree of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "**Operational Effects ($\\boldsymbol{\\beta}$)**\n",
    "\n",
    "The vector of coefficients $\\boldsymbol{\\beta}$ controls the influence of operational features on capacity fade. Engineering knowledge suggests that, unless a feature is extreme, its immediate effect on capacity should be subtle, as the overall degradation process is primarily driven by cycle count.\n",
    "\n",
    "```python\n",
    "    with pm.Model() as battery_model:\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=0.2, shape=n_features)\n",
    "``` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes.plot.distribution import plot_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1 = pm.draw(pm.Normal.dist(mu=0, sigma=0.1), n)\n",
    "s2 = pm.draw(pm.Normal.dist(mu=0, sigma=0.2), n)\n",
    "s3 = pm.draw(pm.Normal.dist(mu=0, sigma=1.0), n)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"value\": np.concatenate([s1, s2, s3]),\n",
    "        \"distribution\": np.repeat([\"(Œº=0, œÉ=0.1)\", \"(Œº=0, œÉ=0.2)\", \"(Œº=0, œÉ=1.0)\"], n),\n",
    "    }\n",
    ")\n",
    "\n",
    "plot=plot_density(df, title=\"Normal Distributions Beta Priors\", fig_size=(500, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "As shown in the figure above, a tight informative prior, $\\text{Normal}(0, 0.2^2)$, is used for $\\boldsymbol{\\beta}$. Centering this prior at zero reflects the assumption that, on average, operational features have no effect, while the small standard deviation ($0.2$) requires strong evidence from the data before attributing a large effect to any single feature. This constraint prevents non-physical, abrupt changes in capacity predictions. In contrast, a broader prior such as $\\text{Normal}(0, 1.0^2)$ (orange curve) allows extreme effects that are considered non-physical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "**Degradation rate $\\lambda$** \n",
    "\n",
    "The degradation rate $\\lambda$ governs the exponential decay term $e^{-\\lambda k_i}$. Since degradation must always occur and capacity cannot increase indefinitely, it is necessary to enforce $\\lambda > 0$. Accordingly, a Log-Normal prior, $\\text{LogNormal}(\\ln(0.005), 0.5^2)$, is used for $\\lambda$.\n",
    "\n",
    "```python\n",
    "with pm.Model() as battery_model:\n",
    "    lambda_rate = pm.Lognormal(\"lambda_rate\", mu=np.log(0.01), sigma=0.5)\n",
    "```\n",
    "> üß† **Self-Test**: Recall that we set the prior for the fade rate $\\lambda$ as $\\text{LogNormal}(\\ln(0.01), 0.5^2)$ (where $\\sigma = 0.5$). What practical problem would arise if an engineer, overly confident in their historical knowledge, reset the prior to $\\text{LogNormal}(\\ln(0.01), 0.1^2)$ (where $\\sigma = 0.1$)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1 = pm.draw(pm.LogNormal.dist(np.log(0.005), sigma=0.1), n)\n",
    "s2 = pm.draw(pm.LogNormal.dist(np.log(0.005), sigma=0.5), n)\n",
    "s3 = pm.draw(pm.LogNormal.dist(np.log(0.005), sigma=1.0), n)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"value\": np.concatenate([s1, s2, s3]),\n",
    "        \"distribution\": np.repeat([\"(Œº=In(0.005), œÉ=0.1)\", \"(Œº=In(0.005), œÉ=0.5)\", \"(Œº=In(0.005), œÉ=1.0)\"], n),\n",
    "    }\n",
    ")\n",
    "\n",
    "plot=plot_density(df, title=\"LogNormal Distributions Priors\", fig_size=(500, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "This weakly informative prior centers the expected degradation rate around $\\mathbf{0.5\\%}$, while the spread $\\sigma = 0.5$ (green/teal curve) is sufficiently wide to accommodate realistic fleet-level variability. At the same time, it remains substantially tighter than $\\sigma = 1.0$ (orange curve), thereby avoiding non-physical probability mass assigned to unrealistically large degradation rates.\n",
    "\n",
    "This distribution reflects a conservative estimate of uncertainty, allowing greater variation in degradation behavior than a tighter prior (e.g., $\\sigma = 0.1$) would permit, while still preventing implausible rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**Degradation Amplitude ($A$)**\n",
    "\n",
    "The parameter degr_amp ($A$) controls the overall amplitude of the degradation component. Since this amplitude must be non-negative, a Half-Normal distribution is used, which has support only on positive values. The scale parameter $\\sigma$ determines the strength of regularization.\n",
    "\n",
    "\n",
    "```python\n",
    "   with pm.Model() as battery_model:\n",
    "    degr_amp = pm.HalfNormal(\"degr_amp\", sigma=0.1)\n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1 = pm.draw(pm.HalfNormal.dist(sigma=0.1), n)\n",
    "s2 = pm.draw(pm.HalfNormal.dist(sigma=0.2), n)\n",
    "s3 = pm.draw(pm.HalfNormal.dist(sigma=0.5), n)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"value\": np.concatenate([s1, s2, s3]),\n",
    "        \"distribution\": np.repeat([\"œÉ=0.1\", \"œÉ=0.2\", \"œÉ=0.5\"], n),\n",
    "    }\n",
    ")\n",
    "plot=plot_density(df, title=\"Gamma Distributions Phi Priors\", fig_size=(500, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "As shown in the figure above, $\\text{HalfNormal}(\\sigma = 0.1)$ strongly concentrates probability mass near zero, requiring substantial evidence before attributing a large degradation amplitude. In contrast, broader priors such as $\\text{HalfNormal}(\\sigma = 0.5)$ place non-negligible probability on large, non-subtle amplitudes (up to approximately $1.0$), increasing the risk of overfitting by allowing the model to explain noise through the amplitude term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "**Precision Parameter ($\\phi$)**\n",
    "\n",
    "The precision parameter $\\phi$ controls the variance of the Beta likelihood and represents the expected level of noise in the $\\text{SoH}$ measurements. Accordingly, a highly informative Gamma prior, $\\text{Gamma}(100, 2)$, is assigned to $\\phi$.\n",
    "```python\n",
    "with pm.Model() as battery_model:\n",
    "    phi = pm.Gamma(\"phi\", alpha=100, beta=2.0)\n",
    "```\n",
    "This prior is centered at $\\mathbb{E}[\\phi] = \\alpha / \\beta = 50$ with a relatively small standard deviation ($\\sigma_{\\phi} = 5.0$), indicating high confidence in this expectation. This choice encodes the belief that sensor noise is low ($\\sigma_{\\text{noise}} \\approx 0.14$), reflecting the physical reality of precise laboratory-grade measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1 = pm.draw(pm.Gamma.dist(alpha=10, beta=1), n)\n",
    "s2 = pm.draw(pm.Gamma.dist(alpha=50, beta=5), n)\n",
    "s3 = pm.draw(pm.Gamma.dist(alpha=100, beta=2), n)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"value\": np.concatenate([s1, s2, s3]),\n",
    "        \"distribution\": np.repeat([\"Gamma(Œ±=10, Œ≤=1)\", \"Gamma(Œ±=50, Œ≤=5)\", \"Gamma(Œ±=100, Œ≤=2)\"], n),\n",
    "    }\n",
    ")\n",
    "plot=plot_density(df, title=\"Gamma Distributions Phi Priors\", fig_size=(500, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "\n",
    "From the figure above, it is evident that $\\text{Gamma}(\\alpha = 100, \\beta = 2.0)$ (orange curve) provides a strong belief in high precision. In contrast, $\\text{Gamma}(\\alpha = 10, \\beta = 1.0)$ yields a lower expected precision with greater spread, allowing excessive uncertainty and risking a flat, unphysical prior predictive distribution. Alternative Gamma priors with the same expected precision but larger variance similarly underestimate the precision of modern sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "The complete model now combines all these components:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_regression_model(\n",
    "    data: pd.DataFrame,\n",
    "    features: list[str],\n",
    "    target: str = \"capacity\",\n",
    "    scaler: StandardScaler | None = None,\n",
    "    lower_bound: float = 0.2,\n",
    "    upper_bound: float = 1.3,\n",
    "    eps: float = 1e-8,\n",
    ") -> tuple[pm.Model, StandardScaler]:\n",
    "    \"\"\"Beta regression model for bounded battery capacity data using PyMC.\n",
    "\n",
    "    Capacity (SoH) is scaled to the (0, 1) interval for the Beta distribution.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame containing 'capacity', 'cycle', and feature columns.\n",
    "        features: List of column names used as predictors (X variables).\n",
    "        target: Name of the capacity column.\n",
    "        scaler: Pre-fitted StandardScaler object, or None to fit a new one.\n",
    "        lower_bound: Physical lower bound for capacity (for scaling).\n",
    "        upper_bound: Physical upper bound for capacity (for scaling).\n",
    "        eps: Small value to avoid boundary issues in Beta distribution.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the PyMC model and the fitted/provided StandardScaler.\n",
    "    \"\"\"\n",
    "    # 1. Prepare Features (X)\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(data[features])\n",
    "    else:\n",
    "        x_scaled = scaler.transform(data[features])\n",
    "\n",
    "    # 2. Prepare Targets (Y)\n",
    "    y = data[target].values.astype(np.float64)\n",
    "    cycles = data[\"cycle\"].values.astype(np.float64)\n",
    "    n_features = len(features)\n",
    "\n",
    "    # Transform y to (0,1) interval and clip to avoid boundaries (0 or 1)\n",
    "    y_scaled = (y - lower_bound) / (upper_bound - lower_bound)\n",
    "    y_scaled = np.clip(y_scaled, eps, 1 - eps)\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Data Containers\n",
    "        x_data = pm.Data(\"x_data\", x_scaled)\n",
    "        cycle_data = pm.Data(\"cycle_data\", cycles)\n",
    "        y_data = pm.Data(\"y_data\", y_scaled)\n",
    "\n",
    "        # Priors\n",
    "        initial_logit_capacity_mean = -np.log(1 - 1e-6)\n",
    "        intercept = pm.Normal(\"intercept\", mu=initial_logit_capacity_mean, sigma=0.5)\n",
    "        lambda_rate = pm.Lognormal(\"lambda_rate\", mu=np.log(0.005), sigma=0.5)\n",
    "        beta = pm.Normal(\"beta\", mu=0, sigma=0.2, shape=n_features)\n",
    "        phi = pm.Gamma(\"phi\", alpha=100, beta=2.0)\n",
    "        degr_amp = pm.HalfNormal(\"degr_amp\", sigma=0.1)\n",
    "\n",
    "        # Linear predictor (eta) on logit scale\n",
    "        degradation = pm.math.exp(-lambda_rate * cycle_data)\n",
    "        degradation_term = -degr_amp * (1 - degradation)\n",
    "        logit_mu = intercept + degradation_term + pm.math.dot(x_data, beta)\n",
    "\n",
    "        # Convert to probability scale (0,1)\n",
    "        mu_scaled = pm.Deterministic(\"mu_scaled\", pm.math.invlogit(logit_mu))\n",
    "\n",
    "        # Beta likelihood\n",
    "        alpha = mu_scaled * phi\n",
    "        beta_shape = (1 - mu_scaled) * phi\n",
    "        pm.Beta(\"y_obs\", alpha=alpha, beta=beta_shape, observed=y_data)\n",
    "\n",
    "        # Transform mu back to original scale\n",
    "        mu_original = pm.Deterministic(\"mu_original\", mu_scaled * (upper_bound - lower_bound) + lower_bound)\n",
    "\n",
    "        pm.Deterministic(\"capacity_pred\", mu_original)\n",
    "        pm.Deterministic(\"feature_effects\", beta)\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Translating raw battery data to diagnostics features\n",
    "\n",
    "In the preceding sections, the output side of the Bayesian model was rigorously defined, including the Beta likelihood, the Logit link function, and physics-informed priors for the parameters ($\\beta_0, \\boldsymbol{\\beta}, \\lambda, \\phi$). However, the quality of the resulting predictions depends critically on the quality of the input features ($\\mathbf{x}$) that drive the degradation term ($\\eta_i = \\dots + \\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}$).\n",
    "\n",
    "Raw capacity measurement curves are noisy and variable. Therefore, before proceeding to Bayesian sampling, it is necessary to dedicate a structured process to translating real-world operational data into robust, physically meaningful diagnostic features.\n",
    "\n",
    "This motivates the crucial step of feature engineering.\n",
    "\n",
    "### Data alignment and cleaning\n",
    "\n",
    "Before extracting diagnostic features, a uniform time base must be established, as the formulas used for feature extraction require comparable voltage and current values across cycles.\n",
    "\n",
    "1. Cycle Alignment (Standardization): Linear interpolation is used to resample all voltage and current time-series arrays to a uniform length (e.g., 500 points). This standardization enables direct cycle-to-cycle comparison, as illustrated by the transition from the raw data (Figures 1 and 2) to the interpolated curves (Figures 3 and 4).\n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; margin: 30px 0;\"> <div style=\"flex: 1; min-width: 300px; max-width: 600px; text-align: center;\"> <img src=\"charge_voltage.png\" alt=\"Cycle 1\" style=\"width: 75%; height: auto; border-radius: 8px;\" /> <p style=\"margin-top: 12px; font-size: 15px; color: #555;\"> Figure 1: Charging Voltage curve at the beginning of life </p> </div>\n",
    "<div style=\"flex: 1; min-width: 300px; max-width: 600px; text-align: center;\"> <img src=\"discharge_voltage.png\" alt=\"Cycle 1000\" style=\"width: 75%; height: auto; border-radius: 8px;\" /> <p style=\"margin-top: 12px; font-size: 15px; color: #555;\"> Figure 2: Discharge Voltage curve at the beginning of life </p> </div> </div> As shown in Figures 1 and 2, voltage curves differ in length due to variations in charge and discharge durations. Linear interpolation standardizes these curves to a fixed length (e.g., 500 points), enabling direct comparison across cycles, as illustrated in Figures 3 and 4.\n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; margin: 30px 0;\"> <div style=\"flex: 1; min-width: 300px; max-width: 600px; text-align: center;\"> <img src=\"charge_voltage_interpolated.png\" alt=\"Cycle 1\" style=\"width: 75%; height: auto; border-radius: 8px;\" /> <p style=\"margin-top: 12px; font-size: 15px; color: #555;\"> Figure 3: Inteporated Charging Voltage curve at the beginning of life </p> </div>\n",
    "\n",
    "<div style=\"flex: 1; min-width: 300px; max-width: 600px; text-align: center;\"> <img src=\"discharge_voltage_interpolated.png\" alt=\"Cycle 1000\" style=\"width: 75%; height: auto; border-radius: 8px;\" /> <p style=\"margin-top: 12px; font-size: 15px; color: #555;\"> Figure 4: Inteporated Discharge Voltage curve at the beginning of life </p> </div> </div>\n",
    "\n",
    "2. Data Filtering: Cycles exhibiting non-meaningful behavior (e.g., flat voltage profiles, excessive noise, or unrealistic starting or peak voltages) are removed to ensure that all inputs correspond to valid charging or discharging events.\n",
    "\n",
    "\n",
    "### Diagnostic Feature Extraction \n",
    "\n",
    "With aligned and cleaned curves, it is now possible to reliably extract cycle-specific diagnostic features that quantify the battery‚Äôs underlying physical degradation processes. These features are sensitive to aging mechanisms such as active material loss and internal resistance growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "\n",
    "> **üß† Reflection**:  We chose to derive these physically meaningful features instead of feeding the entire, aligned time-series data (Figures 3 & 4). Why are these manually engineered features often preferred in industrial applications? Consider the trade-offs in **model complexity**, **training speed**, and the crucial **interpretability** of the final Bayesian coefficients ($\\beta$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fix the typo and create data\n",
    "data = pd.DataFrame({\n",
    "    \"Diagnostic Feature\": [\n",
    "        \"Voltage Gap\",\n",
    "        \"Voltage Hysteresis\", \n",
    "        \"IC Peak Metrics\",\n",
    "        \"Hysteresis Proxy Resistance\"\n",
    "    ],\n",
    "    \"Formula\": [\n",
    "        \"ŒîVÃÑ = VÃÑ_c - VÃÑ_d\",\n",
    "        \"ŒîV(x) = V_c(x) - V_d(x)\",\n",
    "        \"IC = dQ/dV\",\n",
    "        \"R_proxy ‚àù ŒîV(x)/I_diff\"\n",
    "    ],\n",
    "    \"Physical Meaning\": [\n",
    "        \"Average polarization; quantifies internal losses\",\n",
    "        \"Loss mechanisms at specific state-of-charge\",\n",
    "        \"Phase transitions; indicates active material loss\",\n",
    "        \"Proxy for internal resistance growth\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "\n",
    "# Create publication-quality table\n",
    "table = (\n",
    "    GT(data)\n",
    "    .tab_header(\n",
    "        title=md(\"**Table 1: Battery Degradation Diagnostic Features**\"),\n",
    "        subtitle=\"Mathematical definitions and physical interpretations of key battery health indicators\"\n",
    "    )\n",
    "    .cols_label(\n",
    "        **{\n",
    "            \"Diagnostic Feature\": md(\"**Diagnostic Feature**\"),\n",
    "            \"Formula\": md(\"**Formula**\"),\n",
    "            \"Physical Meaning\": md(\"**Physical Meaning**\")\n",
    "        }\n",
    "    )\n",
    "    .tab_options(\n",
    "        table_width=\"100%\",\n",
    "        container_width=\"100%\",\n",
    "        table_font_size=\"14px\",\n",
    "        heading_title_font_size=\"18px\",\n",
    "        heading_subtitle_font_size=\"14px\",\n",
    "        column_labels_border_bottom_style=\"solid\",\n",
    "        column_labels_border_bottom_width=\"3px\",\n",
    "        column_labels_border_bottom_color=\"#3498db\",\n",
    "        table_body_border_bottom_style=\"solid\",\n",
    "        table_body_border_bottom_width=\"1px\",\n",
    "        table_body_border_bottom_color=\"#dee2e6\"\n",
    "    )\n",
    "    .tab_source_note(\n",
    "        source_note=\"Formulas assume constant temperature and current rates unless otherwise specified.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display\n",
    "table.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Statistical feature aggregation \n",
    "\n",
    "The diagnostic signals derived above (e.g., incremental capacity curves) remain high-resolution time- or cycle-series data. To produce robust, concise, and comparable inputs for the Bayesian regression model, a final aggregation step is performed by extracting statistical moments from each diagnostic signal $s(x)$. This aggregation reduces hundreds of data points per cycle into a small number of highly informative scalar features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    \"Statistical Feature\": [\n",
    "        \"Mean\",\n",
    "        \"Standard Deviation\", \n",
    "        \"Skewness\",\n",
    "        \"Kurtosis\",\n",
    "        \"RMS (Root-Mean-Square)\",\n",
    "        \"Entropy\",\n",
    "        \"Crest Factor\",\n",
    "        \"AUC (Area Under the Curve)\"\n",
    "    ],\n",
    "    \"Role in Degradation Modeling\": [\n",
    "        \"Captures the overall trend or shift of the diagnostic signal.\",\n",
    "        \"Measures variability and cycle-to-cycle noise.\",\n",
    "        \"Indicates asymmetry or bias in the signal distribution.\",\n",
    "        \"Quantifies the presence of extreme values or anomalies.\",\n",
    "        \"Represents the overall magnitude and stress level of the signal.\",\n",
    "        \"Measures irregularity or disorder, often increasing with non-uniform degradation.\",\n",
    "        \"Compares peak magnitude to average signal level, highlighting abnormal peaks.\",\n",
    "        \"Captures cumulative effects such as total energy loss or degradation trends.\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = (\n",
    "    GT(data)\n",
    "    .tab_header(\n",
    "        title=md(\"Statistical Features for Battery Degradation Modeling\"),\n",
    "        subtitle=\"Key signal processing metrics used to quantify degradation patterns\"\n",
    "    )\n",
    "    .cols_label(\n",
    "        **{\n",
    "            \"Statistical Feature\": md(\"**Statistical Feature**\"),\n",
    "            \"Role in Degradation Modeling\": md(\"**Role in Degradation Modeling**\")\n",
    "        }\n",
    "    )\n",
    "    .tab_options(\n",
    "        table_width=\"100%\",\n",
    "        container_width=\"100%\",\n",
    "        table_font_size=\"14px\",\n",
    "        heading_title_font_size=\"18px\",\n",
    "        heading_subtitle_font_size=\"14px\",\n",
    "        column_labels_border_bottom_style=\"solid\",\n",
    "        column_labels_border_bottom_width=\"3px\",\n",
    "        column_labels_border_bottom_color=\"#3498db\",\n",
    "        table_body_border_bottom_style=\"solid\",\n",
    "        table_body_border_bottom_width=\"1px\",\n",
    "        table_body_border_bottom_color=\"#dee2e6\"\n",
    "    )\n",
    "    .tab_source_note(\n",
    "        source_note=\"Bayesian Modelling|Anthony Faustine@ 2025\"\n",
    "    )\n",
    ")\n",
    "\n",
    "table.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "\n",
    "These statistical summaries (e.g., $\\text{Mean}(\\text{IC})$, $\\text{Std}(\\Delta V)$) form the input vector $\\mathbf{x}$ in the linear predictor $\\eta_i = \\dots + \\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}$. Such summaries of early-cycle behavior often preserve key degradation signatures while significantly reducing model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "After extracting a broad set of diagnostic and statistical features, feature selection is required. Using all available features can lead to overfitting, increased model complexity, and multicollinearity, which compromises interpretability of the Bayesian coefficients ($\\boldsymbol{\\beta}$). The final four features selected for regression ($\\mathbf{x}$) are:\n",
    "\n",
    "\n",
    "- charge_current_auc\n",
    "- charge_current_mean\n",
    "- discharge_voltage_auc\n",
    "- discharge_voltage_crest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Load pre-processed CALCE dataset\n",
    "\n",
    "The raw CALCE dataset is a widely used public resource in battery prognostics and can be downloaded via the [CALCE dataset link](https://ieee-dataport.org/documents/calce-battery-group).\n",
    "\n",
    "For this notebook, however, we use pre-processed data that has been cleaned and formatted. This pre-processing reuses the techniques and codes originally published in this paper [Ref](https://www.nature.com/articles/s42256-024-00972-x#citeas). Using the cleaned data allows us to focus immediately on the Bayesian modeling aspects without the overhead of complex data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSHARE_DOWNLOAD_URL = \"https://ndownloader.figshare.com/files/59415941\"\n",
    "features = [\"charge_current_auc\", \"charge_current_mean\", \"discharge_voltage_crest\", \"discharge_voltage_auc\"]\n",
    "target = \"capacity\"\n",
    "data = pd.read_parquet(FIGSHARE_DOWNLOAD_URL, engine=\"pyarrow\")\n",
    "upper_bound, lower_bound = data[target].max(), data[target].min()\n",
    "df = data[data.CellType == \"CS2\"].copy()\n",
    "test_df = df[df.BatteryID != \"CALCE_CS2_38\"]\n",
    "train_df = df[df.BatteryID == \"CALCE_CS2_38\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "for feature_name in features:\n",
    "    plot = scatter_plot(train_df, y_col=feature_name)\n",
    "    plots.append(plot + labs(title=feature_name) + modern_theme(font_size=9))\n",
    "\n",
    "plot=gggrid(plots, ncol=2) + ggsize(650, 450)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "The figure below plots the four selected features against cycle number for a representative battery. These plots empirically validate the selection process, as all four features exhibit clear, monotonic changes with cycling and, critically, show a distinct shift or acceleration in slope as the battery enters the failure state ($\\text{SoH} \\le 80\\%$, shown in green). This strong visual correlation provides high confidence that these inputs will effectively drive the degradation component of our Bayesian model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Bayesian model building\n",
    "\n",
    "Before constructing the Bayesian Beta regression model, it is necessary to define a rigorous evaluation strategy. The central question addressed here is whether a model trained on data from a single battery can successfully generalize to other batteries whose degradation trajectories were not observed during training.\n",
    "\n",
    "This setting reflects a common real-world scenario in which detailed historical data may be available for only a limited number of prototype units, while the deployed model must operate reliably across an entire manufacturing batch.\n",
    "\n",
    "To ensure a fair and controlled evaluation, all batteries considered in this study are restricted to a single cell chemistry type (‚ÄúCS2‚Äù). By holding the underlying electrochemical properties constant, the analysis isolates unit-to-unit variability rather than confounding the results with chemistry-dependent effects.\n",
    "\n",
    "A one-shot generalization split is employed. A single representative battery (CALCE_CS2_38) is designated as the training set (train_df). The model learns the degradation rate ($\\lambda$) and operational sensitivities ($\\boldsymbol{\\beta}$) exclusively from this unit‚Äôs historical data. All remaining batteries of the same chemistry are assigned to the test set (test_df). Model performance is therefore evaluated based on its ability to predict capacity fade for previously unseen batteries using only the generalizable parameters inferred from the training unit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "With the input data rigorously cleaned, aligned, scaled, and reduced to the four most informative operational features ($\\mathbf{x}$), the Bayesian regression model can now be implemented and fitted. As defined in the Beta Likelihood and Priors subsection, the model is specified as a Bayesian Beta regression with a logit link function, enabling the modeling of bounded battery capacity ($\\tilde{C}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bayes.regression.beta_degradation import beta_regression_model\n",
    "model, scaler = beta_regression_model(\n",
    "    train_df, features, target=target, upper_bound=upper_bound, lower_bound=lower_bound\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Prior Predictive Check\n",
    "\n",
    "Following standard Bayesian practice, model validation begins with a Prior Predictive Check (PPC). The PPC involves simulating data from the model using only the prior distributions, without conditioning on any observed measurements. This procedure serves as a critical sanity check, verifying that the encoded engineering knowledge produces physically plausible behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    prior_pred = pm.sample_prior_predictive(samples=1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 1.8))\n",
    "az.plot_ppc(prior_pred, group=\"prior\", ax=ax)\n",
    "plt.xlabel(\"Capacity\")\n",
    "plt.ylabel(\"Density\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "The figure below, compare the predicted prior distribution (green line) against the observed data (blue line). This plot is essential for validating that our model's structural assumptions align with physical reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prior = prior_pred.prior[\"capacity_pred\"].stack(sample=[\"chain\", \"draw\"]).values\n",
    "y_obs = train_df[target].values\n",
    "post_mean = y_prior.mean()\n",
    "n_draws = 500\n",
    "rng = np.random.default_rng(42)\n",
    "draw_idx = rng.choice(y_prior.shape[0], size=n_draws, replace=False)\n",
    "y_prior_subset = y_prior[:, draw_idx].flatten()\n",
    "df_prior = pd.DataFrame(\n",
    "    {\n",
    "        \"SoH\": np.concatenate([y_obs, y_prior_subset]),\n",
    "        \"type\": [\"observed\"] * len(y_obs) + [\"prior\"] * len(y_prior_subset),\n",
    "    }\n",
    ")\n",
    "plot=plot_density(\n",
    "    df_prior,\n",
    "    x_col=\"SoH\",\n",
    "    color_col=\"type\",\n",
    "    x_label=\"Capacity\",\n",
    "    fig_size=(500, 400),\n",
    "    title=\"Prior comparison\",\n",
    "    subtitle=\"Prior Predictive Check\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "From the two figures above, the PPC confirms the structural validity of the model:\n",
    "\n",
    "- High-Confidence Initial Capacity: The predicted capacity distribution exhibits a dominant peak near $\\mu \\approx 1.0$, reflecting the highly informative precision prior $\\phi \\sim \\text{Gamma}(100, 2.0)$ (mean $\\phi = 50$). This enforces a strong prior belief in low sensor noise and high initial measurement confidence.\n",
    "\n",
    "- Realistic Degradation Envelope: The prior predictive distribution remains tightly constrained across the capacity range. This behavior is driven by the informative degradation-rate prior on $\\lambda$, which minimizes the probability of immediate or catastrophic capacity loss and enforces physically plausible degradation trajectories.\n",
    "\n",
    "- Acknowledgment of Failure Modes: While constrained, the prior allocates non-negligible probability mass to lower capacity regions (e.g., $\\tilde{C} \\approx 0.4$‚Äì$0.7$). This reflects uncertainty in the degradation amplitude and rate parameters, allowing for degradation and failure scenarios without overstating their likelihood.\n",
    "\n",
    "\n",
    "The PPC demonstrates that the model respects physical bounds, reflects realistic degradation behavior, and balances strong prior knowledge with controlled uncertainty. The model is therefore suitable for posterior inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "## Running inference \n",
    "\n",
    "With the model fully specified, priors validated through the PPC, and input features prepared, posterior inference is performed using Markov Chain Monte Carlo (MCMC) sampling. This step approximates the posterior distribution by updating prior beliefs using the observed data, forming the core of Bayesian inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    idata = pm.sample(2000, tune=2000, target_accept=0.95, random_seed=42)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "\n",
    "As discussed in [Part 1](https://sambaiga.github.io/blog/2025/10/bayesian-modelling-01.html), the MCMC process uses the No-U-Turn Sampler (NUTS) to explore the parameter space. The primary arguments guide this process:\n",
    "\n",
    "- tune=2000: Specifies 2000 initial samples that are used solely to adapt the sampler's step size and are then discarded. A high tuning value is crucial for complex, highly curved posteriors (like those involving Beta distributions) to ensure stable exploration.\n",
    "- draws=2000: Specifies 2000 final samples kept from the chain. These collected samples form the final Posterior Distribution for every model parameter ($\\lambda$, $\\beta$, $\\phi$).\n",
    "- target_accept=0.95: Forces the sampler to take smaller, more cautious steps. This high acceptance rate is necessary to avoid divergences in challenging models, ensuring a high-quality, accurate representation of the posterior distribution, though it increases computation time.\n",
    "  \n",
    "The resulting idata object now contains thousands of samples for every single model parameter, representing our comprehensive, uncertainty-quantified solution. The next step is to ensure these samples are reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "### Model diagnostics\n",
    "\n",
    "After sampling, convergence diagnostics are evaluated to ensure the reliability of posterior estimates. The validity of all subsequent inferences depends on whether the Markov chains have adequately explored the parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\"beta\", \"intercept\", \"lambda_rate\", \"phi\", \"degr_amp\"]\n",
    "data_summary = az.summary(idata, var_names=vars, kind=\"diagnostics\")[[\"ess_bulk\", \"ess_tail\", \"r_hat\"]]\n",
    "GT(data_summary.reset_index()).tab_header(title=\"\", subtitle=\"Diagnostics Summary\").cols_label(\n",
    "    {\n",
    "        \"ess_bulk\": \"ESS Bulk\",\n",
    "        \"ess_tail\": \"ESS Tail.\",\n",
    "        \"r_hat\": \"R-hat\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Two primary diagnostics are considered:\n",
    "\n",
    "1. $\\hat{R}$ (Gelman‚ÄìRubin statistic): All parameters exhibit $\\hat{R} = 1.0$, indicating excellent chain mixing and agreement across chains.\n",
    "\n",
    "2. Effective Sample Size (ESS): ESS values exceed 400 for all parameters (ranging from approximately 4,200 to 7,300), confirming that a sufficient number of independent samples were obtained for stable estimation of posterior means and credible intervals.\n",
    "\n",
    "These diagnostics collectively indicate successful convergence and robust posterior sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "\n",
    "### Analysing the posterior distribution\n",
    "With convergence confirmed, the sampled chains provide a reliable approximation of the posterior distribution. The marginal posterior densities and corresponding trace plots for the core model parameters are examined to quantify degradation dynamics and assess the influence of operational features.\n",
    "\n",
    "This analysis enables principled uncertainty quantification of degradation rates and feature effects, supporting interpretable and decision-relevant predictions for battery health forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=vars, compact=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "The ```analyze_parameter``` function below acts as a post-processing utility dedicated to generating publication-ready summary tables from the output of the MCMC sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_parameter(\n",
    "    idata,\n",
    "    parameter: str,\n",
    "    features: list[str] | None = None,\n",
    "    hdi_prob: float = 0.95,\n",
    "    title: str = \"Parameter Summary\",\n",
    "    subtitle: str | None = None,\n",
    ") -> GT:\n",
    "    \"\"\"Generates a formatted summary table for a single parameter using Great Tables.\n",
    "\n",
    "    This function extracts posterior summary statistics from ArviZ InferenceData and\n",
    "    returns a beautifully styled table suitable for reports, notebooks, or publications.\n",
    "\n",
    "    Args:\n",
    "        idata: ArviZ InferenceData object containing posterior samples.\n",
    "        parameter: Name of the parameter to summarize (e.g., \"beta\", \"alpha\", \"sigma\").\n",
    "        features: List of feature names to label rows. Required and used only when\n",
    "            ``parameter == \"beta\"``. Length must match the number of coefficients.\n",
    "        hdi_prob: Highest density interval probability (default: 0.95).\n",
    "        title: Main title for the table.\n",
    "        subtitle: Optional subtitle. If None and parameter is \"beta\", defaults to\n",
    "            \"Beta coefficient analysis\".\n",
    "\n",
    "    Returns:\n",
    "        A Great Tables (GT) object ready for display or further customization.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If ``features`` is provided for non-beta parameters or has wrong length.\n",
    "\n",
    "    Example:\n",
    "        >>> gt = analyze_parameter(idata, \"beta\", features=X.columns.tolist())\n",
    "        >>> gt  # displays nicely in Jupyter\n",
    "    \"\"\"\n",
    "    if features is not None and parameter != \"beta\":\n",
    "        raise ValueError(\"`features` should only be provided when parameter == 'beta'\")\n",
    "\n",
    "    # Get summary statistics from ArviZ\n",
    "    summary_df = az.summary(\n",
    "        idata,\n",
    "        var_names=[parameter],\n",
    "        hdi_prob=hdi_prob,\n",
    "        kind=\"stats\",\n",
    "        fmt=\"wide\",\n",
    "    ).reset_index(names=\"feature\")\n",
    "\n",
    "    # Assign meaningful feature names for beta coefficients\n",
    "    if parameter == \"beta\":\n",
    "        if features is None:\n",
    "            raise ValueError(\"`features` must be provided when analyzing 'beta' parameter\")\n",
    "        if len(features) != len(summary_df):\n",
    "            raise ValueError(\n",
    "                f\"Length of features ({len(features)}) must equal number of beta coefficients ({len(summary_df)})\"\n",
    "            )\n",
    "        summary_df[\"feature\"] = features\n",
    "\n",
    "    conditions = [\n",
    "        summary_df[\"hdi_2.5%\"] > 0,  # Entire interval is positive\n",
    "        summary_df[\"hdi_97.5%\"] < 0,  # Entire interval is negative\n",
    "    ]\n",
    "    choices = [\"Positive\", \"Negative\"]\n",
    "    summary_df[\"certainty\"] = np.select(conditions, choices, default=\"Uncertain\")\n",
    "\n",
    "    # Set default subtitle for beta coefficients\n",
    "    if subtitle is None and parameter == \"beta\":\n",
    "        subtitle = \"Beta coefficient analysis\"\n",
    "\n",
    "    gt_table = (\n",
    "        GT(summary_df)\n",
    "        .tab_header(\n",
    "            title=md(f\"**{title}**\"),\n",
    "            subtitle=md(subtitle) if subtitle else None,\n",
    "        )\n",
    "        .fmt_number(\n",
    "            columns=[\"mean\", \"sd\", \"hdi_2.5%\", \"hdi_97.5%\"],\n",
    "            decimals=3,\n",
    "        )\n",
    "        .data_color(\n",
    "            columns=[\"certainty\"],\n",
    "            palette=[\"#E1DFDD\", \"#F18F01\", \"#F18F01\"],\n",
    "            domain=[\"Uncertain\", \"Negative\", \"Positive\"],\n",
    "        )\n",
    "        .cols_label(\n",
    "            feature=md(\"**Feature**\"),\n",
    "            mean=md(\"**Mean**\"),\n",
    "            sd=md(\"**SD**\"),\n",
    "            **{\"hdi_2.5%\": md(\"**HDI 2.5%**\")},\n",
    "            **{\"hdi_97.5%\": md(\"**HDI 97.5%**\")},\n",
    "        )\n",
    "        .cols_align(align=\"center\", columns=[\"mean\", \"sd\", \"hdi_2.5%\", \"hdi_97.5%\", \"Certainty\"])\n",
    "        .tab_options(\n",
    "            table_font_size=\"14px\",\n",
    "            heading_title_font_size=\"20px\",\n",
    "            heading_subtitle_font_size=\"16px\",\n",
    "            row_group_font_weight=\"bold\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return gt_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "### Identifying Reliable Degradation Drivers ($\\boldsymbol{\\beta}$ Coefficients)\n",
    "\n",
    "The regression coefficients $\\boldsymbol{\\beta}$ quantify the relationship between the engineered operational features (e.g., current and voltage metrics) and battery State of Health ($\\text{SoH}$) through the logit link function, $\\log\\left(\\frac{\\mu}{1-\\mu}\\right)$. The credibility of each predictor is assessed by examining whether its $95%$ Highest Density Interval (HDI) includes zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=analyze_parameter(idata, \"beta\", features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "The posterior summary indicates that only one feature emerges as a statistically reliable degradation driver at the $95%$ credibility level: the discharge_voltage_crest factor. Its $95%$ HDI lies entirely below zero (from $-0.528$ to $-0.369$), indicating strong evidence of a negative association with capacity retention. This result implies, with high certainty, that increases in this factor accelerate capacity fade. The posterior mean coefficient for the discharge_voltage_crest factor is $\\beta = -0.446$. Interpreted on the odds scale as $$\\text{Odds Ratio} = \\exp(-0.446) \\approx 0.64$$. \n",
    " \n",
    "Thus, a one-unit increase in the crest factor is associated with an approximately $36%$ reduction in the odds of maintaining high battery capacity ($1 - 0.64$).\n",
    "\n",
    "In contrast, the $95%$ HDIs for the remaining three features include zero (e.g., for charge_current_auc, HDI $[-0.437,,0.132]$). As a result, the model cannot rule out the possibility that their true effects are negligible or even slightly positive. These features therefore do not constitute statistically reliable degradation drivers under the current model specification. Consequently, maintenance and monitoring efforts can be focused on the discharge_voltage_crest factor as the dominant operational indicator of degradation.\n",
    "\n",
    "> **üõ†Ô∏è Action**: Refit the Beta regression model using only the discharge_voltage_crest factor as an operational covariate. Evaluate whether predictive performance on the test set remains comparable and whether the posterior mean and HDI for this coefficient remain stable. Such consistency would further support the conclusion that the remaining features primarily contributed noise rather than explanatory signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### Quantifying the degradation rate ($\\lambda_{\\text{rate}}$)\n",
    "\n",
    "The parameter $\\lambda_{\\text{rate}}$ governs the speed of capacity fade induced by cycling. By adopting a weakly informative Lognormal prior with increased dispersion ($\\sigma = 1.0$), the data is allowed to dominate the posterior estimation of this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=analyze_parameter(idata, \"lambda_rate\", title=\"Lambda Rate Summary\", subtitle=\"Degradation rate parameter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "The posterior summary yields a highly precise estimate of the degradation rate, with a posterior mean of $\\mathbf{0.003}$ per unit of cycle data. This value is lower than the prior expectation (centered around $0.005$), indicating that although degradation is inevitable, it progresses more gradually than initially assumed.\n",
    "\n",
    "The remaining uncertainty is minimal, as evidenced by a small posterior standard deviation ($\\text{SD} = 0.001$) and a narrow $95%$ HDI of $[0.002,,0.004]$. These results confirm that the MCMC sampler has effectively leveraged the data to tightly constrain the degradation speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "###  Model precision ($\\phi$)\n",
    "\n",
    "The precision parameter $\\phi$ controls the dispersion of the Beta likelihood, quantifying how tightly the observed $\\text{SoH}$ measurements cluster around the model-predicted mean after accounting for all modeled effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=analyze_parameter(idata, \"phi\", title=\"Phi Summary\", subtitle=\"Phi  parameter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "The posterior distribution of $\\phi$ exhibits a high degree of concentration, with a posterior mean of $233.461$ and a narrow $95%$ HDI. This large mean precision implies very low residual variance in $\\text{SoH}$, indicating that the combined model structure‚Äîincorporating the exponential degradation term, the cycling rate $\\lambda$, and the operational features $\\boldsymbol{\\beta}$ explains the majority of observed variability across the battery fleet. The narrow HDI further indicates that this high precision is estimated with substantial certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "#### Degr amp parameter ($A$)\n",
    "\n",
    "The degradation amplitude parameter, $\\text{degr\\_amp}$, quantifies the maximum potential capacity fade attributable solely to the cycling process and operates on the log-odds scale. The posterior mean of $0.367$ represents the maximum reduction in $\\text{logit}(\\mu)$ induced by cycling over the battery‚Äôs lifetime, thereby determining the vertical extent of the degradation curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table=analyze_parameter(idata, \"degr_amp\", title=\"Degr amp\", subtitle=\"A  parameter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "The $95%$ HDI for $\\text{degr\\_amp}$ is narrow and entirely positive, spanning $[0.265,,0.468]$. This provides strong statistical evidence that degradation due to cycling is both certain and quantitatively well-defined, rather than an artifact of noise. The strictly positive support of this parameter confirms that capacity loss is an unavoidable consequence of repeated cycling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### Posterior predictive check\n",
    "\n",
    "Following parameter interpretation, a Posterior Predictive Check (PPC) is performed to assess model adequacy. This step evaluates whether the model, using posterior parameter samples, can generate synthetic data that closely resembles the observed measurements.\n",
    "\n",
    "Using PyMC‚Äôs ```sample_posterior_predictive``` function, samples are drawn from the likelihood conditioned on the converged posterior chains. The resulting PPC compares three distributions: the observed data, the prior predictive distribution, and the posterior predictive distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    post_pred = pm.sample_posterior_predictive(idata, var_names=[\"y_obs\"], random_seed=42)\n",
    "\n",
    "y_post = post_pred.posterior_predictive[\"y_obs\"].stack(sample=[\"chain\", \"draw\"]).values\n",
    "# Mean of the posterior predictive\n",
    "post_mean = y_post.mean()\n",
    "n_draws = 500\n",
    "rng = np.random.default_rng(42)\n",
    "draw_idx = rng.choice(y_post.shape[0], size=n_draws, replace=False)\n",
    "y_post_subset = y_post[:, draw_idx].flatten()\n",
    "y_post_subset = y_post_subset * (upper_bound - lower_bound) + lower_bound\n",
    "\n",
    "\n",
    "df_posterior = pd.DataFrame(\n",
    "    {\n",
    "        \"SoH\": np.concatenate([y_obs, y_post_subset]),\n",
    "        \"type\": [\"observed\"] * len(y_obs) + [\"posterior\"] * len(y_post_subset),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "The figure below shows a Posterior Predictive Check (PPC), which is the gold standard for evaluating model fit in Bayesian statistics. It compares three key distributions for the capacity: the data we observed, our initial beliefs (Prior), and the model's final predictions (Posterior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_prior, df_posterior])\n",
    "plot=plot_density(\n",
    "    df,\n",
    "    x_col=\"SoH\",\n",
    "    color_col=\"type\",\n",
    "    x_label=\"Capacity\",\n",
    "    fig_size=(700, 350),\n",
    "    title=\"Prior and Posterior Comparison\",\n",
    "    subtitle=\"Beta-regression\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "The posterior predictive distribution aligns closely with the observed capacity distribution, indicating that the model successfully captures the underlying data-generating process. In contrast, the prior predictive distribution is smoother and exhibits broader structure, reflecting weaker and less targeted assumptions before observing data. \n",
    "\n",
    "The shift and sharpening from prior to posterior predictive distributions demonstrate that the observed data provided substantial information and that the model effectively updated its initial beliefs.\n",
    "\n",
    "The posterior predictive distribution is strongly skewed toward high capacity values near $1.0$, consistent with the predominance of early- and mid-life measurements. A smaller secondary mode around $0.3$‚Äì$0.4$ corresponds to a limited number of end-of-life observations. This agreement between synthetic and observed data provides strong evidence of model adequacy and predictive reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "## Predict capacity for a new battery\n",
    "\n",
    "The final objective of this modeling effort is to transition from parameter estimation to practical prognosis by generating a full Posterior Predictive Distribution (PPD) for the capacity of a new or future battery state. This process converts uncertainty-aware parameter estimates into actionable prognostic predictions.\n",
    "\n",
    "The PPD explicitly incorporates two fundamental sources of uncertainty:\n",
    "\n",
    "1. Epistemic uncertainty, arising from uncertainty in the estimated model parameters (e.g., the width of the HDI for $\\lambda_{\\text{rate}}$).\n",
    "\n",
    "2. Aleatoric uncertainty, representing irreducible noise in the measurement process, as captured by the precision parameter $\\phi$.\n",
    "\n",
    "As a result, the model produces not a single point estimate but a credible interval (HDI) that probabilistically bounds the true capacity value at each cycle. \n",
    "\n",
    "To assess generalization performance and demonstrate practical utility for risk management, four cells from the CALCE dataset that were excluded during training are selected for evaluation. For each battery, the same four operational features used in model training are extracted and supplied to the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes.regression.beta_degradation import get_posterior_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = test_df[test_df[\"BatteryID\"].isin([\"CALCE_CS2_34\", \"CALCE_CS2_36\", \"CALCE_CS2_37\", \"CALCE_CS2_33\"])].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "Posterior predictions for unseen batteries are generated using the ```get_posterior_predictions`` procedure, which applies the fitted Bayesian model to new input data. The process consists of the following steps:\n",
    "\n",
    "- **Feature Transformation**: The operational features of the new battery are transformed using the same scaling object fitted during training, ensuring consistency between training and inference domains. The corresponding cycle counts are extracted separately, as they directly enter the exponential degradation component of the model.\n",
    "- \n",
    "```python\n",
    "    x_new = scaler.transform(data[features])\n",
    "```\n",
    "\n",
    "\n",
    "- **Dummy Target Initialization**: A placeholder target array is supplied to satisfy the dimensional requirements of the PyMC model‚Äôs observed variable. These values are ignored during posterior prediction..\n",
    "   \n",
    "```python\n",
    "    y_dummy_scaled = np.full(shape=(X_new_scaled.shape[0],), fill_value=0.5)\n",
    "```\n",
    "\n",
    "- **Model update**: The new feature matrix, cycle data, and dummy target are injected into the model using pm.set_data, reconfiguring the model for prediction without retraining.\n",
    "  \n",
    "```python\n",
    "    with battery_model:\n",
    "        pm.set_data({\n",
    "            \"x_data\": x_new,\n",
    "            \"cycle_data\": cycle_new,\n",
    "            \"y_obs\": y_dummy_scaled\n",
    "        })\n",
    "```\n",
    "\n",
    "- **Posterior Predictive Sampling**: Samples are drawn from the Posterior Predictive Distribution using ```pm.sample_posterior_predictive```, incorporating both posterior parameter uncertainty and observation noise..\n",
    "   \n",
    "```python\n",
    "    with battery_model:\n",
    "        post_pred = pm.sample_posterior_predictive(\n",
    "            idata,\n",
    "            var_names=[\"y_obs\"],\n",
    "            random_seed=42,\n",
    "            predictions=True,\n",
    "        )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = get_posterior_predictions(\n",
    "    idata, model, scaler, new_df, features, alpha=0.1, upper_bound=upper_bound, lower_bound=lower_bound\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "Predictions for each test battery are visualized using the plot_hdi_regression function. The plots display the observed capacity measurements (points) overlaid with the model‚Äôs posterior predictive mean and the corresponding $90%$ HDI.  The blue line represents the posterior predictive mean where the shaded region represents the $90%$ HDI, quantifying predictive uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes.plot.regres_plot import plot_hdi_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=plot_hdi_regression(\n",
    "    pred_df,\n",
    "    x_column=\"cycle\",\n",
    "    y_column=\"capacity\",\n",
    "    group_column=\"BatteryID\",\n",
    "    pred_column=\"pred_median\",\n",
    "    x_label=\"Cycle Number\",\n",
    "    y_label=\"Capacity (Ah)\",\n",
    "    title_prefix=\"Battery Capacity vs. Cycle with Posterior Predictions\",\n",
    "    subtitle=\"90% HDI accounts for  uncertainty.\",\n",
    "    alpha=0.1,\n",
    ") + ggsize(800, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "Key Observations\n",
    "\n",
    "- The posterior predictive mean closely tracks the observed capacity trajectory across the full battery lifetime, including the non-linear degradation phase near end-of-life.\n",
    "\n",
    "- Approximately $90\\%$ (or more) of observed data points fall within the predictive HDI, indicating well-calibrated uncertainty estimates.\n",
    "\n",
    "- For batteries CS2_33, CS2_36, and CS2_37, the HDI remains narrow even during late-life degradation, reflecting high model confidence and low residual noise.\n",
    "\n",
    "- For battery CS2_34, the HDI widens toward the final cycles, appropriately reflecting increased predictive uncertainty in the late-life regime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "### Evaluating Predictive Performance\n",
    "\n",
    "Predictive performance on the held-out batteries is quantified using both accuracy and uncertainty-based metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes.metrics.interval import get_interval_metrics\n",
    "from bayes.metrics.regression import regression_report\n",
    "\n",
    "metrics_list = []\n",
    "for battery_id, df in pred_df.groupby(\"BatteryID\"):\n",
    "    reg_report = regression_report(df[\"capacity\"], df[\"pred_median\"])\n",
    "    interval_report = get_interval_metrics(\n",
    "        df[\"pred_median\"].values,\n",
    "        df[\"capacity\"].values,\n",
    "        df[\"hdi_low\"].values,\n",
    "        df[\"hdi_high\"].values,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    full_report = pd.concat([reg_report, interval_report], ignore_index=True)\n",
    "    full_report[\"BatteryID\"] = battery_id\n",
    "    metrics_list.append(full_report)\n",
    "metrics_df = pd.concat(metrics_list, ignore_index=True)\n",
    "\n",
    "metrics_df = metrics_df.pivot_table(\n",
    "    index=[\"BatteryID\"],\n",
    "    columns=\"Metric\",\n",
    "    values=\"Value\",\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "def make_metrics_table(metrics_df, title=\"Model Evaluation Results\"):\n",
    "    \"\"\"Generate a formatted GT table from cross-validation metrics.\"\"\"\n",
    "    # Sort to present best models first\n",
    "    df = metrics_df.sort_values([\"BatteryID\", \"MAE\"]).reset_index(drop=True)\n",
    "\n",
    "    # Build base table\n",
    "    gt = (\n",
    "        GT(df[[\"BatteryID\", \"MAE\", \"RMSE\", \"R2\", \"NMPI\", \"PICP\"]])\n",
    "        .tab_header(title=title, subtitle=\"Per-battery performance\")\n",
    "        .cols_label(BatteryID=\"Test Cell\", MAE=\"MAE\", RMSE=\"RMSE\", R2=md(\"R<sup>2</sup>\"))\n",
    "        .fmt_number(columns=[\"MAE\", \"RMSE\", \"NMPI\", \"PICP\"], decimals=3)\n",
    "        .fmt_number(columns=\"R2\", decimals=3)\n",
    "        .tab_spanner(label=\"Error Metrics\", columns=[\"MAE\", \"RMSE\", \"NMPI\", \"PICP\"])\n",
    "        .tab_style(\n",
    "            style=style.text(weight=\"bold\"),\n",
    "            locations=loc.body(columns=\"Model\"),\n",
    "        )\n",
    "        .tab_options(\n",
    "            table_font_size=\"small\",\n",
    "            # row_strip_color=\"#fafafa\"\n",
    "        )\n",
    "    )\n",
    "    for col in [\"MAE\", \"RMSE\", \"R2\", \"NMPI\", \"PICP\"]:\n",
    "        best_idx = df[col].idxmax() if col in [\"R2\", \"PICP\"] else df[col].idxmin()\n",
    "        gt = gt.tab_style(style=style.fill(color=\"#E1DFDD\"), locations=loc.body(rows=best_idx, columns=col))\n",
    "\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_metrics_table(metrics_df, title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "**Accuracy Metrics**\n",
    "\n",
    "Point-prediction accuracy is evaluated using the coefficient of determination ($R^2$), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE). Together, these metrics assess how well the model‚Äôs posterior predictive mean captures the observed capacity degradation trajectory.\n",
    "\n",
    "- $R^2$ quantifies the proportion of variance in the observed capacity explained by the model. Values close to 1 indicate that the predicted degradation curve accurately follows the overall trend and slope of capacity fade.\n",
    "\n",
    "- MAE represents the average absolute deviation between predicted and observed capacity values, expressed in State-of-Health (SoH) units. MAE provides a physically interpretable measure of typical prediction error.\n",
    "\n",
    "- RMSE penalizes larger deviations more strongly than MAE and is therefore particularly sensitive to localized mismatches, especially during the highly nonlinear end-of-life degradation phase.\n",
    "\n",
    "From the results summarized above, the model achieves $R^2$ values between $0.910$ and $1.0$, with MAE in the range of $0.010$‚Äì$0.040$ SoH units, indicating strong point-prediction accuracy across all evaluated cells. RMSE values range from $0.01$ to $0.05$ SoH units, confirming that large deviations are generally rare.\n",
    "\n",
    "However, Cell 34 exhibits the highest RMSE ($0.05$), along with comparatively lower $R^2$ and higher MAE than the remaining cells. This combination indicates that, while the model captures the overall degradation trend for Cell 34, it experiences larger localized errors‚Äîparticularly near late-life degradation relative to other cells. These deviations suggest the presence of sharper nonlinear behavior or cell-specific degradation mechanisms not fully represented by the global model parameters.\n",
    "\n",
    "**Uncertainty Quality Metrics**\n",
    "\n",
    "Beyond point accuracy, a central goal of Bayesian modeling is to provide reliable and interpretable uncertainty estimates. This is assessed using Prediction Interval Coverage Probability (PICP) and Normalized Mean Prediction Interval (NMPI).\n",
    "\n",
    "- PICP measures the fraction of observed capacity values that fall within the model‚Äôs $90%$ Highest Density Interval (HDI). A well-calibrated model should achieve PICP close to the nominal level (0.95), indicating that the predicted uncertainty accurately reflects real variability.\n",
    "\n",
    "- NMPI quantifies the average width of the predictive interval, normalized by the observed capacity range. NMPI reflects the sharpness of predictions: lower values indicate tighter uncertainty bounds, which are essential for actionable maintenance and risk-based decision-making.\n",
    "\n",
    "Results show consistently low NMPI values (approximately $\\mathbf{0.1}$) across all test cells. This confirms that the predictive intervals are narrow relative to the capacity range, indicating high confidence in the model‚Äôs predictions. At the same time, PICP exceeds $0.90$ for most cells, demonstrating that this confidence is not over-stated and that the uncertainty bounds are well calibrated.\n",
    "\n",
    "Cell 34 again deviates from this pattern, exhibiting reduced PICP ($75\\%$). This indicates that a larger fraction of its observed capacity measurements fall outside the predicted $90%$ HDI, suggesting either increased intrinsic variability or degradation dynamics that differ from those captured by the global model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "> **üõ†Ô∏è Action**: To diagnose the degraded predictive performance observed for Cell 34, compare all test cells by plotting $R^2$ versus PICP to identify accuracy‚Äìreliability trade-offs. Examine whether Cell 34‚Äôs operational features fall outside the training-feature distribution, indicating extrapolation beyond the model‚Äôs learned domain. Finally, compare the capacity degradation distribution of Cell 34 with the training cell to assess whether it follows a distinct degradation regime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "This post demonstrates that a single-level Bayesian Beta regression model, informed by physics-aware priors and carefully engineered features, can deliver highly accurate capacity predictions together with trustworthy uncertainty bounds. The model achieves near-perfect predictive accuracy while maintaining well-calibrated $95%$ credible intervals, validating the use of Beta likelihoods and informed priors for battery degradation modeling.\n",
    "\n",
    "However, the current formulation assumes that the degradation rate ($\\lambda_{\\text{rate}}$) and operational sensitivities ($\\boldsymbol{\\beta}$) are shared across the entire battery fleet. In practice, manufacturing variability and latent defects introduce unit-specific degradation behavior. As a result, even a highly accurate global model may underpredict risk for batteries from unfavorable batches or overestimate degradation for higher-quality units.\n",
    "\n",
    "**Coming Next**:  In Part 3, this limitation will be addressed by introducing Hierarchical Bayesian Models. These models learn a robust global degradation trend while allowing each individual battery to exhibit informed local deviations in parameters such as $\\lambda_{\\text{rate}}$ and $\\boldsymbol{\\beta}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "  > The data and full code in [pymc5](https://www.pymc.io/welcome.html) is available on my [GITHUB](https://github.com/sambaiga/bayesian-modelling/blob/main/notebook/2025-12-1-bayesian-regression..ipynb) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Zhang, H., Li, Y., Zheng, S. et al. [Battery lifetime prediction across diverse ageing conditions with inter-cell deep learning](https://www.nature.com/articles/s42256-024-00972-x#citeas). Nat Mach Intell 7, 270‚Äì277 (2025). https://doi.org/10.1038/s42256-024-00972-x\n",
    "2. Ferrari, S. L. P., & Cribari-Neto, F. (2004). Beta regression for modelling rates and proportions. Journal of Applied Statistics, 31(7), 799‚Äì815.\n",
    "3. Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). CRC Press.\n",
    "4. McElreath, R. (2020). Statistical Rethinking (2nd ed.). CRC Press."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
